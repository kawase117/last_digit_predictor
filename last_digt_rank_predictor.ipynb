{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ã‚»ãƒ«00: ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ§‹é€ ãƒ¡ãƒ¢\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "ğŸ“š ãƒ‘ãƒã‚¹ãƒ­åˆ†æãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ v3.0\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "ğŸ¯ ã‚»ãƒ«ç•ªå·ãƒ«ãƒ¼ãƒ«\n",
    "  01-09: ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "  10-19: ãƒ¢ãƒ‡ãƒ«å®šç¾©\n",
    "  20-29: å®Ÿè¡Œ\n",
    "  30-39: åˆ†æ\n",
    "  90-99: ãƒ‡ãƒãƒƒã‚°ç”¨\n",
    "\n",
    "ğŸ“‹ ã‚»ãƒ«æ§‹æˆ\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "  01 - ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— + CONFIG\n",
    "  02 - ãƒ‡ãƒ¼ã‚¿èª­è¾¼\n",
    "  03 - ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ç‰¹å¾´é‡\n",
    "  04 - åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "  05 - ãƒãƒ¼ã‚¸å‡¦ç†\n",
    "  \n",
    "Phase 2: ãƒ¢ãƒ‡ãƒ«å®šç¾©\n",
    "  10 - ãƒ©ãƒ™ãƒ«ä½œæˆ+ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "  11 - ç‰¹å¾´é‡é¸æŠ(Lasso/F/MI/RF)\n",
    "  12 - Optunaæœ€é©åŒ–\n",
    "  13 - æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´\n",
    "  14 - è©•ä¾¡é–¢æ•°\n",
    "  15 - æ¬¡å›äºˆæ¸¬é–¢æ•°\n",
    "  16 - ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°\n",
    "  \n",
    "Phase 3: å®Ÿè¡Œ\n",
    "  20 - ã‚¤ãƒ™ãƒ³ãƒˆé¸æŠ\n",
    "  21 - ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ«ãƒ¼ãƒ—\n",
    "  22 - æ¬¡å›äºˆæ¸¬å®Ÿè¡Œ\n",
    "  \n",
    "Phase 4: åˆ†æ\n",
    "  30 - åŸºæœ¬çµ±è¨ˆ\n",
    "  31 - ç‰¹å¾´é‡åˆ†æ\n",
    "  32 - æ¬¡å›äºˆæ¸¬ã‚µãƒãƒªãƒ¼\n",
    "  33 - å¯è¦–åŒ–\n",
    "\n",
    "ğŸ”§ CONFIGå®šæ•°(ã‚»ãƒ«01)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "  N_TEST_DAYS: 3          # ãƒ†ã‚¹ãƒˆæ—¥æ•°\n",
    "  N_TRIALS: 20            # Optunaè©¦è¡Œå›æ•°\n",
    "  MIN_FEATURES: 30        # æœ€å°ç‰¹å¾´é‡æ•°\n",
    "  MAX_FEATURES: 80        # æœ€å¤§ç‰¹å¾´é‡æ•°\n",
    "  MIN_EVENT_DAYS: 8       # æœ€ä½ã‚¤ãƒ™ãƒ³ãƒˆæ—¥æ•°\n",
    "\n",
    "ğŸ”„ å®Ÿè¡Œãƒ•ãƒ­ãƒ¼\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "  åˆå›å®Ÿè¡Œ:\n",
    "    01â†’02â†’03â†’04â†’05â†’10â†’11â†’12â†’13â†’14â†’15â†’16â†’20â†’21â†’22â†’30â†’31â†’32\n",
    "  \n",
    "  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´å¾Œ:\n",
    "    20(ã‚¤ãƒ™ãƒ³ãƒˆå¤‰æ›´)â†’21(å†è¨“ç·´)â†’22(å†äºˆæ¸¬)â†’30â†’31â†’32\n",
    "  \n",
    "  åˆ†æã®ã¿:\n",
    "    30â†’31â†’32â†’33\n",
    "\n",
    "ğŸ“¦ ä¸»è¦å¤‰æ•°\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "  df_all          : å…ƒãƒ‡ãƒ¼ã‚¿(ã‚»ãƒ«02)\n",
    "  df_history      : ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´(ã‚»ãƒ«03)\n",
    "  df_base         : åŸºæœ¬ç‰¹å¾´é‡(ã‚»ãƒ«04)\n",
    "  df_merged       : çµ±åˆãƒ‡ãƒ¼ã‚¿(ã‚»ãƒ«05)\n",
    "  top_rank_results: è¨“ç·´çµæœ(ã‚»ãƒ«21)\n",
    "  next_predictions: äºˆæ¸¬çµæœ(ã‚»ãƒ«22)\n",
    "\n",
    "ğŸš¨ é‡è¦ãªæ³¨æ„\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "  âœ“ current_diffé™¤å¤–(ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢)\n",
    "  âœ“ å…¨ãƒ©ã‚°ç‰¹å¾´é‡ã¯shift(1)\n",
    "  âœ“ TOP1/TOP2ã¯ç´”ç²‹ãªãƒ©ãƒ³ã‚¯äºˆæ¸¬(å·®æšæ¡ä»¶ãªã—)\n",
    "  âœ“ å·®æšäºˆæ¸¬ã¯åˆ¥ãƒ¢ãƒ‡ãƒ«ã§å®Ÿè£…äºˆå®š\n",
    "\n",
    "ğŸ“– è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "  è©³ç´°ãªæ§‹é€ ã€ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¯\n",
    "  åˆ¥é€”ä½œæˆã—ãŸã€Œãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ§‹é€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ.mdã€ã‚’å‚ç…§\n",
    "  \n",
    "  ä»–ã®ãƒãƒ£ãƒƒãƒˆã§è³ªå•ã™ã‚‹éš›ã¯ã€ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å…±æœ‰ã—ã¦ãã ã•ã„\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "æœ€çµ‚æ›´æ–°: 2025å¹´ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 3.0\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“š ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ§‹é€ ãƒ¡ãƒ¢ã‚’è¡¨ç¤º\")\n",
    "print(\"è©³ç´°ã¯ä¸Šè¨˜ã®docstringã¾ãŸã¯åˆ¥é€”ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«01: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— + CONFIGè¨­å®š + ã‚¤ãƒ™ãƒ³ãƒˆå®šç¾©\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, mutual_info_classif, mutual_info_regression\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score,\n",
    "    mean_absolute_error, mean_squared_error, roc_auc_score\n",
    ")\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "# XGBoost / LightGBM\n",
    "from lightgbm import LGBMRanker\n",
    "try:\n",
    "    from xgboost import XGBClassifier, XGBRegressor\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  XGBoostãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  LightGBMãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n",
    "\n",
    "# ============================================================\n",
    "# æ‹¡å¼µCONFIGå®šæ•°\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # ===== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ =====\n",
    "    'DB_PATH': 'pachinko_analysis_ãƒãƒ«ãƒãƒ³ãƒ¡ã‚¬ã‚·ãƒ†ã‚£æŸ.db',\n",
    "    \n",
    "    # ===== ãƒ‡ãƒ¼ã‚¿åˆ†å‰² =====\n",
    "    'N_TEST_DAYS': 3,                      # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ—¥æ•°\n",
    "    'N_VALID_DAYS': 2,                     # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æ—¥æ•°\n",
    "    'MIN_EVENT_DAYS': 8,                   # æœ€ä½å¿…è¦ã‚¤ãƒ™ãƒ³ãƒˆæ—¥æ•°\n",
    "    'TRAIN_RATIO': 0.7,                    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ¯”ç‡\n",
    "    'TEST_SIZE': 0.1,                      # ãƒ†ã‚¹ãƒˆæ¯”ç‡\n",
    "    \n",
    "    # ===== ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®šï¼ˆã‚»ãƒ«01ã§ä¸€å…ƒç®¡ç†ï¼‰=====\n",
    "    'TEST_EVENTS': ['1day', '4day', '0day', '40day'],\n",
    "    \n",
    "    # ===== ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ– =====\n",
    "    'N_TRIALS': 20,                        # Optunaè©¦è¡Œå›æ•°\n",
    "    'CV_FOLDS': 5,                         # Cross-validationåˆ†å‰²æ•°\n",
    "    'RANDOM_STATE': 42,\n",
    "    \n",
    "    # ===== ç‰¹å¾´é‡é¸æŠ =====\n",
    "    'MIN_FEATURES': 10,                    # æœ€å°ç‰¹å¾´é‡æ•°\n",
    "    'MAX_FEATURES': 150,                    # æœ€å¤§ç‰¹å¾´é‡æ•°\n",
    "    'LASSO_THRESHOLD': 0.0001,             # Lassoä¿‚æ•°é–¾å€¤\n",
    "    'CORRELATION_THRESHOLD': 0.85,         # ç›¸é–¢é™¤å»é–¾å€¤\n",
    "    'F_TEST_PVALUE': 0.05,                 # Fæ¤œå®špå€¤\n",
    "    'MI_THRESHOLD': 0.01,                  # ç›¸äº’æƒ…å ±é‡é–¾å€¤\n",
    "    \n",
    "    # ===== ãƒ¢ãƒ‡ãƒ«é¸æŠ =====\n",
    "    'MODELS': ['LogisticRegression', 'RandomForest', 'Ridge', 'XGBoost', 'LightGBM'],\n",
    "    'DEFAULT_MODEL': 'RandomForest',\n",
    "    \n",
    "    # ===== ãƒ©ãƒ³ã‚¯å­¦ç¿’ç‰¹æœ‰ =====\n",
    "    'TOP3_ENABLED': True,                  # TOP3ç‰¹åŒ–ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹\n",
    "    'TOP3_WEIGHT': 3.0,                    # TOP3ã¸ã®é‡ã¿\n",
    "    'MIN_RANK': 1,\n",
    "    'MAX_RANK': 11,\n",
    "    \n",
    "    # ===== äºˆæ¸¬ =====\n",
    "    'PREDICTION_CONFIDENCE_THRESHOLD': 0.6,\n",
    "    'ENSEMBLE_METHOD': 'auto_best',         # 'auto_best', 'ensemble', 'manual'\n",
    "    \n",
    "    # ===== å‡ºåŠ› =====\n",
    "    'SAVE_MODELS': True,\n",
    "    'SAVE_RESULTS': True,\n",
    "    'VERBOSE': True,\n",
    "    'CONFIDENCE_HIGH': 0.7,                 # é«˜ä¿¡é ¼åº¦é–¾å€¤\n",
    "    'CONFIDENCE_MEDIUM': 0.5,               # ä¸­ä¿¡é ¼åº¦é–¾å€¤\n",
    "}\n",
    "\n",
    "print(\"âœ… CONFIGè¨­å®šå®Œäº†\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¤ãƒ™ãƒ³ãƒˆå®šç¾©\n",
    "# ============================================================\n",
    "\n",
    "EVENT_DEFINITIONS = {\n",
    "    'is_1day': '1day',\n",
    "    'is_2day': '2day',\n",
    "    'is_3day': '3day',\n",
    "    'is_4day': '4day',\n",
    "    'is_5day': '5day',\n",
    "    'is_6day': '6day',\n",
    "    'is_7day': '7day',\n",
    "    'is_8day': '8day',\n",
    "    'is_9day': '9day',\n",
    "    'is_0day': '0day',\n",
    "    'is_39day': '39day',\n",
    "    'is_40day': '40day',\n",
    "    'is_zorome': 'zorome',\n",
    "    'is_saturday': 'saturday',\n",
    "    'is_sunday': 'sunday',\n",
    "}\n",
    "\n",
    "print(\"âœ… ã‚¤ãƒ™ãƒ³ãƒˆå®šç¾©å®Œäº†\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['CONFIG'] = CONFIG\n",
    "globals()['EVENT_DEFINITIONS'] = EVENT_DEFINITIONS\n",
    "globals()['XGBOOST_AVAILABLE'] = XGBOOST_AVAILABLE\n",
    "globals()['LIGHTGBM_AVAILABLE'] = LIGHTGBM_AVAILABLE\n",
    "\n",
    "# ============================================================\n",
    "# è¨­å®šã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ã€ã‚»ãƒ«01: ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã€‘\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nÃ£â‚¬Ã£â€šÂ¤Ã£Æ’â„¢Ã£Æ’Â³Ã£Æ’Ë†Ã¨Â¨Â­Ã¥Â®Å¡Ã£â‚¬'\")\n",
    "print(f\"  å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆ: {CONFIG['TEST_EVENTS']}\")\n",
    "print(f\"  ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(CONFIG['TEST_EVENTS'])}ç¨®\")\n",
    "\n",
    "print(f\"\\nã€æ©Ÿæ¢°å­¦ç¿’è¨­å®šã€‘\")\n",
    "print(f\"  Optunaè©¦è¡Œæ•°: {CONFIG['N_TRIALS']}\")\n",
    "print(f\"  CVåˆ†å‰²æ•°: {CONFIG['CV_FOLDS']}\")\n",
    "print(f\"  ç‰¹å¾´é‡ç¯„å›²: {CONFIG['MIN_FEATURES']}-{CONFIG['MAX_FEATURES']}\")\n",
    "print(f\"  ãƒ†ã‚¹ãƒˆæ¯”ç‡: {CONFIG['TEST_SIZE']*100:.0f}%\")\n",
    "\n",
    "print(f\"\\nã€ãƒ©ãƒ³ã‚¯å­¦ç¿’è¨­å®šã€‘\")\n",
    "print(f\"  TOP3ç‰¹åŒ–: {'æœ‰åŠ¹' if CONFIG['TOP3_ENABLED'] else 'ç„¡åŠ¹'}\")\n",
    "if CONFIG['TOP3_ENABLED']:\n",
    "    print(f\"  TOP3é‡ã¿: {CONFIG['TOP3_WEIGHT']}å€\")\n",
    "\n",
    "print(\"\\nã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¢ºèªã€‘\")\n",
    "print(f\"  XGBoost: {'âœ… åˆ©ç”¨å¯' if XGBOOST_AVAILABLE else 'âŒ åˆ©ç”¨ä¸å¯'}\")\n",
    "print(f\"  LightGBM: {'âœ… åˆ©ç”¨å¯' if LIGHTGBM_AVAILABLE else 'âŒ åˆ©ç”¨ä¸å¯'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ã‚»ãƒ«01: ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«02: ãƒ‡ãƒ¼ã‚¿èª­è¾¼\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«02: ãƒ‡ãƒ¼ã‚¿èª­è¾¼ã€‘\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 1. CONFIGç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "if 'CONFIG' not in globals():\n",
    "    raise RuntimeError(\"âŒ CONFIGãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚»ãƒ«01ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "DB_PATH = CONFIG.get('DB_PATH', 'pachinko_analysis_ãƒãƒ«ãƒãƒ³ãƒ¡ã‚¬ã‚·ãƒ†ã‚£æŸ.db')\n",
    "TABLE_NAME = 'last_digit_summary_all'\n",
    "\n",
    "print(f\"\\nã€æ¥ç¶šæƒ…å ±ã€‘\")\n",
    "print(f\"  DB_PATH: {DB_PATH}\")\n",
    "print(f\"  TABLE_NAME: {TABLE_NAME}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèªé–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def get_available_tables(db_path):\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    db_path : str\n",
    "        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : ãƒ†ãƒ¼ãƒ–ãƒ«åãƒªã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—\n",
    "        cursor.execute(\n",
    "            \"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\"\n",
    "        )\n",
    "        \n",
    "        tables = [row[0] for row in cursor.fetchall()]\n",
    "        conn.close()\n",
    "        \n",
    "        return tables\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. ãƒ‡ãƒ¼ã‚¿èª­è¾¼é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def load_last_digit_data(db_path, table_name='last_digit_summary_all'):\n",
    "    \"\"\"\n",
    "    last_digit_summaryãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    db_path : str\n",
    "        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "    table_name : str\n",
    "        ãƒ†ãƒ¼ãƒ–ãƒ«å\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : èª­ã¿è¾¼ã¿æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # DBæ¥ç¶š\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿èª­è¾¼\n",
    "        try:\n",
    "            df = pd.read_sql_query(\n",
    "                f\"SELECT * FROM {table_name} ORDER BY date, last_digit\",\n",
    "                conn\n",
    "            )\n",
    "            print(f\"âœ… {table_name}èª­è¾¼: {len(df)}è¡Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ã®èª­è¾¼ã«å¤±æ•—\")\n",
    "            print(f\"   è©³ç´°: {str(e)[:100]}\")\n",
    "            raise\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèªã¨å¤‰æ›\n",
    "        if 'date' in df.columns:\n",
    "            try:\n",
    "                df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "            except:\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # æ—¥ä»˜ç¯„å›²\n",
    "        if 'date' in df.columns:\n",
    "            print(f\"   æ—¥ä»˜ç¯„å›²: {df['date'].min()} ï½ {df['date'].max()}\")\n",
    "        \n",
    "        if 'last_digit' in df.columns:\n",
    "            print(f\"   æœ«å°¾ç¨®é¡: {df['last_digit'].nunique()}ç¨®\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        print(f\"   ãƒ•ã‚¡ã‚¤ãƒ«: {db_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­è¾¼å¤±æ•—\")\n",
    "        print(f\"   è©³ç´°: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª...\")\n",
    "\n",
    "available_tables = get_available_tables(DB_PATH)\n",
    "\n",
    "if not available_tables:\n",
    "    print(f\"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    print(f\"âœ… åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ« ({len(available_tables)}å€‹):\")\n",
    "    for i, table_name in enumerate(available_tables, 1):\n",
    "        print(f\"   {i}. {table_name}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ãƒ‡ãƒ¼ã‚¿èª­è¾¼å®Ÿè¡Œ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰èª­è¾¼ä¸­...\")\n",
    "\n",
    "# å­˜åœ¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚Œã°æœ€åˆã®ã‚‚ã®ã‚’ä½¿ç”¨\n",
    "if available_tables:\n",
    "    # æœ«å°¾ãƒ‡ãƒ¼ã‚¿ã£ã½ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™\n",
    "    last_digit_tables = [t for t in available_tables \n",
    "                        if 'last_digit' in t.lower() or 'digit' in t.lower()]\n",
    "    \n",
    "    if last_digit_tables:\n",
    "        TABLE_NAME = last_digit_tables[0]\n",
    "        print(f\"ä½¿ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}\")\n",
    "    else:\n",
    "        TABLE_NAME = available_tables[0]\n",
    "        print(f\"ä½¿ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME} (æœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«)\")\n",
    "    \n",
    "    try:\n",
    "        df_all = load_last_digit_data(DB_PATH, TABLE_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ã‚¨ãƒ©ãƒ¼: ãƒ†ãƒ¼ãƒ–ãƒ« '{TABLE_NAME}' ã®èª­è¾¼ã«å¤±æ•—\")\n",
    "        print(f\"è©³ç´°: {str(e)[:100]}\")\n",
    "        df_all = None\n",
    "else:\n",
    "    print(f\"âŒ ã‚¨ãƒ©ãƒ¼: åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "    df_all = None\n",
    "\n",
    "# ============================================================\n",
    "# 6. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«02: ãƒ‡ãƒ¼ã‚¿èª­è¾¼å®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "if df_all is not None:\n",
    "    # ========================================================\n",
    "    # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼\n",
    "    # ========================================================\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼\")\n",
    "    \n",
    "    print(f\"   å½¢çŠ¶: {df_all.shape}\")\n",
    "    print(f\"   ãƒ‡ãƒ¼ã‚¿å‹:\")\n",
    "    print(f\"      æ•°å€¤: {(df_all.dtypes == 'int64').sum() + (df_all.dtypes == 'float64').sum()}åˆ—\")\n",
    "    print(f\"      æ–‡å­—åˆ—: {(df_all.dtypes == 'object').sum()}åˆ—\")\n",
    "    \n",
    "    # ãƒ©ãƒ³ã‚¯é–¢é€£åˆ—ã®ç¢ºèª\n",
    "    rank_cols = [col for col in df_all.columns if 'rank' in col.lower()]\n",
    "    if rank_cols:\n",
    "        print(f\"\\n   ãƒ©ãƒ³ã‚¯é–¢é€£åˆ—: {rank_cols}\")\n",
    "    \n",
    "    # é‡è¦åˆ—ã®ãƒã‚§ãƒƒã‚¯\n",
    "    print(f\"\\n   é‡è¦åˆ—ãƒã‚§ãƒƒã‚¯:\")\n",
    "    important_cols = ['last_digit_rank_diff', 'current_diff', 'avg_diff_coins', 'date', 'last_digit']\n",
    "    for col in important_cols:\n",
    "        exists = col in df_all.columns\n",
    "        status = 'âœ…' if exists else 'âŒ'\n",
    "        print(f\"      {status} {col}\")\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã®ãƒã‚§ãƒƒã‚¯\n",
    "    event_flags = [col for col in df_all.columns if col.startswith('is_')]\n",
    "    if event_flags:\n",
    "        print(f\"\\n   ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°: {len(event_flags)}å€‹\")\n",
    "        print(f\"      ä¾‹: {event_flags[:5]}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ\n",
    "    print(f\"\\n   ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:\")\n",
    "    if 'date' in df_all.columns:\n",
    "        print(f\"      æ—¥ä»˜ç¯„å›²: {df_all['date'].min()} ï½ {df_all['date'].max()}\")\n",
    "        print(f\"      æ—¥æ•°: {(df_all['date'].max() - df_all['date'].min()).days}æ—¥\")\n",
    "    \n",
    "    if 'last_digit' in df_all.columns:\n",
    "        print(f\"      æœ«å°¾ç¨®é¡: {df_all['last_digit'].nunique()}ç¨®\")\n",
    "        print(f\"      æœ«å°¾ä¾‹: {df_all['last_digit'].unique()[:5].tolist()}\")\n",
    "    \n",
    "    if 'avg_diff_coins' in df_all.columns:\n",
    "        print(f\"      å·®æšå¹³å‡: {df_all['avg_diff_coins'].mean():.1f}æš\")\n",
    "        print(f\"      å·®æšç¯„å›²: {df_all['avg_diff_coins'].min():.1f} ï½ {df_all['avg_diff_coins'].max():.1f}æš\")\n",
    "    \n",
    "    # ========================================================\n",
    "    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\n",
    "    # ========================================================\n",
    "    \n",
    "    globals()['df_all'] = df_all\n",
    "    globals()['TABLE_NAME'] = TABLE_NAME\n",
    "    \n",
    "    print(f\"\\n  ğŸ“¦ ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²:\")\n",
    "    print(f\"     - df_all: ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿\")\n",
    "    print(f\"     - TABLE_NAME: èª­è¾¼å…ƒãƒ†ãƒ¼ãƒ–ãƒ«å\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâŒ ãƒ‡ãƒ¼ã‚¿èª­è¾¼å¤±æ•—\")\n",
    "    print(f\"   df_all = None\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡ç”Ÿæˆ03ï½05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«03-å…±é€š: prevç³»ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢æ¸ˆã¿ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«03-å…±é€šã€‘prevç³»ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°å®šç¾©\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°1: ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´è¾æ›¸ã®æ§‹ç¯‰\n",
    "# ============================================================\n",
    "\n",
    "def build_event_history(df, available_events, metric_cols):\n",
    "    \"\"\"\n",
    "    ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿæ™‚ã®å±¥æ­´ã‚’è¾æ›¸ã§æ§‹ç¯‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        date, digit_num, is_* ãƒ•ãƒ©ã‚°ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿\n",
    "    available_events : list\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåãƒªã‚¹ãƒˆ\n",
    "    metric_cols : list\n",
    "        è¨˜éŒ²å¯¾è±¡ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ©ãƒ \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : event_history = {(event, digit_num): [å±¥æ­´ãƒªã‚¹ãƒˆ]}\n",
    "    \"\"\"\n",
    "    \n",
    "    event_history = {}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        current_date = row['date']\n",
    "        current_digit = row['digit_num']\n",
    "        \n",
    "        for event in available_events:\n",
    "            flag_col = f'is_{event}'\n",
    "            \n",
    "            if flag_col in df.columns and row[flag_col] == 1:\n",
    "                key = (event, current_digit)\n",
    "                \n",
    "                if key not in event_history:\n",
    "                    event_history[key] = []\n",
    "                \n",
    "                # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿæ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²\n",
    "                event_record = {'date': current_date}\n",
    "                for metric in metric_cols:\n",
    "                    if metric in df.columns:\n",
    "                        event_record[metric] = row[metric]\n",
    "                \n",
    "                event_history[key].append(event_record)\n",
    "    \n",
    "    return event_history\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°2: prevåŸºæœ¬ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆprev_1, prev_2, prev_3ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_prev_basic_features(df, available_events, metric_cols):\n",
    "    \"\"\"\n",
    "    å‰å›ã€å‰ã€…å›ã€å‰ã€…ã€…å›ã®ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ç‰¹å¾´é‡ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿\n",
    "    available_events : list\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåãƒªã‚¹ãƒˆ\n",
    "    metric_cols : list\n",
    "        è¨˜éŒ²å¯¾è±¡ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ©ãƒ \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : prev_1_*, prev_2_*, prev_3_* ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out = df_out.sort_values(['date', 'digit_num']).reset_index(drop=True)\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã®æ§‹ç¯‰\n",
    "    event_history = build_event_history(df_out, available_events, metric_cols)\n",
    "    \n",
    "    # prev_1, prev_2, prev_3 ã®ç”Ÿæˆ\n",
    "    feature_rows = []\n",
    "    basic_feature_count = 0\n",
    "    \n",
    "    for idx, row in df_out.iterrows():\n",
    "        current_digit = row['digit_num']\n",
    "        row_features = {}\n",
    "        \n",
    "        for event in available_events:\n",
    "            key = (event, current_digit)\n",
    "            \n",
    "            # å‰å›(1), å‰ã€…å›(2), å‰ã€…ã€…å›(3)\n",
    "            for prev_n in [1, 2, 3]:\n",
    "                if key in event_history and len(event_history[key]) > prev_n:\n",
    "                    prev_record = event_history[key][-prev_n]\n",
    "                    \n",
    "                    for metric in metric_cols:\n",
    "                        if metric in prev_record:\n",
    "                            feature_name = f'prev_{prev_n}_{metric}'\n",
    "                            row_features[feature_name] = prev_record[metric]\n",
    "                            basic_feature_count += 1\n",
    "        \n",
    "        feature_rows.append(row_features)\n",
    "    \n",
    "    features_df = pd.DataFrame(feature_rows)\n",
    "    df_out = pd.concat([df_out.reset_index(drop=True), \n",
    "                        features_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    print(f\"  âœ… prevåŸºæœ¬ç‰¹å¾´é‡: {len(features_df.columns)}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°3: prevå¤‰åŒ–é‡ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆprev_*_changeï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_prev_change_features(df, available_events, metric_cols):\n",
    "    \"\"\"\n",
    "    prev_1 ã¨ prev_2 ã®å·®åˆ†ã‹ã‚‰å¤‰åŒ–é‡ç‰¹å¾´é‡ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        prevåŸºæœ¬ç‰¹å¾´é‡ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿\n",
    "    available_events : list\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåãƒªã‚¹ãƒˆ\n",
    "    metric_cols : list\n",
    "        å¯¾è±¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ©ãƒ \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : prev_*_change ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out = df_out.sort_values(['date', 'digit_num']).reset_index(drop=True)\n",
    "    \n",
    "    event_history = build_event_history(df_out, available_events, metric_cols)\n",
    "    \n",
    "    feature_rows = []\n",
    "    change_feature_count = 0\n",
    "    \n",
    "    for idx, row in df_out.iterrows():\n",
    "        current_digit = row['digit_num']\n",
    "        row_features = {}\n",
    "        \n",
    "        for event in available_events:\n",
    "            key = (event, current_digit)\n",
    "            \n",
    "            if key in event_history and len(event_history[key]) >= 2:\n",
    "                # prev_1 ã¨ prev_2 ã®å·®ã‚’è¨ˆç®—\n",
    "                prev_1 = event_history[key][-1]\n",
    "                prev_2 = event_history[key][-2]\n",
    "                \n",
    "                for metric in metric_cols:\n",
    "                    if metric in prev_1 and metric in prev_2:\n",
    "                        change = prev_1[metric] - prev_2[metric]\n",
    "                        feature_name = f'prev_1_{metric}_change'\n",
    "                        row_features[feature_name] = change\n",
    "                        change_feature_count += 1\n",
    "        \n",
    "        feature_rows.append(row_features)\n",
    "    \n",
    "    features_df = pd.DataFrame(feature_rows)\n",
    "    df_out = pd.concat([df_out.reset_index(drop=True), \n",
    "                        features_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    print(f\"  âœ… prevå¤‰åŒ–é‡ç‰¹å¾´é‡: {len(features_df.columns)}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°4: prevçµ±è¨ˆé‡ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆprev_max/min/avg/std_*ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_prev_stat_features(df, available_events, metric_cols, windows=[3, 5]):\n",
    "    \"\"\"\n",
    "    éå»Nå›ã®æœ€å¤§å€¤ãƒ»æœ€å°å€¤ãƒ»å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    âš ï¸ ã€é‡è¦ã€‘metric_cols ã¯éå»ã‚¤ãƒ™ãƒ³ãƒˆæ™‚ã®å€¤ã®ã¿ï¼ˆå½“æ—¥å€¤ã¯é™¤å¤–ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿\n",
    "    available_events : list\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåãƒªã‚¹ãƒˆ\n",
    "    metric_cols : list\n",
    "        å¯¾è±¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ©ãƒ ï¼ˆãƒ©ãƒ³ã‚¯ç³»ã®ã¿æ¨å¥¨ï¼‰\n",
    "    windows : list\n",
    "        é›†è¨ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: [3, 5]ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : prev_max/min/avg/std_* ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out = df_out.sort_values(['date', 'digit_num']).reset_index(drop=True)\n",
    "    \n",
    "    event_history = build_event_history(df_out, available_events, metric_cols)\n",
    "    \n",
    "    feature_rows = []\n",
    "    stat_feature_count = 0\n",
    "    \n",
    "    for idx, row in df_out.iterrows():\n",
    "        current_digit = row['digit_num']\n",
    "        row_features = {}\n",
    "        \n",
    "        for event in available_events:\n",
    "            key = (event, current_digit)\n",
    "            \n",
    "            for window in windows:\n",
    "                if key in event_history and len(event_history[key]) >= window:\n",
    "                    recent_records = event_history[key][-window:]\n",
    "                    \n",
    "                    for metric in metric_cols:\n",
    "                        values = [r[metric] for r in recent_records if metric in r]\n",
    "                        \n",
    "                        if len(values) > 0:\n",
    "                            # æœ€å¤§å€¤\n",
    "                            feature_name = f'prev_max{window}_{metric}'\n",
    "                            row_features[feature_name] = max(values)\n",
    "                            stat_feature_count += 1\n",
    "                            \n",
    "                            # æœ€å°å€¤\n",
    "                            feature_name = f'prev_min{window}_{metric}'\n",
    "                            row_features[feature_name] = min(values)\n",
    "                            stat_feature_count += 1\n",
    "                            \n",
    "                            # å¹³å‡å€¤\n",
    "                            feature_name = f'prev_avg{window}_{metric}'\n",
    "                            row_features[feature_name] = np.mean(values)\n",
    "                            stat_feature_count += 1\n",
    "                            \n",
    "                            # æ¨™æº–åå·®\n",
    "                            feature_name = f'prev_std{window}_{metric}'\n",
    "                            row_features[feature_name] = np.std(values)\n",
    "                            stat_feature_count += 1\n",
    "        \n",
    "        feature_rows.append(row_features)\n",
    "    \n",
    "    features_df = pd.DataFrame(feature_rows)\n",
    "    df_out = pd.concat([df_out.reset_index(drop=True), \n",
    "                        features_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    print(f\"  âœ… prevçµ±è¨ˆé‡ç‰¹å¾´é‡: {len(features_df.columns)}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°5: prevãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆprev_*_trendï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_prev_trend_features(df, available_events, metric_cols=['avg_diff_coins', 'last_digit_rank_diff']):\n",
    "    \"\"\"\n",
    "    éå»3å›ã®å·®æšãƒ»ãƒ©ãƒ³ã‚¯æ”¹å–„ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿\n",
    "    available_events : list\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåãƒªã‚¹ãƒˆ\n",
    "    metric_cols : list\n",
    "        ãƒˆãƒ¬ãƒ³ãƒ‰å¯¾è±¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : prev_*_trend_3 ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out = df_out.sort_values(['date', 'digit_num']).reset_index(drop=True)\n",
    "    \n",
    "    event_history = build_event_history(df_out, available_events, metric_cols)\n",
    "    \n",
    "    feature_rows = []\n",
    "    trend_feature_count = 0\n",
    "    \n",
    "    for idx, row in df_out.iterrows():\n",
    "        current_digit = row['digit_num']\n",
    "        row_features = {}\n",
    "        \n",
    "        for event in available_events:\n",
    "            key = (event, current_digit)\n",
    "            \n",
    "            # å·®æšãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆéå»3å›ï¼‰\n",
    "            if key in event_history and len(event_history[key]) >= 3:\n",
    "                recent_diff = [r['avg_diff_coins'] for r in event_history[key][-3:] \n",
    "                              if 'avg_diff_coins' in r]\n",
    "                \n",
    "                if len(recent_diff) == 3:\n",
    "                    if recent_diff[2] > recent_diff[1] > recent_diff[0]:\n",
    "                        trend = 1  # ä¸Šæ˜‡\n",
    "                    elif recent_diff[2] < recent_diff[1] < recent_diff[0]:\n",
    "                        trend = -1  # ä¸‹é™\n",
    "                    else:\n",
    "                        trend = 0  # æ¨ªã°ã„\n",
    "                    \n",
    "                    row_features[f'prev_diff_trend_3'] = trend\n",
    "                    trend_feature_count += 1\n",
    "            \n",
    "            # ãƒ©ãƒ³ã‚¯æ”¹å–„ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆéå»3å›ï¼‰\n",
    "            if key in event_history and len(event_history[key]) >= 3:\n",
    "                recent_ranks = [r['last_digit_rank_diff'] for r in event_history[key][-3:] \n",
    "                               if 'last_digit_rank_diff' in r]\n",
    "                \n",
    "                if len(recent_ranks) == 3 and all(isinstance(r, (int, float)) for r in recent_ranks):\n",
    "                    # ãƒ©ãƒ³ã‚¯æ”¹å–„: æ•°å€¤ãŒå°ã•ããªã£ã¦ã„ã‚‹\n",
    "                    if recent_ranks[2] < recent_ranks[1] < recent_ranks[0]:\n",
    "                        row_features[f'prev_rank_improving_trend_3'] = 1\n",
    "                        trend_feature_count += 1\n",
    "                    elif recent_ranks[2] > recent_ranks[1] > recent_ranks[0]:\n",
    "                        row_features[f'prev_rank_declining_trend_3'] = 1\n",
    "                        trend_feature_count += 1\n",
    "        \n",
    "        feature_rows.append(row_features)\n",
    "    \n",
    "    features_df = pd.DataFrame(feature_rows)\n",
    "    df_out = pd.concat([df_out.reset_index(drop=True), \n",
    "                        features_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    print(f\"  âœ… prevãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡: {len(features_df.columns)}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«03-å…±é€š: ã™ã¹ã¦ã®prevç³»é–¢æ•°ã‚’å®šç¾©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«03: çµ±åˆprevç³»ç‰¹å¾´é‡ç”Ÿæˆï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢æ¸ˆã¿ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«03ã€‘çµ±åˆprevç³»ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# ============================================================\n",
    "# 1. df_all ã®ç¢ºèªï¼ˆã‚»ãƒ«02ã‹ã‚‰ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "if 'df_all' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_all ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«02ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = df_all.copy()\n",
    "print(f\"âœ… df_all: {df_out.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. dateå‹ã®çµ±ä¸€ï¼ˆYYYYMMDDæ–‡å­—åˆ—ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘dateå‹ã®çµ±ä¸€\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# date ã‚’ YYYYMMDDæ–‡å­—åˆ—ã«çµ±ä¸€\n",
    "if df_out['date'].dtype != 'object':\n",
    "    df_out['date'] = pd.to_datetime(df_out['date']).dt.strftime('%Y%m%d')\n",
    "else:\n",
    "    df_out['date'] = df_out['date'].astype(str)\n",
    "\n",
    "print(f\"âœ… dateå‹çµ±ä¸€: {df_out['date'].dtype} (ä¾‹: {df_out['date'].iloc[0]})\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. event_calendar ãƒ†ãƒ¼ãƒ–ãƒ«ã®èª­è¾¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘event_calendarãƒ†ãƒ¼ãƒ–ãƒ«ã®èª­è¾¼\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    DB_PATH = CONFIG.get('DB_PATH', 'pachinko_analysis_ãƒãƒ«ãƒãƒ³ãƒ¡ã‚¬ã‚·ãƒ†ã‚£æŸ.db')\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    \n",
    "    df_events = pd.read_sql_query(\n",
    "        \"SELECT * FROM event_calendar ORDER BY date\",\n",
    "        conn\n",
    "    )\n",
    "    conn.close()\n",
    "    \n",
    "    # event_calendar ã® date ã‚‚çµ±ä¸€\n",
    "    if df_events['date'].dtype != 'object':\n",
    "        df_events['date'] = pd.to_datetime(df_events['date']).dt.strftime('%Y%m%d')\n",
    "    else:\n",
    "        df_events['date'] = df_events['date'].astype(str)\n",
    "    \n",
    "    print(f\"âœ… event_calendarèª­è¾¼: {len(df_events)}è¡Œ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# ============================================================\n",
    "# 4. event_calendarã¨ã®JOIN\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘event_calendarã¨ã®JOIN\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = df_out.merge(df_events, on='date', how='left')\n",
    "\n",
    "print(f\"âœ… JOINå¾Œ: {df_out.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã®ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "event_flags = [col for col in df_out.columns if col.startswith('is_')]\n",
    "available_events = [col.replace('is_', '') for col in event_flags]\n",
    "\n",
    "print(f\"âœ… ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°æ•°: {len(event_flags)}å€‹\")\n",
    "print(f\"âœ… åˆ©ç”¨å¯èƒ½ã‚¤ãƒ™ãƒ³ãƒˆ: {len(available_events)}å€‹\")\n",
    "print(f\"   ä¾‹: {available_events[:10]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. æœ«å°¾ç•ªå·ï¼ˆdigit_numï¼‰ã®ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘æœ«å°¾ç•ªå·ï¼ˆdigit_numï¼‰ã®ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'last_digit' in df_out.columns:\n",
    "    # last_digit ã‚’ digit_num ã«å¤‰æ›\n",
    "    digit_mapping = {\n",
    "        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4,\n",
    "        '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,\n",
    "        'ã‚¾ãƒ­ç›®': 10\n",
    "    }\n",
    "    \n",
    "    df_out['digit_num'] = df_out['last_digit'].map(digit_mapping)\n",
    "    print(f\"âœ… digit_numç”Ÿæˆ: {df_out['digit_num'].dtype}\")\n",
    "else:\n",
    "    raise RuntimeError(\"âŒ last_digit ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—7ã€‘å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# âš ï¸ ã€é‡è¦ã€‘å½“æ—¥å€¤ï¼ˆãƒªãƒ¼ã‚¯ï¼‰ã‚’é¿ã‘ã‚‹ãŸã‚ã€æœ€å¾Œ_rankã®ã¿ã‚’è¨˜éŒ²\n",
    "# avg_*, win_rate, high_profit_rateãªã©ã¯å½“æ—¥ç¢ºå®šå€¤ãªã®ã§é™¤å¤–\n",
    "metric_cols = [\n",
    "    'last_digit_rank_diff',  # âœ… ãƒ©ãƒ³ã‚¯æƒ…å ±ã®ã¿ï¼ˆéå»ã‚¤ãƒ™ãƒ³ãƒˆæ™‚ã®ãƒ©ãƒ³ã‚¯ã‚’è¨˜éŒ²ï¼‰\n",
    "    'last_digit_rank_games'  # âœ… ã‚²ãƒ¼ãƒ æ•°ãƒ©ãƒ³ã‚¯\n",
    "    # âŒ avg_diff_coins, avg_games, win_rate, high_profit_rate ã¯é™¤å¤–ï¼ˆå½“æ—¥ç¢ºå®šå€¤ï¼‰\n",
    "]\n",
    "\n",
    "stat_windows = [3, 5]\n",
    "trend_metrics = ['avg_diff_coins', 'last_digit_rank_diff']\n",
    "\n",
    "print(f\"ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ©ãƒ : {len(metric_cols)}å€‹\")\n",
    "print(f\"çµ±è¨ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {stat_windows}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. prevåŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—8ã€‘prevåŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_prev_basic_features(df_out, available_events, metric_cols)\n",
    "\n",
    "# ============================================================\n",
    "# 9. prevå¤‰åŒ–é‡ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—9ã€‘prevå¤‰åŒ–é‡ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_prev_change_features(df_out, available_events, metric_cols)\n",
    "\n",
    "# ============================================================\n",
    "# 10. prevçµ±è¨ˆé‡ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—10ã€‘prevçµ±è¨ˆé‡ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_prev_stat_features(df_out, available_events, metric_cols, windows=stat_windows)\n",
    "\n",
    "# ============================================================\n",
    "# 11. prevãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—11ã€‘prevãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_prev_trend_features(df_out, available_events, metric_cols=trend_metrics)\n",
    "\n",
    "# ============================================================\n",
    "# 12. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—12ã€‘ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "globals()['df_merged'] = df_out\n",
    "globals()['available_events'] = available_events\n",
    "\n",
    "print(f\"âœ… df_merged, available_events ã‚’ç™»éŒ²\")\n",
    "\n",
    "# ============================================================\n",
    "# 13. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«03: çµ±åˆprevç³»ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nã€å‡¦ç†çµæœã€‘\")\n",
    "print(f\"  å…¥åŠ›ï¼ˆdf_allï¼‰: {df_all.shape}\")\n",
    "print(f\"  å‡ºåŠ›ï¼ˆdf_mergedï¼‰: {df_out.shape}\")\n",
    "print(f\"  æ–°è¦ã‚«ãƒ©ãƒ æ•°: {df_out.shape[1] - df_all.shape[1]}\")\n",
    "\n",
    "# ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ\n",
    "prev_basic = [col for col in df_out.columns if col.startswith('prev_') \n",
    "              and any(s in col for s in ['_avg_diff_coins', '_avg_games', '_win_rate', \n",
    "                                         '_high_profit_rate', '_last_digit_rank_diff', '_last_digit_rank_games'])\n",
    "              and not any(s in col for s in ['_change', '_max', '_min', '_avg', '_std', '_trend'])]\n",
    "prev_change = [col for col in df_out.columns if '_change' in col and col.startswith('prev_')]\n",
    "prev_stat = [col for col in df_out.columns if any(s in col for s in ['_max', '_min', '_avg', '_std']) and col.startswith('prev_')]\n",
    "prev_trend = [col for col in df_out.columns if '_trend' in col and col.startswith('prev_')]\n",
    "\n",
    "prev_total = len([c for c in df_out.columns if c.startswith('prev_')])\n",
    "\n",
    "print(f\"\\nã€ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥ã€‘\")\n",
    "print(f\"  prevåŸºæœ¬ï¼ˆprev_1/2/3_*ï¼‰: {len(prev_basic)}å€‹\")\n",
    "print(f\"  prevå¤‰åŒ–é‡ï¼ˆprev_*_changeï¼‰: {len(prev_change)}å€‹\")\n",
    "print(f\"  prevçµ±è¨ˆé‡ï¼ˆprev_max/min/avg/std_*ï¼‰: {len(prev_stat)}å€‹\")\n",
    "print(f\"  prevãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆprev_*_trendï¼‰: {len(prev_trend)}å€‹\")\n",
    "print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"  åˆè¨ˆprev_* ç‰¹å¾´é‡: {prev_total}å€‹\")\n",
    "\n",
    "print(f\"\\nã€é‡è¦: ãƒªãƒ¼ã‚¯é˜²æ­¢ã€‘\")\n",
    "print(f\"  âœ… å½“æ—¥å€¤ï¼ˆmax_games, min_gamesï¼‰ã¯é™¤å¤–\")\n",
    "print(f\"  âœ… ã™ã¹ã¦ã®prev_*ã¯éå»ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã‹ã‚‰ã®ã¿æ´¾ç”Ÿ\")\n",
    "print(f\"  âœ… ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿæ™‚ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¨˜éŒ²ï¼ˆå½“æ—¥å€¤ã¯å«ã¾ãªã„ï¼‰\")\n",
    "\n",
    "print(f\"\\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘\")\n",
    "print(f\"  ã‚»ãƒ«04-å…±é€š: alldayç³»ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°ã®ç¢ºèª\")\n",
    "print(f\"  ã‚»ãƒ«04: alldayç³»çµ±åˆç‰¹å¾´é‡ç”Ÿæˆå®Ÿè¡Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«04-å…±é€š: å…±é€šåŒ–ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°ï¼ˆãƒ©ã‚°ãƒ»ç§»å‹•å¹³å‡ãƒ»å¤‰åŒ–é‡ãªã©ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«04-å…±é€šã€‘å…±é€šåŒ–ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°å®šç¾©\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°1: ãƒ©ã‚°ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆæ—¥ä»˜å˜ä½ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_lag_features(df, target_cols, lag_days=[1, 2, 3, 4, 7, 14, 21, 28]):\n",
    "    \"\"\"\n",
    "    æœ«å°¾ã”ã¨ã®ãƒ©ã‚°ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆå½“æ—¥ã‚’é™¤ãéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆ1æ—¥11è¡Œï¼‰\n",
    "    target_cols : list\n",
    "        ãƒ©ã‚°å¯¾è±¡ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆ\n",
    "    lag_days : list\n",
    "        ãƒ©ã‚°æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: [1,2,3,4,7,14,21,28]ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : allday_lagX_* ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    lag_feature_count = 0\n",
    "    \n",
    "    for target_col in target_cols:\n",
    "        for lag_day in lag_days:\n",
    "            # 1æ—¥ = 11è¡Œãªã®ã§ã€lag_dayæ—¥å‰ = lag_day * 11è¡Œå‰\n",
    "            shift_amount = lag_day * 11\n",
    "            \n",
    "            df_out[f'allday_lag{lag_day}_{target_col}'] = (\n",
    "                df_out.groupby('digit_num')[target_col]\n",
    "                .shift(shift_amount)\n",
    "                .values\n",
    "            )\n",
    "            lag_feature_count += 1\n",
    "    \n",
    "    print(f\"  âœ… ãƒ©ã‚°ç‰¹å¾´é‡: {lag_feature_count}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°2: ç§»å‹•å¹³å‡ãƒ»æ¨™æº–åå·®ã®ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "def create_moving_avg_std_features(\n",
    "    df, target_cols, \n",
    "    window_sizes=[1, 2, 3, 4, 7, 14, 21, 28]\n",
    "):\n",
    "    \"\"\"\n",
    "    æœ«å°¾ã”ã¨ã®ç§»å‹•å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’ç”Ÿæˆï¼ˆå½“æ—¥ã‚’é™¤ãéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆ1æ—¥11è¡Œï¼‰\n",
    "    target_cols : list\n",
    "        å¯¾è±¡ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆ\n",
    "    window_sizes : list\n",
    "        ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: [1,2,3,4,7,14,21,28]ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : allday_ma/std_* ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out = df_out.sort_values(['date', 'digit_num']).reset_index(drop=True)\n",
    "    \n",
    "    ma_feature_count = 0\n",
    "    std_feature_count = 0\n",
    "    \n",
    "    for target_col in target_cols:\n",
    "        for window in window_sizes:\n",
    "            # shift(1)ã§å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¦ã‹ã‚‰ç§»å‹•å¹³å‡ã‚’è¨ˆç®—\n",
    "            df_out[f'allday_ma{window}_{target_col}'] = (\n",
    "                df_out.groupby('digit_num')[target_col]\n",
    "                .shift(1)  # å½“æ—¥ã‚’é™¤å¤–\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .mean()\n",
    "                .values\n",
    "            )\n",
    "            ma_feature_count += 1\n",
    "            \n",
    "            # æ¨™æº–åå·®\n",
    "            df_out[f'allday_std{window}_{target_col}'] = (\n",
    "                df_out.groupby('digit_num')[target_col]\n",
    "                .shift(1)  # å½“æ—¥ã‚’é™¤å¤–\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .std()\n",
    "                .values\n",
    "            )\n",
    "            std_feature_count += 1\n",
    "    \n",
    "    print(f\"  âœ… ç§»å‹•å¹³å‡ç‰¹å¾´é‡: {ma_feature_count}å€‹\")\n",
    "    print(f\"  âœ… æ¨™æº–åå·®ç‰¹å¾´é‡: {std_feature_count}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°3: å¤‰åŒ–é‡ï¼ˆå·®åˆ†ãƒ»å¤‰åŒ–ç‡ï¼‰ã®ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "def create_change_features(\n",
    "    df, target_cols,\n",
    "    change_lags=[1, 7, 14]\n",
    "):\n",
    "    \"\"\"\n",
    "    lag_dayæ—¥å‰ã¨ã®æ¯”è¼ƒã§å¤‰åŒ–é‡ã‚’ç”Ÿæˆï¼ˆå·®åˆ†ãƒ»å¤‰åŒ–ç‡ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ãƒ©ã‚°ç‰¹å¾´é‡ãŒæ—¢ã«è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿\n",
    "    target_cols : list\n",
    "        å¯¾è±¡ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆ\n",
    "    change_lags : list\n",
    "        æ¯”è¼ƒãƒ©ã‚°æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: [1, 7, 14]ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : allday_lagX_*_diff/pct ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    change_feature_count = 0\n",
    "    \n",
    "    for target_col in target_cols:\n",
    "        for lag_day in change_lags:\n",
    "            lag_col = f'allday_lag{lag_day}_{target_col}'\n",
    "            \n",
    "            if lag_col in df_out.columns:\n",
    "                # å·®åˆ†: å½“æ—¥å€¤ - lagæ—¥å‰å€¤\n",
    "                df_out[f'allday_lag{lag_day}_{target_col}_diff'] = (\n",
    "                    df_out[target_col] - df_out[lag_col]\n",
    "                )\n",
    "                change_feature_count += 1\n",
    "                \n",
    "                # å¤‰åŒ–ç‡: (å½“æ—¥å€¤ - lagæ—¥å‰å€¤) / |lagæ—¥å‰å€¤|\n",
    "                df_out[f'allday_lag{lag_day}_{target_col}_pct'] = (\n",
    "                    (df_out[target_col] - df_out[lag_col]) / \n",
    "                    (df_out[lag_col].abs() + 1e-10)  # ã‚¼ãƒ­é™¤ç®—å¯¾ç­–\n",
    "                )\n",
    "                change_feature_count += 1\n",
    "    \n",
    "    print(f\"  âœ… å¤‰åŒ–é‡ç‰¹å¾´é‡: {change_feature_count}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°4: ãƒ©ãƒ³ã‚¯å¤‰åŒ–ç‰¹å¾´é‡ã®ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "def create_rank_change_features(\n",
    "    df, rank_col='last_digit_rank_diff',\n",
    "    change_lags=[1, 7, 14],\n",
    "    stat_windows=[7, 14, 28]\n",
    "):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ã‚¯ã‚«ãƒ©ãƒ ã®å¤‰åŒ–é‡ãƒ»çµ±è¨ˆé‡ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ãƒ©ã‚°ç‰¹å¾´é‡ãŒæ—¢ã«è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿\n",
    "    rank_col : str\n",
    "        ãƒ©ãƒ³ã‚¯ã‚«ãƒ©ãƒ åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'last_digit_rank_diff'ï¼‰\n",
    "    change_lags : list\n",
    "        æ¯”è¼ƒãƒ©ã‚°æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: [1, 7, 14]ï¼‰\n",
    "    stat_windows : list\n",
    "        ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: [7, 14, 28]ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : allday_rank_change_*, allday_rank_max/min/std_* ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    rank_feature_count = 0\n",
    "    \n",
    "    if rank_col not in df_out.columns:\n",
    "        print(f\"  âš ï¸  {rank_col} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        return df_out\n",
    "    \n",
    "    # ãƒ©ãƒ³ã‚¯å¤‰åŒ–é‡\n",
    "    for lag_day in change_lags:\n",
    "        lag_col = f'allday_lag{lag_day}_{rank_col}'\n",
    "        \n",
    "        if lag_col in df_out.columns:\n",
    "            # ãƒ©ãƒ³ã‚¯å·®: å½“æ—¥ãƒ©ãƒ³ã‚¯ - lagæ—¥å‰ãƒ©ãƒ³ã‚¯\n",
    "            # (ãƒ©ãƒ³ã‚¯ãŒå°ã•ã„æ–¹ãŒè‰¯ã„)\n",
    "            df_out[f'allday_rank_change{lag_day}'] = (\n",
    "                df_out[rank_col] - df_out[lag_col]\n",
    "            )\n",
    "            rank_feature_count += 1\n",
    "    \n",
    "    # ãƒ©ãƒ³ã‚¯çµ±è¨ˆé‡\n",
    "    for window in stat_windows:\n",
    "        df_out[f'allday_rank_max{window}'] = (\n",
    "            df_out.groupby('digit_num')[rank_col]\n",
    "            .shift(1)\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .max()\n",
    "            .values\n",
    "        )\n",
    "        rank_feature_count += 1\n",
    "        \n",
    "        df_out[f'allday_rank_min{window}'] = (\n",
    "            df_out.groupby('digit_num')[rank_col]\n",
    "            .shift(1)\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .min()\n",
    "            .values\n",
    "        )\n",
    "        rank_feature_count += 1\n",
    "        \n",
    "        df_out[f'allday_rank_std{window}'] = (\n",
    "            df_out.groupby('digit_num')[rank_col]\n",
    "            .shift(1)\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .std()\n",
    "            .values\n",
    "        )\n",
    "        rank_feature_count += 1\n",
    "    \n",
    "    print(f\"  âœ… ãƒ©ãƒ³ã‚¯å¤‰åŒ–ç‰¹å¾´é‡: {rank_feature_count}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°5: prevç³»ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_prev_features(\n",
    "    df, available_events,\n",
    "    metric_cols=['avg_diff_coins', 'avg_games', 'win_rate', \n",
    "                 'high_profit_rate', 'last_digit_rank_diff', \n",
    "                 'last_digit_rank_games'],\n",
    "    exclude_cols=['max_games', 'min_games']  # ãƒªãƒ¼ã‚¯é˜²æ­¢\n",
    "):\n",
    "    \"\"\"\n",
    "    ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã‹ã‚‰éå»ãƒ‡ãƒ¼ã‚¿ã®prev_*ç‰¹å¾´é‡ã‚’ç”Ÿæˆ\n",
    "    å½“æ—¥å€¤ã¯é™¤å¤–ã—ã¦ãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°(is_*)ãŒå«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿\n",
    "    available_events : list\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåãƒªã‚¹ãƒˆ\n",
    "    metric_cols : list\n",
    "        ç‰¹å¾´é‡å¯¾è±¡ã‚«ãƒ©ãƒ \n",
    "    exclude_cols : list\n",
    "        ãƒªãƒ¼ã‚¯é˜²æ­¢ã®ãŸã‚æœ€åˆã‹ã‚‰ç”Ÿæˆã—ãªã„ã‚«ãƒ©ãƒ \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : prev_* ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out = df_out.sort_values(['date', 'digit_num']).reset_index(drop=True)\n",
    "    \n",
    "    # ãƒªãƒ¼ã‚¯é˜²æ­¢: å¯¾è±¡ã‚«ãƒ©ãƒ ã‹ã‚‰é™¤å¤–ã‚«ãƒ©ãƒ ã‚’å‰Šé™¤\n",
    "    metric_cols = [col for col in metric_cols if col not in exclude_cols]\n",
    "    \n",
    "    event_history = {}\n",
    "    prev_feature_count = 0\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã®æ§‹ç¯‰\n",
    "    for idx, row in df_out.iterrows():\n",
    "        current_date = row['date']\n",
    "        current_digit = row['digit_num']\n",
    "        \n",
    "        for event in available_events:\n",
    "            flag_col = f'is_{event}'\n",
    "            \n",
    "            if flag_col in df_out.columns and row[flag_col] == 1:\n",
    "                key = (event, current_digit)\n",
    "                \n",
    "                if key not in event_history:\n",
    "                    event_history[key] = []\n",
    "                \n",
    "                event_record = {'date': current_date}\n",
    "                for metric in metric_cols:\n",
    "                    if metric in df_out.columns:\n",
    "                        event_record[metric] = row[metric]\n",
    "                \n",
    "                event_history[key].append(event_record)\n",
    "    \n",
    "    # prev_1, prev_2, prev_3 ã®åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "    feature_rows = []\n",
    "    \n",
    "    for idx, row in df_out.iterrows():\n",
    "        current_digit = row['digit_num']\n",
    "        row_features = {}\n",
    "        \n",
    "        for event in available_events:\n",
    "            key = (event, current_digit)\n",
    "            \n",
    "            # prev_1, prev_2, prev_3 (å‰å›ã€å‰ã€…å›ã€å‰ã€…ã€…å›)\n",
    "            for prev_n in [1, 2, 3]:\n",
    "                if key in event_history and len(event_history[key]) > prev_n:\n",
    "                    prev_record = event_history[key][-prev_n]\n",
    "                    \n",
    "                    for metric in metric_cols:\n",
    "                        if metric in prev_record:\n",
    "                            feature_name = f'prev_{prev_n}_{metric}'\n",
    "                            row_features[feature_name] = prev_record[metric]\n",
    "                            prev_feature_count = prev_feature_count + 1 if feature_name not in row_features else prev_feature_count\n",
    "        \n",
    "        feature_rows.append(row_features)\n",
    "    \n",
    "    features_df = pd.DataFrame(feature_rows)\n",
    "    df_out = pd.concat([df_out.reset_index(drop=True), \n",
    "                        features_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    print(f\"  âœ… prevåŸºæœ¬ç‰¹å¾´é‡: {len(features_df.columns)}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "# ============================================================\n",
    "# é–¢æ•°6: è£œåŠ©ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆæ™‚ç³»åˆ—ãƒ»æ›œæ—¥ãƒ»è·é›¢ãƒ»ãƒãƒƒãƒãƒ³ã‚°ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_auxiliary_features(df, available_events):\n",
    "    \"\"\"\n",
    "    æ™‚ç³»åˆ—ä½ç½®ç³»ã€æ›œæ—¥ç³»ã€è·é›¢ç³»ã€ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°ç³»ã‚’ä¸€æ‹¬ç”Ÿæˆ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        åŸºæœ¬ãƒ‡ãƒ¼ã‚¿\n",
    "    available_events : list\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåãƒªã‚¹ãƒˆ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : days_since_start, weekday_*, distance_*, match_* ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    auxiliary_feature_count = 0\n",
    "    \n",
    "    # ============================================================\n",
    "    # ã‚¹ãƒ†ãƒƒãƒ—1: æ™‚ç³»åˆ—ä½ç½®ç³»ç‰¹å¾´é‡\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"  æ™‚ç³»åˆ—ä½ç½®ç³»ç‰¹å¾´é‡ç”Ÿæˆä¸­...\")\n",
    "    \n",
    "    df_out['date_temp'] = pd.to_datetime(df_out['date'], format='%Y%m%d')\n",
    "    min_date = df_out['date_temp'].min()\n",
    "    max_date = df_out['date_temp'].max()\n",
    "    \n",
    "    df_out['days_since_start'] = (df_out['date_temp'] - min_date).dt.days\n",
    "    df_out['days_to_end'] = (max_date - df_out['date_temp']).dt.days\n",
    "    df_out['day_of_month'] = df_out['date_temp'].dt.day\n",
    "    \n",
    "    time_position_cols = ['days_since_start', 'days_to_end', 'day_of_month']\n",
    "    auxiliary_feature_count += len(time_position_cols)\n",
    "    \n",
    "    # ============================================================\n",
    "    # ã‚¹ãƒ†ãƒƒãƒ—2: æ›œæ—¥ç³»ç‰¹å¾´é‡\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"  æ›œæ—¥ç³»ç‰¹å¾´é‡ç”Ÿæˆä¸­...\")\n",
    "    \n",
    "    weekday_names = {0: 'monday', 1: 'tuesday', 2: 'wednesday', \n",
    "                     3: 'thursday', 4: 'friday', 5: 'saturday', 6: 'sunday'}\n",
    "    df_out['weekday_num'] = df_out['date_temp'].dt.dayofweek\n",
    "    \n",
    "    weekday_cols = []\n",
    "    for day_num, day_name in weekday_names.items():\n",
    "        col_name = f'is_weekday_{day_name}'\n",
    "        df_out[col_name] = (df_out['weekday_num'] == day_num).astype(int)\n",
    "        weekday_cols.append(col_name)\n",
    "        auxiliary_feature_count += 1\n",
    "    \n",
    "    # ============================================================\n",
    "    # ã‚¹ãƒ†ãƒƒãƒ—3: è·é›¢ç³»ç‰¹å¾´é‡\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"  è·é›¢ç³»ç‰¹å¾´é‡ç”Ÿæˆä¸­...\")\n",
    "    \n",
    "    distance_cols = []\n",
    "    for target_digit in range(11):  # 0-9, 10=ã‚¾ãƒ­ç›®\n",
    "        df_out[f'distance_from_{target_digit}'] = (\n",
    "            df_out['digit_num'] - target_digit\n",
    "        ).abs()\n",
    "        distance_cols.append(f'distance_from_{target_digit}')\n",
    "        auxiliary_feature_count += 1\n",
    "    \n",
    "    # ============================================================\n",
    "    # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°ç³»ç‰¹å¾´é‡\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"  ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°ç³»ç‰¹å¾´é‡ç”Ÿæˆä¸­...\")\n",
    "    \n",
    "    match_cols = []\n",
    "    for event in available_events:\n",
    "        flag_col = f'is_{event}'\n",
    "        \n",
    "        if flag_col in df_out.columns:\n",
    "            if event.endswith('day') and event != 'zorome':\n",
    "                # é€šå¸¸ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆ1dayï½9dayï¼‰\n",
    "                try:\n",
    "                    day_num = int(event[0])\n",
    "                    df_out[f'match_{event}'] = (\n",
    "                        (df_out[flag_col] == 1) & \n",
    "                        (df_out['digit_num'] == day_num)\n",
    "                    ).astype(int)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            elif event == '39day':\n",
    "                # 3ã¨9ã®è¤‡åˆã‚¤ãƒ™ãƒ³ãƒˆ\n",
    "                df_out[f'match_{event}'] = (\n",
    "                    (df_out[flag_col] == 1) & \n",
    "                    ((df_out['digit_num'] == 3) | (df_out['digit_num'] == 9))\n",
    "                ).astype(int)\n",
    "            \n",
    "            elif event == '40day':\n",
    "                # 4ã¨0ã®è¤‡åˆã‚¤ãƒ™ãƒ³ãƒˆ\n",
    "                df_out[f'match_{event}'] = (\n",
    "                    (df_out[flag_col] == 1) & \n",
    "                    ((df_out['digit_num'] == 4) | (df_out['digit_num'] == 0))\n",
    "                ).astype(int)\n",
    "            \n",
    "            elif event == 'zorome':\n",
    "                # ã‚¾ãƒ­ç›®ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæœ«å°¾ãŒ10=ã‚¾ãƒ­ç›®ï¼‰\n",
    "                df_out[f'match_{event}'] = (\n",
    "                    (df_out[flag_col] == 1) & \n",
    "                    (df_out['digit_num'] == 10)\n",
    "                ).astype(int)\n",
    "        \n",
    "        match_feature_count = len([e for e in available_events \n",
    "                                   if 'day' in e or e == 'zorome'])\n",
    "        auxiliary_feature_count += match_feature_count\n",
    "    \n",
    "    # ============================================================\n",
    "    # âš ï¸ ã€é‡è¦ã€‘ä¸€æ™‚ã‚«ãƒ©ãƒ ã¨æ–‡å­—åˆ—ã‚«ãƒ©ãƒ ã®å‰Šé™¤\n",
    "    # ============================================================\n",
    "    \n",
    "    # date_temp ã‚’å‰Šé™¤\n",
    "    df_out = df_out.drop('date_temp', axis=1)\n",
    "    \n",
    "    # ãã®ä»–ã®objectå‹ï¼ˆæ–‡å­—åˆ—ï¼‰ã‚«ãƒ©ãƒ ã‚’ç¢ºèªãƒ»å‰Šé™¤\n",
    "    object_cols = df_out.select_dtypes(include=['object']).columns.tolist()\n",
    "    if 'date' in object_cols:\n",
    "        object_cols.remove('date')  # dateã¯å¾Œã§å‰Šé™¤ã™ã‚‹ï¼ˆdateã‚«ãƒ©ãƒ ã¯ä¿æŒï¼‰\n",
    "    \n",
    "    if object_cols:\n",
    "        print(f\"  âš ï¸  æ–‡å­—åˆ—ã‚«ãƒ©ãƒ ãŒå­˜åœ¨: {object_cols}\")\n",
    "        print(f\"     å‰Šé™¤ã—ã¦ã„ã¾ã›ã‚“ï¼ˆå¾Œã®ã‚»ãƒ«ã§å‡¦ç†äºˆå®šï¼‰\")\n",
    "    \n",
    "    print(f\"  âœ… è£œåŠ©ç‰¹å¾´é‡: {auxiliary_feature_count}å€‹\")\n",
    "    return df_out\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«04-å…±é€š: ã™ã¹ã¦ã®é–¢æ•°ã‚’å®šç¾©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«04: çµ±åˆç‰¹å¾´é‡ç”Ÿæˆï¼ˆãƒ©ã‚°ãƒ»ç§»å‹•å¹³å‡ãƒ»å¤‰åŒ–é‡ãƒ»è£œåŠ©ç‰¹å¾´é‡ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«04ã€‘çµ±åˆç‰¹å¾´é‡ç”Ÿæˆï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢æ¸ˆã¿ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1. df_merged ã®ç¢ºèªï¼ˆã‚»ãƒ«03ã‹ã‚‰ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«03ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = df_merged.copy()\n",
    "df_out = df_out.sort_values(['date', 'digit_num']).reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… df_merged: {df_out.shape}\")\n",
    "print(f\"   æ—¥ä»˜ç¯„å›²: {df_out['date'].min()} ï½ {df_out['date'].max()}\")\n",
    "\n",
    "# available_events ã®ç¢ºèª\n",
    "if 'available_events' not in globals():\n",
    "    event_flags = [col for col in df_out.columns if col.startswith('is_')]\n",
    "    available_events = [col.replace('is_', '') for col in event_flags]\n",
    "\n",
    "print(f\"âœ… available_events: {len(available_events)}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. ãƒ©ã‚°å¯¾è±¡ã‚«ãƒ©ãƒ ã®è‡ªå‹•æŠ½å‡ºï¼ˆå½“æ—¥å€¤ã¯é™¤å¤–ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ãƒ©ã‚°å¯¾è±¡ã‚«ãƒ©ãƒ ã®æŠ½å‡º\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "exclude_patterns = [\n",
    "    'date', 'digit_num', 'last_digit', 'machine_', 'is_', \n",
    "    'prev_', 'allday_', 'distance_', 'match_', 'weekday', 'day_of',\n",
    "    'max_games', 'min_games'  # ãƒªãƒ¼ã‚¯é˜²æ­¢\n",
    "]\n",
    "\n",
    "numeric_cols = df_out.select_dtypes(include=[np.number]).columns.tolist()\n",
    "lag_target_cols = [\n",
    "    col for col in numeric_cols\n",
    "    if not any(pattern in col.lower() for pattern in exclude_patterns)\n",
    "]\n",
    "\n",
    "print(f\"ãƒ©ã‚°å¯¾è±¡ã‚«ãƒ©ãƒ : {len(lag_target_cols)}å€‹\")\n",
    "print(f\"ä¾‹: {lag_target_cols[:5]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘ç‰¹å¾´é‡ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "lag_days = [1, 2, 3, 4, 7, 14, 21, 28]\n",
    "window_sizes = [1, 2, 3, 4, 7, 14, 21, 28]\n",
    "change_lags = [1, 7, 14]\n",
    "stat_windows = [7, 14, 28]\n",
    "\n",
    "print(f\"ãƒ©ã‚°æ—¥æ•°: {lag_days}\")\n",
    "print(f\"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: {window_sizes}\")\n",
    "print(f\"å¤‰åŒ–é‡ãƒ©ã‚°: {change_lags}\")\n",
    "print(f\"ãƒ©ãƒ³ã‚¯çµ±è¨ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {stat_windows}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ãƒ©ã‚°ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘ãƒ©ã‚°ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_lag_features(df_out, lag_target_cols, lag_days)\n",
    "\n",
    "# ============================================================\n",
    "# 5. ç§»å‹•å¹³å‡ãƒ»æ¨™æº–åå·®ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘ç§»å‹•å¹³å‡ãƒ»æ¨™æº–åå·®ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_moving_avg_std_features(df_out, lag_target_cols, window_sizes)\n",
    "\n",
    "# ============================================================\n",
    "# 6. å¤‰åŒ–é‡ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘å¤‰åŒ–é‡ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_change_features(df_out, lag_target_cols, change_lags)\n",
    "\n",
    "# ============================================================\n",
    "# 7. ãƒ©ãƒ³ã‚¯å¤‰åŒ–ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—7ã€‘ãƒ©ãƒ³ã‚¯å¤‰åŒ–ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'last_digit_rank_diff' in df_out.columns:\n",
    "    df_out = create_rank_change_features(\n",
    "        df_out, \n",
    "        rank_col='last_digit_rank_diff',\n",
    "        change_lags=change_lags,\n",
    "        stat_windows=stat_windows\n",
    "    )\n",
    "else:\n",
    "    print(f\"  âš ï¸  last_digit_rank_diff ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. prevç³»ç‰¹å¾´é‡ç”Ÿæˆï¼ˆã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—8ã€‘prevç³»ç‰¹å¾´é‡ç”Ÿæˆï¼ˆã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "metric_cols = [\n",
    "    'avg_diff_coins', 'avg_games', 'win_rate', 'high_profit_rate',\n",
    "    'last_digit_rank_diff', 'last_digit_rank_games'\n",
    "]\n",
    "\n",
    "df_out = create_prev_features(\n",
    "    df_out, available_events, \n",
    "    metric_cols=metric_cols,\n",
    "    exclude_cols=['max_games', 'min_games']  # ãƒªãƒ¼ã‚¯é˜²æ­¢\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 9. è£œåŠ©ç‰¹å¾´é‡ç”Ÿæˆï¼ˆæ™‚ç³»åˆ—ãƒ»æ›œæ—¥ãƒ»è·é›¢ãƒ»ãƒãƒƒãƒãƒ³ã‚°ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—9ã€‘è£œåŠ©ç‰¹å¾´é‡ç”Ÿæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_out = create_auxiliary_features(df_out, available_events)\n",
    "\n",
    "# ============================================================\n",
    "# 10. ãƒªãƒ¼ã‚¯é˜²æ­¢: å½“æ—¥å€¤ã®é™¤å¤–ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—10ã€‘ãƒªãƒ¼ã‚¯é˜²æ­¢ãƒã‚§ãƒƒã‚¯\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "forbidden_cols_check = [col for col in [\n",
    "    'max_games', 'min_games',\n",
    "    'avg_diff_coins', 'avg_games', 'win_rate', 'high_profit_rate',\n",
    "    'total_diff_coins', 'total_games', 'current_diff',\n",
    "    'max_diff_coins', 'min_diff_coins'\n",
    "] if col in df_out.columns]\n",
    "\n",
    "if forbidden_cols_check:\n",
    "    print(f\"âš ï¸  å½“æ—¥å€¤ã‚«ãƒ©ãƒ ãŒæ®‹å­˜: {forbidden_cols_check}\")\n",
    "else:\n",
    "    print(f\"âœ… å½“æ—¥å€¤ã®ã‚«ãƒ©ãƒ ã¯ã™ã¹ã¦é™¤å¤–æ¸ˆã¿\")\n",
    "\n",
    "# ============================================================\n",
    "# 11. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['df_merged'] = df_out\n",
    "globals()['available_events'] = available_events\n",
    "\n",
    "# ============================================================\n",
    "# 12. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«04: çµ±åˆç‰¹å¾´é‡ç”Ÿæˆå®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nã€å‡¦ç†çµæœã€‘\")\n",
    "print(f\"  å…¥åŠ›: {df_merged.shape}\")\n",
    "print(f\"  å‡ºåŠ›: {df_out.shape}\")\n",
    "print(f\"  æ–°è¦ã‚«ãƒ©ãƒ æ•°: {df_out.shape[1] - df_merged.shape[1]}\")\n",
    "\n",
    "# ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ\n",
    "allday_cols = [col for col in df_out.columns if col.startswith('allday_')]\n",
    "prev_cols = [col for col in df_out.columns if col.startswith('prev_')]\n",
    "distance_cols = [col for col in df_out.columns if col.startswith('distance_')]\n",
    "match_cols = [col for col in df_out.columns if col.startswith('match_')]\n",
    "auxiliary_cols = [col for col in df_out.columns if any(\n",
    "    col.startswith(prefix) for prefix in \n",
    "    ['days_', 'day_of', 'is_weekday']\n",
    ")]\n",
    "\n",
    "print(f\"\\nã€ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥ã€‘\")\n",
    "print(f\"  allday_* (ãƒ©ã‚°ãƒ»ç§»å‹•å¹³å‡ãƒ»å¤‰åŒ–é‡ãƒ»ãƒ©ãƒ³ã‚¯): {len(allday_cols)}å€‹\")\n",
    "print(f\"  prev_* (ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´): {len(prev_cols)}å€‹\")\n",
    "print(f\"  distance_* (è·é›¢): {len(distance_cols)}å€‹\")\n",
    "print(f\"  match_* (ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°): {len(match_cols)}å€‹\")\n",
    "print(f\"  è£œåŠ©ç‰¹å¾´é‡ (æ™‚ç³»åˆ—ãƒ»æ›œæ—¥): {len(auxiliary_cols)}å€‹\")\n",
    "\n",
    "print(f\"\\nã€é‡è¦: ãƒªãƒ¼ã‚¯é˜²æ­¢ã€‘\")\n",
    "print(f\"  âœ… max_games, min_games (å½“æ—¥å€¤) ã¯ç”Ÿæˆãªã—\")\n",
    "print(f\"  âœ… allday_lagX_* ã®ã¿ãŒ max_games/min_games ã§ä½¿ç”¨ã•ã‚Œã‚‹\")\n",
    "print(f\"  âœ… prev_* ã¯ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã‹ã‚‰ã®ã¿æ´¾ç”Ÿï¼ˆå½“æ—¥å€¤ã¯é™¤å¤–ï¼‰\")\n",
    "print(f\"  âœ… ã™ã¹ã¦ã®lagã¯ shiftæ¸ˆã¿ï¼ˆå½“æ—¥ã‚’å«ã¾ãªã„ï¼‰\")\n",
    "\n",
    "print(f\"\\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘\")\n",
    "print(f\"  ã‚»ãƒ«05: ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼ˆå½“æ—¥å€¤ç¢ºèªã¨å‰Šé™¤ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«05: ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼ˆå½“æ—¥å€¤é™¤å¤–ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«05ã€‘ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼šå½“æ—¥å€¤ã®ç¢ºèªã¨é™¤å¤–\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1. df_merged ã®ç¢ºèªï¼ˆã‚»ãƒ«04ã®çµæœï¼‰\n",
    "# ============================================================\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«04ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"âœ… df_merged: {df_merged.shape}\")\n",
    "\n",
    "# ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã®ç¢ºèª\n",
    "event_flags = [col for col in df_merged.columns if col.startswith('is_')]\n",
    "print(f\"âœ… ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°æ•°: {len(event_flags)}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. ã€é‡è¦ã€‘å½“æ—¥ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªãƒ¼ã‚¯ï¼‰ã®ç‰¹å®šã¨é™¤å¤–\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ã€é‡è¦ã€‘å½“æ—¥ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªãƒ¼ã‚¯ï¼‰ã®ç‰¹å®šã¨é™¤å¤–\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ä½¿ç”¨ç¦æ­¢ã‚«ãƒ©ãƒ ï¼ˆå½“æ—¥ã®ç¢ºå®šå€¤ = æœªæ¥æƒ…å ± = ãƒªãƒ¼ã‚¯ï¼‰\n",
    "forbidden_cols = [\n",
    "    'avg_diff_coins',              # âŒ å½“æ—¥ã®å·®æšå®Ÿç¸¾ï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'avg_games',                   # âŒ å½“æ—¥ã®ã‚²ãƒ¼ãƒ æ•°å®Ÿç¸¾ï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'win_rate',                    # âŒ å½“æ—¥ã®å‹ç‡å®Ÿç¸¾ï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'high_profit_rate',            # âŒ å½“æ—¥ã®é«˜åç›Šç‡å®Ÿç¸¾ï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'total_diff_coins',            # âŒ å½“æ—¥ã®ç·å·®æšï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'total_games',                 # âŒ å½“æ—¥ã®ç·ã‚²ãƒ¼ãƒ æ•°ï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'max_games',                   # âŒâŒ å½“æ—¥ã®ã‚²ãƒ¼ãƒ æ•°MAXï¼ˆãƒªãƒ¼ã‚¯ï¼‰\n",
    "    'min_games',                   # âŒâŒ å½“æ—¥ã®ã‚²ãƒ¼ãƒ æ•°MINï¼ˆãƒªãƒ¼ã‚¯ï¼‰\n",
    "    'last_digit_rank_games',       # âŒâŒ å½“æ—¥ã®Gæ•°ãƒ©ãƒ³ã‚¯ï¼ˆãƒªãƒ¼ã‚¯ï¼‰\n",
    "    'last_digit_rank_efficiency',  # âŒâŒ å½“æ—¥ã®åŠ¹ç‡ãƒ©ãƒ³ã‚¯ï¼ˆãƒªãƒ¼ã‚¯ï¼‰\n",
    "    'current_diff',                # âŒ å½“æ—¥ã®ç²å¾—å·®æšï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'max_diff_coins',              # âŒ å½“æ—¥ã®æœ€å¤§å·®æšï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    'min_diff_coins',              # âŒ å½“æ—¥ã®æœ€å°å·®æšï¼ˆç¢ºå®šå€¤ï¼‰\n",
    "    # âš ï¸ last_digit_rank_diff ã¯ä¿æŒï¼ˆç›®çš„å¤‰æ•°ï¼‰\n",
    "]\n",
    "\n",
    "# å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ç¦æ­¢ã‚«ãƒ©ãƒ ã‚’æ¤œå‡º\n",
    "forbidden_cols_actual = [col for col in forbidden_cols if col in df_merged.columns]\n",
    "\n",
    "if forbidden_cols_actual:\n",
    "    print(f\"âŒ å½“æ—¥ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªãƒ¼ã‚¯ï¼‰ãŒ {len(forbidden_cols_actual)}å€‹ æ¤œå‡º:\")\n",
    "    for col in forbidden_cols_actual:\n",
    "        if col in ['max_games', 'min_games']:\n",
    "            print(f\"   âŒâŒ {col} â† å½“æ—¥ã®ã‚²ãƒ¼ãƒ æ•°ï¼ˆã‚»ãƒ«04ã§å‰Šé™¤äºˆå®šï¼‰\")\n",
    "        elif col in ['last_digit_rank_games', 'last_digit_rank_efficiency']:\n",
    "            print(f\"   âŒâŒ {col} â† å½“æ—¥ã®ãƒ©ãƒ³ã‚¯æƒ…å ±ï¼ˆãƒªãƒ¼ã‚¯ï¼‰\")\n",
    "        else:\n",
    "            print(f\"   âŒ {col}\")\n",
    "    \n",
    "    # é™¤å¤–\n",
    "    df_merged_clean = df_merged.drop(columns=forbidden_cols_actual)\n",
    "    print(f\"\\nâœ… é™¤å¤–å¾Œ: {df_merged.shape} â†’ {df_merged_clean.shape}\")\n",
    "    print(f\"   å‰Šé™¤ã‚«ãƒ©ãƒ æ•°: {len(forbidden_cols_actual)}å€‹\")\n",
    "else:\n",
    "    print(f\"âœ“ å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«é™¤å¤–æ¸ˆã¿ï¼ˆã‚»ãƒ«04ã§é©åˆ‡ã«ç”Ÿæˆï¼‰\")\n",
    "    df_merged_clean = df_merged.copy()\n",
    "\n",
    "# ============================================================\n",
    "# 3. å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘objectå‹ï¼ˆæ–‡å­—åˆ—ï¼‰ã‚«ãƒ©ãƒ ã®ç¢ºèªã¨å‡¦ç†\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# objectå‹ã‚«ãƒ©ãƒ ã‚’ç¢ºèª\n",
    "object_cols = df_merged_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"objectå‹ã‚«ãƒ©ãƒ : {len(object_cols)}å€‹\")\n",
    "if object_cols:\n",
    "    print(f\"  {object_cols}\")\n",
    "\n",
    "# âš ï¸ date ã‚«ãƒ©ãƒ ã¯æœ€å¾Œã«å‰Šé™¤ã™ã‚‹ã®ã§ä¿æŒ\n",
    "# ãã®ä»–ã®objectå‹ã¯å‰Šé™¤\n",
    "other_object_cols = [col for col in object_cols if col != 'date']\n",
    "if other_object_cols:\n",
    "    print(f\"\\nâš ï¸  dateä»¥å¤–ã®objectå‹ã‚«ãƒ©ãƒ ãŒæ®‹å­˜: {other_object_cols}\")\n",
    "    print(f\"   ã“ã‚Œã‚‰ã‚’å‰Šé™¤ã—ã¾ã™ï¼ˆç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ä¸å¯ï¼‰\")\n",
    "    df_merged_clean = df_merged_clean.drop(columns=other_object_cols)\n",
    "    print(f\"âœ… å‰Šé™¤å®Œäº†\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—4: date â†’ date_num ã«å¤‰æ›ï¼ˆæ—¥é€£ç•ªï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘date â†’ date_num ã«å¤‰æ›ï¼ˆæ—¥é€£ç•ªï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'date' in df_merged_clean.columns:\n",
    "    try:\n",
    "        # YYYYMMDDæ–‡å­—åˆ—ã‚’æ—¥ä»˜ã«å¤‰æ›\n",
    "        df_merged_clean['date_datetime'] = pd.to_datetime(df_merged_clean['date'], format='%Y%m%d')\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿é–‹å§‹æ—¥ã‚’åŸºæº–ã«æ—¥é€£ç•ªã‚’è¨ˆç®—\n",
    "        min_date = df_merged_clean['date_datetime'].min()\n",
    "        df_merged_clean['date_num'] = (df_merged_clean['date_datetime'] - min_date).dt.days\n",
    "        \n",
    "        print(f\"âœ… date_num ã‚’ç”Ÿæˆï¼ˆæ—¥é€£ç•ªï¼‰\")\n",
    "        print(f\"   ç¯„å›²: {df_merged_clean['date_num'].min()} ï½ {df_merged_clean['date_num'].max()} æ—¥\")\n",
    "        print(f\"   å‹: {df_merged_clean['date_num'].dtype}\")\n",
    "        \n",
    "        # date ã¨ date_datetime ã¯ä¸è¦ãªã®ã§å‰Šé™¤\n",
    "        df_merged_clean = df_merged_clean.drop(['date', 'date_datetime'], axis=1)\n",
    "        print(f\"âœ… date ã‚«ãƒ©ãƒ ã‚’å‰Šé™¤\")\n",
    "        print(f\"âœ… df_merged_clean: {df_merged_clean.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"âš ï¸  date ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(f\"   å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ : {df_merged_clean.columns[:10].tolist()}\")\n",
    "    raise RuntimeError(\"âŒ date ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "required_cols = ['date_num', 'digit_num', 'last_digit_rank_diff']\n",
    "missing_cols = [col for col in required_cols if col not in df_merged_clean.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"âŒ å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_cols}\")\n",
    "    raise RuntimeError(f\"å¿…é ˆã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    print(f\"âœ… å¿…é ˆã‚«ãƒ©ãƒ ã™ã¹ã¦å­˜åœ¨:\")\n",
    "    for col in required_cols:\n",
    "        print(f\"   âœ… {col}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ç‰¹å¾´é‡ã®çµ±è¨ˆï¼ˆãƒªãƒ¼ã‚¯é™¤å¤–å¾Œï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘ç‰¹å¾´é‡ã®çµ±è¨ˆï¼ˆãƒªãƒ¼ã‚¯é™¤å¤–å¾Œï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ã‚«ãƒ©ãƒ ã®åˆ†é¡\n",
    "prev_cols = [col for col in df_merged_clean.columns if col.startswith('prev_')]\n",
    "allday_cols = [col for col in df_merged_clean.columns if col.startswith('allday_')]\n",
    "distance_cols = [col for col in df_merged_clean.columns if col.startswith('distance_')]\n",
    "match_cols = [col for col in df_merged_clean.columns if col.startswith('match_')]\n",
    "is_cols = [col for col in df_merged_clean.columns if col.startswith('is_')]\n",
    "auxiliary_cols = [col for col in df_merged_clean.columns if col in [\n",
    "    'days_since_start', 'days_to_end', 'day_of_month', 'weekday_num'\n",
    "] or any(t in col for t in ['weekday', 'digit_interaction'])]\n",
    "\n",
    "print(f\"ç‰¹å¾´é‡ã®æ§‹æˆ:\")\n",
    "print(f\"  prev_*: {len(prev_cols)}å€‹ â† ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ï¼ˆå½“æ—¥å€¤ã¯é™¤å¤–ï¼‰\")\n",
    "print(f\"  allday_*: {len(allday_cols)}å€‹ â† ãƒ©ã‚°ãƒ»ç§»å‹•å¹³å‡ãƒ»å¤‰åŒ–é‡\")\n",
    "print(f\"  distance_*: {len(distance_cols)}å€‹\")\n",
    "print(f\"  match_*: {len(match_cols)}å€‹\")\n",
    "print(f\"  is_* (ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°): {len(is_cols)}å€‹\")\n",
    "print(f\"  è£œåŠ©ç‰¹å¾´é‡ï¼ˆæ›œæ—¥ãƒ»æ™‚ç³»åˆ—ï¼‰: {len(auxiliary_cols)}å€‹\")\n",
    "\n",
    "total_features = len(prev_cols) + len(allday_cols) + len(distance_cols) + len(match_cols) + len(is_cols) + len(auxiliary_cols)\n",
    "print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"  åˆè¨ˆç‰¹å¾´é‡: {total_features}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. NaNå€¤ãƒ»ç„¡é™å€¤ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘NaNå€¤ãƒ»ç„¡é™å€¤ã®ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# NaNå€¤\n",
    "nan_count = df_merged_clean.isnull().sum().sum()\n",
    "total_cells = df_merged_clean.shape[0] * df_merged_clean.shape[1]\n",
    "nan_ratio = nan_count / total_cells * 100 if total_cells > 0 else 0\n",
    "\n",
    "print(f\"NaNå€¤ç·æ•°: {nan_count}å€‹ï¼ˆå…¨ã‚»ãƒ«æ•°ã® {nan_ratio:.2f}%ï¼‰\")\n",
    "\n",
    "# ç„¡é™å€¤\n",
    "inf_count = np.isinf(df_merged_clean.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"ç„¡é™å€¤ç·æ•°: {inf_count}å€‹\")\n",
    "\n",
    "if nan_count > 0 or inf_count > 0:\n",
    "    print(f\"âš ï¸  ç•°å¸¸å€¤ãŒã‚ã‚Šã¾ã™ï¼ˆå¾Œç¶šã‚»ãƒ«ã§è£œå®Œãƒ»å‡¦ç†äºˆå®šï¼‰\")\n",
    "else:\n",
    "    print(f\"âœ… ç•°å¸¸å€¤ãªã—\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—7ã€‘ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ç™»éŒ²å‰ã®ç¢ºèª\n",
    "print(f\"ç™»éŒ²å‰ç¢ºèª:\")\n",
    "print(f\"  df_merged_clean ã‚«ãƒ©ãƒ æ•°: {df_merged_clean.shape[1]}\")\n",
    "print(f\"  date_num å­˜åœ¨: {'date_num' in df_merged_clean.columns}\")\n",
    "print(f\"  date å­˜åœ¨: {'date' in df_merged_clean.columns}\")\n",
    "\n",
    "globals()['df_merged'] = df_merged_clean\n",
    "\n",
    "print(f\"âœ… df_merged ã‚’ç™»éŒ²ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢æ¸ˆã¿ã€date_numç”Ÿæˆæ¸ˆã¿ã€objectå‹å‰Šé™¤æ¸ˆã¿ï¼‰\")\n",
    "print(f\"   ç™»éŒ²å¾Œã®ã‚«ãƒ©ãƒ æ•°: {globals()['df_merged'].shape[1]}\")\n",
    "print(f\"   ç™»éŒ²å¾Œã®date_numç¢ºèª: {'date_num' in globals()['df_merged'].columns}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«05: ãƒªãƒ¼ã‚¯é˜²æ­¢å®Œäº† + date_numç”Ÿæˆå®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nã€å®Ÿè¡Œçµæœã€‘\")\n",
    "print(f\"  å…¥åŠ›: {df_merged.shape}\")\n",
    "print(f\"  é™¤å¤–: {len(forbidden_cols_actual)}å€‹ã®ãƒªãƒ¼ã‚¯åˆ—\")\n",
    "print(f\"  å‡ºåŠ›: {df_merged_clean.shape}\")\n",
    "\n",
    "print(f\"\\nã€ãƒªãƒ¼ã‚¯é˜²æ­¢ã€‘\")\n",
    "print(f\"  âœ… å½“æ—¥ç¢ºå®šå€¤ï¼ˆavg_diff_coinsç­‰ï¼‰ã‚’é™¤å¤–\")\n",
    "print(f\"  âœ… å½“æ—¥ã‚²ãƒ¼ãƒ æ•°ï¼ˆmax_games, min_gamesï¼‰ã¯ç”Ÿæˆãªã—\")\n",
    "print(f\"  âœ… å½“æ—¥ãƒ©ãƒ³ã‚¯æƒ…å ±ï¼ˆlast_digit_rank_gamesç­‰ï¼‰ã‚’é™¤å¤–\")\n",
    "print(f\"  âœ… last_digit_rank_diff ã¯ä¿æŒï¼ˆç›®çš„å¤‰æ•°ï¼‰\")\n",
    "\n",
    "print(f\"\\nã€ä¿æŒã•ã‚Œã¦ã„ã‚‹ç‰¹å¾´é‡ã€‘\")\n",
    "print(f\"  âœ… prev_* ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ã®éå»ãƒ‡ãƒ¼ã‚¿ï¼‰\")\n",
    "print(f\"  âœ… allday_lag* ï¼ˆéå»Xæ—¥å‰ã®ãƒ‡ãƒ¼ã‚¿ï¼‰\")\n",
    "print(f\"  âœ… allday_ma/std_* ï¼ˆå½“æ—¥ã‚’é™¤ãéå»ã®ç§»å‹•å¹³å‡/æ¨™æº–åå·®ï¼‰\")\n",
    "print(f\"  âœ… allday_rank_change/max/min/std_* ï¼ˆãƒ©ãƒ³ã‚¯ç³»ï¼‰\")\n",
    "print(f\"  âœ… distance_* ï¼ˆè·é›¢ç³»ï¼‰\")\n",
    "print(f\"  âœ… match_* ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°ï¼‰\")\n",
    "print(f\"  âœ… æ™‚ç³»åˆ—ãƒ»æ›œæ—¥ç‰¹å¾´é‡\")\n",
    "\n",
    "print(f\"\\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘\")\n",
    "print(f\"  ã‚»ãƒ«06: ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯ã¨æº–å‚™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«05-ç¢ºèª: NaNå€¤è©³ç´°è¨ºæ–­ã¨ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«06ã€‘NaNå€¤è©³ç´°è¨ºæ–­ã¨ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# 1. df_merged ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«05ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df = df_merged.copy()\n",
    "print(f\"âœ… df_merged: {df.shape}\")\n",
    "\n",
    "# å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª\n",
    "required_cols = ['date_num', 'digit_num']\n",
    "missing = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "if missing:\n",
    "    raise RuntimeError(f\"âŒ å¿…é ˆã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}\\nã‚»ãƒ«05ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "\n",
    "print(f\"   æ—¥ä»˜ç¯„å›²: {df['date_num'].min()} ï½ {df['date_num'].max()} æ—¥\")\n",
    "print(f\"   æœ«å°¾: {sorted(df['digit_num'].unique())}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. NaNå€¤ã®é›†è¨ˆï¼ˆã‚«ãƒ©ãƒ åˆ¥ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘NaNå€¤ã®é›†è¨ˆï¼ˆã‚«ãƒ©ãƒ åˆ¥ï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "nan_by_col = df.isnull().sum().sort_values(ascending=False)\n",
    "nan_by_col_pct = (nan_by_col / len(df) * 100).round(2)\n",
    "\n",
    "# NaNå€¤ãŒã‚ã‚Šã‚«ãƒ©ãƒ ã®ã¿\n",
    "cols_with_nan = nan_by_col[nan_by_col > 0]\n",
    "\n",
    "print(f\"\\nâœ… NaNå€¤ãŒã‚ã‚‹: {len(cols_with_nan)}å€‹ã®ã‚«ãƒ©ãƒ \")\n",
    "print(f\"   ç·NaNæ•°: {nan_by_col.sum():,}å€‹\")\n",
    "\n",
    "# ã‚«ãƒ©ãƒ åˆ¥NaNçµ±è¨ˆè¡¨\n",
    "nan_stats = pd.DataFrame({\n",
    "    'ã‚«ãƒ©ãƒ å': cols_with_nan.index,\n",
    "    'NaNæ•°': cols_with_nan.values,\n",
    "    'NaNç‡ï¼ˆ%ï¼‰': nan_by_col_pct[cols_with_nan.index].values,\n",
    "    ' ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—': [\n",
    "        'prevç³»' if 'prev_' in col else\n",
    "        'alldayç³»' if 'allday_' in col else\n",
    "        'ãã®ä»–' \n",
    "        for col in cols_with_nan.index\n",
    "    ]\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nğŸ“Š NaNå€¤ãŒå¤šã„ TOP 20:\")\n",
    "print(nan_stats.head(20).to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# 3. NaNå€¤ã®åŸå› åˆ†æï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘NaNå€¤ã®åŸå› åˆ†æï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡\n",
    "nan_by_type = {\n",
    "    'prev_ç³»': nan_by_col[[col for col in nan_by_col.index if col.startswith('prev_')]].sum(),\n",
    "    'allday_ç³»': nan_by_col[[col for col in nan_by_col.index if col.startswith('allday_')]].sum(),\n",
    "    'ãã®ä»–': nan_by_col[[col for col in nan_by_col.index if not col.startswith('prev_') and not col.startswith('allday_')]].sum()\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“Š ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ¥NaNå€¤:\")\n",
    "for ftype, count in nan_by_type.items():\n",
    "    pct = count / len(df) / len([c for c in df.columns if \n",
    "           (ftype == 'prev_ç³»' and c.startswith('prev_')) or\n",
    "           (ftype == 'allday_ç³»' and c.startswith('allday_')) or\n",
    "           (ftype == 'ãã®ä»–' and not c.startswith('prev_') and not c.startswith('allday_'))\n",
    "           ]) * 100 if count > 0 else 0\n",
    "    print(f\"  {ftype}: {count:,}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. NaNå€¤ã®æ™‚ç³»åˆ—åˆ†æï¼ˆæ—¥ä»˜åˆ¥ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘NaNå€¤ã®æ™‚ç³»åˆ—åˆ†æï¼ˆæ—¥ä»˜åˆ¥ï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "nan_by_date = df.groupby('date_num').apply(lambda x: x.isnull().sum().sum())\n",
    "print(f\"\\nğŸ“Š æ—¥ä»˜åˆ¥NaNå€¤çµ±è¨ˆ:\")\n",
    "print(f\"  å¹³å‡: {nan_by_date.mean():.0f}å€‹/æ—¥\")\n",
    "print(f\"  æœ€å°: {nan_by_date.min():.0f}å€‹/æ—¥ (date_num={nan_by_date.idxmin()})\")\n",
    "print(f\"  æœ€å¤§: {nan_by_date.max():.0f}å€‹/æ—¥ (date_num={nan_by_date.idxmax()})\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. æ­£å¸¸æ€§ã®åˆ¤å®šï¼ˆprevç³»ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘NaNå€¤ã®æ­£å¸¸æ€§åˆ¤å®šï¼ˆprevç³»ï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "prev_cols = [col for col in df.columns if col.startswith('prev_')]\n",
    "prev_nan_pct = (df[prev_cols].isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nâœ… prevç³»ç‰¹å¾´é‡ã®NaNç‡:\")\n",
    "print(f\"  ä¸­å¤®å€¤: {prev_nan_pct.median():.1f}%\")\n",
    "print(f\"  æœ€å°: {prev_nan_pct.min():.1f}% ({prev_nan_pct.idxmin()})\")\n",
    "print(f\"  æœ€å¤§: {prev_nan_pct.max():.1f}% ({prev_nan_pct.idxmax()})\")\n",
    "\n",
    "# æ—©æœŸãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥ä»˜ãŒæµ…ã„ï¼‰ã®NaNç‡ãŒé«˜ã„ã®ã¯æ­£å¸¸\n",
    "early_data_threshold = 30  # æœ€åˆ30æ—¥\n",
    "early_df = df[df['date_num'] < early_data_threshold]\n",
    "later_df = df[df['date_num'] >= early_data_threshold]\n",
    "\n",
    "if len(early_df) > 0:\n",
    "    early_nan_rate = early_df[prev_cols].isnull().sum().sum() / (len(early_df) * len(prev_cols)) * 100\n",
    "    later_nan_rate = later_df[prev_cols].isnull().sum().sum() / (len(later_df) * len(prev_cols)) * 100\n",
    "    \n",
    "    print(f\"\\n  æ—©æœŸãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆ{early_data_threshold}æ—¥ï¼‰NaNç‡: {early_nan_rate:.1f}%\")\n",
    "    print(f\"  å¾ŒæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆãã‚Œä»¥é™ï¼‰NaNç‡: {later_nan_rate:.1f}%\")\n",
    "    \n",
    "    if early_nan_rate > later_nan_rate:\n",
    "        print(f\"  âœ… æ­£å¸¸: æ—©æœŸãƒ‡ãƒ¼ã‚¿ãŒNaNã«ãªã‚‹ã®ã¯æœŸå¾…é€šã‚Š\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸  è­¦å‘Š: å¾ŒæœŸãƒ‡ãƒ¼ã‚¿ã®NaNç‡ãŒé«˜ã„ - ãƒ‡ãƒ¼ã‚¿å“è³ªã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. å•é¡Œã®ã‚ã‚‹ã‚«ãƒ©ãƒ ã®ç‰¹å®šï¼ˆexpectedä»¥å¤–ã®NaNï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘å•é¡Œã®ã‚ã‚‹NaNå€¤ã®ç‰¹å®š\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# æœŸå¾…ã•ã‚Œã‚‹NaN\n",
    "expected_nan_threshold = 50  # NaNç‡ãŒ50%ä»¥ä¸Šãªã‚‰å±¥æ­´ä¸è¶³ã§æ­£å¸¸\n",
    "suspicious_cols = nan_stats[nan_stats['NaNç‡ï¼ˆ%ï¼‰'] < expected_nan_threshold]\n",
    "\n",
    "if len(suspicious_cols) > 0:\n",
    "    print(f\"\\nâš ï¸  ç–‘ã‚ã—ã„ã‚«ãƒ©ãƒ ï¼ˆNaNç‡ãŒ{expected_nan_threshold}%æœªæº€ï¼‰:\")\n",
    "    print(suspicious_cols.to_string(index=False))\n",
    "    print(f\"\\nğŸ“Œ ã“ã‚Œã‚‰ã¯å±¥æ­´ä¸è¶³ã§ã¯ãªãã€ä»–ã®åŸå› ã§NaNã«ãªã£ã¦ã„ã¾ã™\")\n",
    "else:\n",
    "    print(f\"\\nâœ… ç–‘ã‚ã—ã„ã‚«ãƒ©ãƒ ãªã—ï¼ˆã™ã¹ã¦ã®NaNå€¤ã¯å±¥æ­´ä¸è¶³ã§èª¬æ˜ã§ãã‚‹ï¼‰\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. å¯è¦–åŒ–ï¼ˆ1ï¼‰ã‚«ãƒ©ãƒ åˆ¥NaNç‡\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—7ã€‘å¯è¦–åŒ–é–‹å§‹\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•1: NaNç‡ãŒé«˜ã„ TOP 20 ã‚«ãƒ©ãƒ \n",
    "nan_top20 = nan_by_col_pct[cols_with_nan.index].head(20)\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "nan_top20.plot(kind='barh', ax=ax1, color='coral')\n",
    "ax1.set_xlabel('NaNç‡ï¼ˆ%ï¼‰')\n",
    "ax1.set_title('NaNç‡ãŒé«˜ã„ TOP 20 ã‚«ãƒ©ãƒ ')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•2: ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ¥NaNç‡ã®ç®±ã²ã’å›³\n",
    "ax2 = axes[0, 1]\n",
    "prev_nan_list = df[[c for c in df.columns if c.startswith('prev_')]].isnull().sum() / len(df) * 100\n",
    "allday_nan_list = df[[c for c in df.columns if c.startswith('allday_')]].isnull().sum() / len(df) * 100\n",
    "\n",
    "bp = ax2.boxplot(\n",
    "    [prev_nan_list, allday_nan_list],\n",
    "    labels=['prev_ç³»', 'allday_ç³»'],\n",
    "    patch_artist=True\n",
    ")\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "ax2.set_ylabel('NaNç‡ï¼ˆ%ï¼‰')\n",
    "ax2.set_title('ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ¥NaNç‡ã®åˆ†å¸ƒ')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•3: æ—¥ä»˜åˆ¥NaNæ•°ã®æ¨ç§»\n",
    "ax3 = axes[1, 0]\n",
    "nan_by_date.plot(ax=ax3, color='steelblue', marker='o', markersize=3)\n",
    "ax3.set_xlabel('date_numï¼ˆæ—¥ï¼‰')\n",
    "ax3.set_ylabel('NaNæ•°')\n",
    "ax3.set_title('æ—¥ä»˜åˆ¥NaNå€¤æ•°ã®æ¨ç§»')\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.axvline(x=early_data_threshold, color='red', linestyle='--', label=f'æ—©æœŸ/å¾ŒæœŸå¢ƒç•Œ({early_data_threshold}æ—¥)')\n",
    "ax3.legend()\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•4: æœ«å°¾åˆ¥NaNç‡\n",
    "ax4 = axes[1, 1]\n",
    "nan_by_digit = df.groupby('digit_num').apply(lambda x: (x.isnull().sum().sum() / (len(x) * len(x.columns)) * 100))\n",
    "nan_by_digit.plot(kind='bar', ax=ax4, color='mediumseagreen')\n",
    "ax4.set_xlabel('æœ«å°¾ç•ªå·')\n",
    "ax4.set_ylabel('NaNç‡ï¼ˆ%ï¼‰')\n",
    "ax4.set_title('æœ«å°¾åˆ¥NaNç‡')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nan_analysis.png', dpi=100, bbox_inches='tight')\n",
    "print(f\"âœ… ã‚°ãƒ©ãƒ•ä¿å­˜: nan_analysis.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 8. ãã®ä»–ã®ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—8ã€‘ãã®ä»–ã®ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if zero_ratios:\n",
    "    print(f\"\\nâš ï¸  ã‚¼ãƒ­ãŒ80%ä»¥ä¸Šã®ã‚«ãƒ©ãƒ ï¼ˆ{len(zero_ratios)}å€‹ï¼‰:\")\n",
    "    for col, pct in sorted(zero_ratios.items(), key=lambda x: -x[1])[:10]:\n",
    "        print(f\"   {col}: {pct:.1f}%\")\n",
    "else:\n",
    "    print(f\"\\nâœ… ã‚¼ãƒ­ãŒ80%ä»¥ä¸Šã®ã‚«ãƒ©ãƒ : ãªã—\")\n",
    "\n",
    "# 3. é‡è¤‡è¡Œã®ãƒã‚§ãƒƒã‚¯\n",
    "dup_rows = df.duplicated(subset=[c for c in df.columns if c not in ['date_num', 'digit_num']]).sum()\n",
    "print(f\"\\nâœ… é‡è¤‡è¡Œãƒã‚§ãƒƒã‚¯: {dup_rows}è¡Œ\")\n",
    "\n",
    "# 4. å¤–ã‚Œå€¤ã®ãƒã‚§ãƒƒã‚¯ï¼ˆæ•°å€¤ã‚«ãƒ©ãƒ ï¼‰\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "outlier_summary = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in ['date_num', 'digit_num']:\n",
    "        continue\n",
    "    \n",
    "    data = df[col].dropna()\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "    \n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    outliers = len(data[(data < Q1 - 1.5 * IQR) | (data > Q3 + 1.5 * IQR)])\n",
    "    if outliers > 0:\n",
    "        outlier_pct = outliers / len(data) * 100\n",
    "        if outlier_pct > 5:  # 5%ä»¥ä¸Š\n",
    "            outlier_summary[col] = (outliers, outlier_pct)\n",
    "\n",
    "if outlier_summary:\n",
    "    print(f\"\\nâš ï¸  å¤–ã‚Œå€¤ãŒ5%ä»¥ä¸Šã®ã‚«ãƒ©ãƒ ï¼ˆ{len(outlier_summary)}å€‹ï¼‰:\")\n",
    "    for col, (count, pct) in sorted(outlier_summary.items(), key=lambda x: -x[1][1])[:10]:\n",
    "        print(f\"   {col}: {count}å€‹ï¼ˆ{pct:.1f}%ï¼‰\")\n",
    "else:\n",
    "    print(f\"\\nâœ… å¤–ã‚Œå€¤ãŒ5%ä»¥ä¸Šã®ã‚«ãƒ©ãƒ : ãªã—\")\n",
    "\n",
    "# 5. æœ«å°¾åˆ¥ã®ãƒ‡ãƒ¼ã‚¿æ•°ãƒãƒ©ãƒ³ã‚¹\n",
    "print(f\"\\nâœ… æœ«å°¾åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°ãƒãƒ©ãƒ³ã‚¹:\")\n",
    "digit_counts = df.groupby('digit_num').size()\n",
    "min_count = digit_counts.min()\n",
    "max_count = digit_counts.max()\n",
    "balance_ratio = min_count / max_count * 100\n",
    "\n",
    "print(f\"   æœ€å°: {min_count}è¡Œï¼ˆæœ«å°¾{digit_counts.idxmin()}ï¼‰\")\n",
    "print(f\"   æœ€å¤§: {max_count}è¡Œï¼ˆæœ«å°¾{digit_counts.idxmax()}ï¼‰\")\n",
    "print(f\"   ãƒãƒ©ãƒ³ã‚¹ç‡: {balance_ratio:.1f}%\")\n",
    "\n",
    "if balance_ratio < 90:\n",
    "    print(f\"   âš ï¸  è­¦å‘Š: æœ«å°¾é–“ã§ãƒ‡ãƒ¼ã‚¿æ•°ãŒã‚¢ãƒ³ãƒãƒ©ãƒ³ã‚¹\")\n",
    "else:\n",
    "    print(f\"   âœ… æ­£å¸¸: ãƒ‡ãƒ¼ã‚¿ãŒã»ã¼ãƒãƒ©ãƒ³ã‚¹ã—ã¦ã„ã‚‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 9. æ¨å¥¨äº‹é …\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—9ã€‘æ¨å¥¨äº‹é …\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… NaNå€¤ãŒ24.82%ãªã®ã¯æ­£å¸¸ã§ã™ã€‚ç†ç”±ï¼š\n",
    "  1. prev_ç³»ç‰¹å¾´é‡ï¼šå‰å›ä»¥å‰ã®ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ãŒãªã„æœ€åˆã®æ—¥ä»˜ã§ã¯NaN\n",
    "  2. allday_lagç‰¹å¾´é‡ï¼š28æ—¥å‰ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªãŸã‚ã€æœ€åˆã®28æ—¥ã¯NaN\n",
    "\n",
    "ğŸ” æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼š\n",
    "  1. ç¶šè¡Œ: NaNå€¤ãŒã»ã¼ã™ã¹ã¦ã€Œå±¥æ­´ä¸è¶³ã€ã§ã‚ã‚‹å ´åˆã€ãã®ã¾ã¾ç¶šè¡Œ\n",
    "  2. ç¢ºèª: ç–‘ã‚ã—ã„ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€ã‚»ãƒ«03ï½05ã‚’è¦‹ç›´ã™\n",
    "  3. è£œå®Œ: å¿…è¦ã«å¿œã˜ã¦ã‚»ãƒ«10ã§NaNå€¤ã‚’è£œå®Œï¼ˆå¹³å‡å€¤ãªã©ï¼‰\n",
    "\n",
    "ğŸ“Š å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼š\n",
    "  - nan_analysis.png: 4ã¤ã®NaNåˆ†æã‚°ãƒ©ãƒ•\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«06: NaNå€¤è©³ç´°è¨ºæ–­å®Œäº†\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«06: çµ±ä¸€çš„ãªè©•ä¾¡é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_unified_metrics(y_true, y_pred, test_data, task_type='binary'):\n",
    "    \"\"\"\n",
    "    çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        çœŸå®Ÿãƒ©ãƒ™ãƒ«\n",
    "    y_pred : array-like\n",
    "        äºˆæ¸¬å€¤\n",
    "    test_data : DataFrame\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ©ç›Šè¨ˆç®—ç”¨ï¼‰\n",
    "    task_type : str\n",
    "        'binary' (äºŒå€¤åˆ†é¡) or 'regression' (å›å¸°)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè©•ä¾¡æŒ‡æ¨™\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # =====================================\n",
    "    # 1. å…±é€šæŒ‡æ¨™ï¼ˆå…¨ã‚¿ã‚¹ã‚¯ï¼‰\n",
    "    # =====================================\n",
    "    \n",
    "    # MAEï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰\n",
    "    metrics['mae'] = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # RMSEï¼ˆäºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®ï¼‰\n",
    "    metrics['rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Spearmanç›¸é–¢ä¿‚æ•°ï¼ˆãƒ©ãƒ³ã‚¯ç›¸é–¢ï¼‰\n",
    "    spearman_corr, spearman_pval = spearmanr(y_true, y_pred)\n",
    "    metrics['spearman_corr'] = spearman_corr if not np.isnan(spearman_corr) else 0.0\n",
    "    metrics['spearman_pval'] = spearman_pval if not np.isnan(spearman_pval) else 1.0\n",
    "    \n",
    "    # =====================================\n",
    "    # 2. ã‚¿ã‚¹ã‚¯åˆ¥æŒ‡æ¨™\n",
    "    # =====================================\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        # ===== äºŒå€¤åˆ†é¡æŒ‡æ¨™ =====\n",
    "        \n",
    "        # äºˆæ¸¬ãŒç¢ºç‡ã®å ´åˆã¨ç¡¬ã„ãƒ©ãƒ™ãƒ«ã®å ´åˆã«å¯¾å¿œ\n",
    "        if y_pred.min() >= 0 and y_pred.max() <= 1 and len(np.unique(y_pred)) > 2:\n",
    "            # ç¢ºç‡å€¤ã¨åˆ¤æ–­\n",
    "            y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "            y_pred_proba = y_pred\n",
    "        else:\n",
    "            # ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«\n",
    "            y_pred_binary = y_pred\n",
    "            y_pred_proba = None\n",
    "        \n",
    "        # ç²¾åº¦ï¼ˆAccuracyï¼‰\n",
    "        metrics['accuracy'] = accuracy_score(y_true, y_pred_binary)\n",
    "        \n",
    "        # F1ã‚¹ã‚³ã‚¢\n",
    "        metrics['f1'] = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "        \n",
    "        # é©åˆç‡ï¼ˆPrecisionï¼‰\n",
    "        metrics['precision'] = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "        \n",
    "        # å†ç¾ç‡ï¼ˆRecallï¼‰\n",
    "        metrics['recall'] = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "        \n",
    "        # ROC-AUCï¼ˆç¢ºç‡å€¤ãŒã‚ã‚‹å ´åˆï¼‰\n",
    "        try:\n",
    "            if y_pred_proba is not None:\n",
    "                metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba)\n",
    "            else:\n",
    "                metrics['roc_auc'] = roc_auc_score(y_true, y_pred_binary)\n",
    "        except:\n",
    "            metrics['roc_auc'] = np.nan\n",
    "    \n",
    "    elif task_type == 'regression':\n",
    "        # ===== å›å¸°æŒ‡æ¨™ =====\n",
    "        \n",
    "        # ã‚¯ãƒªãƒƒãƒ—ï¼ˆãƒ©ãƒ³ã‚¯å­¦ç¿’ã¯1-11ã®ç¯„å›²ï¼‰\n",
    "        y_pred_clipped = np.clip(y_pred, CONFIG['MIN_RANK'], CONFIG['MAX_RANK'])\n",
    "        \n",
    "        # TOP3å‘½ä¸­ç‡ï¼ˆäºˆæ¸¬ãƒ©ãƒ³ã‚¯<=3ï¼‰\n",
    "        top3_pred = (y_pred_clipped <= 3).astype(int)\n",
    "        top3_true = (y_true <= 3).astype(int)\n",
    "        metrics['top3_hit_rate'] = accuracy_score(top3_true, top3_pred)\n",
    "        \n",
    "        # TOP3ã®Spearmanç›¸é–¢\n",
    "        top3_mask = (y_true <= 3) | (y_pred_clipped <= 3)\n",
    "        if top3_mask.sum() >= 3:\n",
    "            spearman_top3, _ = spearmanr(y_true[top3_mask], y_pred_clipped[top3_mask])\n",
    "            metrics['spearman_top3'] = spearman_top3 if not np.isnan(spearman_top3) else 0.0\n",
    "        else:\n",
    "            metrics['spearman_top3'] = 0.0\n",
    "    \n",
    "    # =====================================\n",
    "    # 3. åˆ©ç›ŠæŒ‡æ¨™ï¼ˆå…±é€šï¼‰\n",
    "    # =====================================\n",
    "    \n",
    "    if 'current_diff' in test_data.columns:\n",
    "        try:\n",
    "            # äºˆæ¸¬æ­£è§£æ™‚ã®å·®æš\n",
    "            if task_type == 'binary':\n",
    "                y_pred_binary = (y_pred >= 0.5).astype(int) if y_pred.min() >= 0 and y_pred.max() <= 1 else y_pred\n",
    "                correct_mask = (y_pred_binary == y_true)\n",
    "            else:\n",
    "                # å›å¸°ã®å ´åˆã€äºˆæ¸¬ãƒ©ãƒ³ã‚¯ã¨çœŸå®Ÿãƒ©ãƒ³ã‚¯ãŒ3ä»¥å†…ãªã‚‰æ­£è§£\n",
    "                y_pred_clipped = np.clip(y_pred, CONFIG['MIN_RANK'], CONFIG['MAX_RANK'])\n",
    "                correct_mask = np.abs(y_pred_clipped - y_true) <= 3\n",
    "            \n",
    "            # å¹³å‡åˆ©ç›Š\n",
    "            if correct_mask.sum() > 0:\n",
    "                metrics['avg_predicted_profit'] = test_data.loc[correct_mask, 'current_diff'].mean()\n",
    "                metrics['avg_correct_profit'] = test_data.loc[correct_mask, 'current_diff'].mean()\n",
    "            else:\n",
    "                metrics['avg_predicted_profit'] = 0.0\n",
    "                metrics['avg_correct_profit'] = 0.0\n",
    "            \n",
    "            # åˆ©ç›ŠåŠ¹ç‡ï¼ˆå®Ÿç¾åˆ©ç›Š / æœŸå¾…åˆ©ç›Šï¼‰\n",
    "            total_profit = test_data['current_diff'].sum()\n",
    "            correct_profit = test_data.loc[correct_mask, 'current_diff'].sum()\n",
    "            \n",
    "            if total_profit > 0:\n",
    "                metrics['profit_loss_rate'] = correct_profit / total_profit\n",
    "            else:\n",
    "                metrics['profit_loss_rate'] = 0.0\n",
    "        except:\n",
    "            metrics['avg_predicted_profit'] = np.nan\n",
    "            metrics['avg_correct_profit'] = np.nan\n",
    "            metrics['profit_loss_rate'] = np.nan\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_unified_metrics(metrics, event_name='', task_name=''):\n",
    "    \"\"\"\n",
    "    çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè©•ä¾¡æŒ‡æ¨™ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metrics : dict\n",
    "        è©•ä¾¡æŒ‡æ¨™è¾æ›¸\n",
    "    event_name : str\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "    task_name : str\n",
    "        ã‚¿ã‚¹ã‚¯å\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ“Š è©•ä¾¡çµæœ: {event_name} - {task_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # å…±é€šæŒ‡æ¨™\n",
    "    print(f\"\\nã€å…±é€šæŒ‡æ¨™ã€‘\")\n",
    "    print(f\"  MAE (å¹³å‡çµ¶å¯¾èª¤å·®):      {metrics.get('mae', np.nan):.4f}\")\n",
    "    print(f\"  RMSE (äºŒä¹—å¹³å‡å¹³æ–¹æ ¹):  {metrics.get('rmse', np.nan):.4f}\")\n",
    "    print(f\"  Spearmanç›¸é–¢:          {metrics.get('spearman_corr', np.nan):.4f}\")\n",
    "    \n",
    "    # ã‚¿ã‚¹ã‚¯åˆ¥æŒ‡æ¨™\n",
    "    if 'accuracy' in metrics:\n",
    "        print(f\"\\nã€äºŒå€¤åˆ†é¡æŒ‡æ¨™ã€‘\")\n",
    "        print(f\"  Accuracy (ç²¾åº¦):       {metrics.get('accuracy', np.nan):.4f}\")\n",
    "        print(f\"  F1ã‚¹ã‚³ã‚¢:              {metrics.get('f1', np.nan):.4f}\")\n",
    "        print(f\"  Precision (é©åˆç‡):    {metrics.get('precision', np.nan):.4f}\")\n",
    "        print(f\"  Recall (å†ç¾ç‡):       {metrics.get('recall', np.nan):.4f}\")\n",
    "        if 'roc_auc' in metrics and not np.isnan(metrics['roc_auc']):\n",
    "            print(f\"  ROC-AUC:              {metrics.get('roc_auc', np.nan):.4f}\")\n",
    "    \n",
    "    if 'top3_hit_rate' in metrics:\n",
    "        print(f\"\\nã€å›å¸°æŒ‡æ¨™ï¼ˆãƒ©ãƒ³ã‚¯å­¦ç¿’ï¼‰ã€‘\")\n",
    "        print(f\"  TOP3å‘½ä¸­ç‡:            {metrics.get('top3_hit_rate', np.nan):.4f}\")\n",
    "        print(f\"  TOP3 Spearmanç›¸é–¢:     {metrics.get('spearman_top3', np.nan):.4f}\")\n",
    "    \n",
    "    # åˆ©ç›ŠæŒ‡æ¨™\n",
    "    if 'avg_predicted_profit' in metrics:\n",
    "        print(f\"\\nã€åˆ©ç›ŠæŒ‡æ¨™ã€‘\")\n",
    "        print(f\"  å¹³å‡åˆ©ç›Š:              {metrics.get('avg_predicted_profit', np.nan):.1f} æš\")\n",
    "        print(f\"  åˆ©ç›ŠåŠ¹ç‡:              {metrics.get('profit_loss_rate', np.nan):.4f}\")\n",
    "\n",
    "\n",
    "def get_best_metric(metrics, task_type='binary'):\n",
    "    \"\"\"\n",
    "    ã‚¿ã‚¹ã‚¯åˆ¥ã®ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒç”¨ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metrics : dict\n",
    "        è©•ä¾¡æŒ‡æ¨™è¾æ›¸\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : 0-1ã®ç·åˆã‚¹ã‚³ã‚¢\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = {}\n",
    "    score_components = []\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        # F1ã‚¹ã‚³ã‚¢ã‚’ä¸»è¦æŒ‡æ¨™ã¨ã™ã‚‹ï¼ˆ0.5ã®é‡ã¿ï¼‰\n",
    "        f1 = metrics.get('f1', 0.0)\n",
    "        score_components.append(f1 * 0.5)\n",
    "        \n",
    "        # Precisioné‡è¦–ï¼ˆç²¾åº¦ã®èª¤ã‚Šã‚’é‡è¦–ï¼š0.3ã®é‡ã¿ï¼‰\n",
    "        precision = metrics.get('precision', 0.0)\n",
    "        score_components.append(precision * 0.3)\n",
    "        \n",
    "        # Recallï¼ˆ0.2ã®é‡ã¿ï¼‰\n",
    "        recall = metrics.get('recall', 0.0)\n",
    "        score_components.append(recall * 0.2)\n",
    "    \n",
    "    elif task_type == 'regression':\n",
    "        # TOP3å‘½ä¸­ç‡ã‚’ä¸»è¦æŒ‡æ¨™ï¼ˆ0.5ã®é‡ã¿ï¼‰\n",
    "        top3_hit = metrics.get('top3_hit_rate', 0.0)\n",
    "        score_components.append(top3_hit * 0.5)\n",
    "        \n",
    "        # Spearmanç›¸é–¢ã‚’æ­£è¦åŒ–ï¼ˆ-1-1ã‚’0-1ã«ï¼‰\n",
    "        spearman = metrics.get('spearman_corr', 0.0)\n",
    "        spearman_normalized = (spearman + 1.0) / 2.0\n",
    "        score_components.append(spearman_normalized * 0.3)\n",
    "        \n",
    "        # TOP3ç‰¹åŒ–ã®ç›¸é–¢ï¼ˆ0.2ã®é‡ã¿ï¼‰\n",
    "        spearman_top3 = metrics.get('spearman_top3', 0.0)\n",
    "        spearman_top3_normalized = (spearman_top3 + 1.0) / 2.0\n",
    "        score_components.append(spearman_top3_normalized * 0.2)\n",
    "    \n",
    "    # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "    total_score = sum(score_components)\n",
    "    return np.clip(total_score, 0.0, 1.0)\n",
    "\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«06: çµ±ä¸€çš„ãªè©•ä¾¡é–¢æ•°ã®å®šç¾©å®Œäº†\")\n",
    "print(\"   ğŸ“Š evaluate_unified_metrics(y_true, y_pred, test_data, task_type)\")\n",
    "print(\"   ğŸ“‹ print_unified_metrics(metrics, event_name, task_name)\")\n",
    "print(\"   â­ get_best_metric(metrics, task_type)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«07: ãƒ©ãƒ™ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿æº–å‚™é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_top_labels(df, event, rank=1):\n",
    "    \"\"\"\n",
    "    TOP1/TOP2ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆï¼ˆäºŒå€¤åˆ†é¡ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "    event : str\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "    rank : int\n",
    "        1 for TOP1, 2 for TOP2\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series : äºŒå€¤ãƒ©ãƒ™ãƒ«ï¼ˆãƒ©ãƒ³ã‚¯<=rankã®æœ«å°¾=1, ãã®ä»–=0ï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    label_col = 'last_digit_rank_diff'\n",
    "    \n",
    "    if label_col not in df.columns:\n",
    "        raise ValueError(f\"{label_col}åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    \n",
    "    # ãƒ©ãƒ³ã‚¯å€¤ãŒrankä»¥ä¸‹ = é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ = 1\n",
    "    # ãƒ©ãƒ³ã‚¯å€¤ãŒrankè¶…é = ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ = 0\n",
    "    labels = (df[label_col] <= rank).astype(int)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def create_rank_labels(df):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ã‚¯å­¦ç¿’ç”¨ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆï¼ˆå›å¸°ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series : ãƒ©ãƒ³ã‚¯å€¤ï¼ˆ1-11ï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = df['last_digit_rank_diff'].copy()\n",
    "    \n",
    "    # NaNå‡¦ç†\n",
    "    labels = labels.fillna(6.0)  # ä¸­å¤®å€¤ã¨ã—ã¦6.0ã‚’ä½¿ç”¨\n",
    "    \n",
    "    # ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ1-11ã«æ­£è¦åŒ–ï¼‰\n",
    "    labels = np.clip(labels, CONFIG['MIN_RANK'], CONFIG['MAX_RANK'])\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def prepare_unified_data(df, event, task_type='binary', rank=1):\n",
    "    \"\"\"\n",
    "    çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "    event : str\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåï¼ˆä¾‹: '1day', '2day'ï¼‰\n",
    "    task_type : str\n",
    "        'binary' (TOP1/TOP2) or 'regression' (ãƒ©ãƒ³ã‚¯å­¦ç¿’)\n",
    "    rank : int\n",
    "        TOPé †ä½ï¼ˆäºŒå€¤åˆ†é¡ã®å ´åˆã®ã¿ä½¿ç”¨ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (X_train, y_train, X_test, y_test, test_data, feature_cols)\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================\n",
    "    # 1. ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã§è©²å½“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º\n",
    "    # =========================================\n",
    "    \n",
    "    flag_col = f'is_{event}'\n",
    "    \n",
    "    if flag_col not in df.columns:\n",
    "        raise ValueError(f\"ã‚¤ãƒ™ãƒ³ãƒˆåˆ—'{flag_col}'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    \n",
    "    event_data = df[df[flag_col] == 1].copy().reset_index(drop=True)\n",
    "    \n",
    "    if len(event_data) == 0:\n",
    "        raise ValueError(f\"ã‚¤ãƒ™ãƒ³ãƒˆ'{event}'ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™\")\n",
    "    \n",
    "    # =========================================\n",
    "    # 2. ãƒ©ãƒ™ãƒ«ã®ç”Ÿæˆ\n",
    "    # =========================================\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        labels = create_top_labels(event_data, event, rank)\n",
    "        task_name = f'TOP{rank}'\n",
    "    elif task_type == 'regression':\n",
    "        labels = create_rank_labels(event_data)\n",
    "        task_name = 'Rank_Learning'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown task_type: {task_type}\")\n",
    "    \n",
    "    # =========================================\n",
    "    # 3. ç‰¹å¾´é‡åˆ—ã®è‡ªå‹•æ¤œå‡º\n",
    "    # =========================================\n",
    "    \n",
    "    exclude_patterns = [\n",
    "        'date', 'event', 'target', 'label', 'current_diff',\n",
    "        'last_digit_rank', 'digit_num', 'last_digit', 'is_'\n",
    "    ]\n",
    "    \n",
    "    feature_cols = []\n",
    "    for col in event_data.columns:\n",
    "        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯\n",
    "        if any(pattern in col.lower() for pattern in exclude_patterns):\n",
    "            continue\n",
    "        \n",
    "        # æ•°å€¤å‹ã®ã¿\n",
    "        if event_data[col].dtype in ['int64', 'float64']:\n",
    "            feature_cols.append(col)\n",
    "    \n",
    "    if len(feature_cols) == 0:\n",
    "        raise ValueError(\"ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    \n",
    "    print(f\"âœ… ã‚¿ã‚¹ã‚¯: {task_name}\")\n",
    "    print(f\"   ç‰¹å¾´é‡æ•°: {len(feature_cols)}å€‹\")\n",
    "    print(f\"   ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {pd.Series(labels).value_counts().to_dict()}\")\n",
    "    \n",
    "    # =========================================\n",
    "    # 4. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆæ™‚ç³»åˆ—åˆ†å‰²ï¼‰\n",
    "    # =========================================\n",
    "    \n",
    "    # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ\n",
    "    if 'date' in event_data.columns:\n",
    "        event_data = event_data.sort_values('date').reset_index(drop=True)\n",
    "        unique_dates = event_data['date'].unique()\n",
    "    else:\n",
    "        unique_dates = np.arange(len(event_data))\n",
    "    \n",
    "    n_dates = len(unique_dates)\n",
    "    n_test = max(1, int(n_dates * CONFIG['TEST_SIZE']))\n",
    "    n_train = n_dates - n_test\n",
    "    \n",
    "    # æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆæœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã¯ãƒ†ã‚¹ãƒˆã«ï¼‰\n",
    "    if 'date' in event_data.columns:\n",
    "        train_dates = set(unique_dates[:n_train])\n",
    "        train_mask = event_data['date'].isin(train_dates)\n",
    "    else:\n",
    "        train_mask = np.arange(len(event_data)) < int(n_train * len(event_data))\n",
    "    \n",
    "    test_mask = ~train_mask\n",
    "    \n",
    "    # =========================================\n",
    "    # 5. ç‰¹å¾´é‡ãƒ»ãƒ©ãƒ™ãƒ«æŠ½å‡º\n",
    "    # =========================================\n",
    "    \n",
    "    X = event_data[feature_cols].copy()\n",
    "    y = labels.reset_index(drop=True)\n",
    "    \n",
    "    # NaNå‡¦ç†\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # ç„¡é™å€¤å‡¦ç†\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²\n",
    "    X_train = X[train_mask].reset_index(drop=True)\n",
    "    y_train = y[train_mask].reset_index(drop=True)\n",
    "    X_test = X[test_mask].reset_index(drop=True)\n",
    "    y_test = y[test_mask].reset_index(drop=True)\n",
    "    \n",
    "    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©³ç´°æƒ…å ±ã‚’ä¿æŒ\n",
    "    test_data = event_data[test_mask].reset_index(drop=True)\n",
    "    \n",
    "    # =========================================\n",
    "    # 6. çµ±è¨ˆæƒ…å ±å‡ºåŠ›\n",
    "    # =========================================\n",
    "    \n",
    "    print(f\"\\n   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)} ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "    print(f\"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)} ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        print(f\"   è¨“ç·´ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {pd.Series(y_train).value_counts().to_dict()}\")\n",
    "        print(f\"   ãƒ†ã‚¹ãƒˆãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {pd.Series(y_test).value_counts().to_dict()}\")\n",
    "        \n",
    "        # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã®è­¦å‘Š\n",
    "        label_counts = pd.Series(y_train).value_counts()\n",
    "        if len(label_counts) == 2:\n",
    "            ratio = label_counts.iloc[1] / label_counts.iloc[0]\n",
    "            if ratio < 0.2 or ratio > 5:\n",
    "                print(f\"   âš ï¸  ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡: {ratio:.2f}å€ (ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ã®å¯èƒ½æ€§ã‚ã‚Š)\")\n",
    "    else:\n",
    "        print(f\"   è¨“ç·´ãƒ©ãƒ™ãƒ«çµ±è¨ˆ: mean={y_train.mean():.2f}, std={y_train.std():.2f}\")\n",
    "        print(f\"   ãƒ†ã‚¹ãƒˆãƒ©ãƒ™ãƒ«çµ±è¨ˆ: mean={y_test.mean():.2f}, std={y_test.std():.2f}\")\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, test_data, feature_cols\n",
    "\n",
    "\n",
    "def validate_data(X_train, y_train, X_test, y_test, task_type='binary'):\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train, X_test, y_test : array-like\n",
    "        è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : å¦¥å½“ãªå ´åˆTrue\n",
    "    \"\"\"\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯1: ã‚µã‚¤ã‚º\n",
    "    if len(X_train) < 10:\n",
    "        errors.append(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™: {len(X_train)} < 10\")\n",
    "    \n",
    "    if len(X_test) < 5:\n",
    "        errors.append(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™: {len(X_test)} < 5\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯2: ç‰¹å¾´é‡\n",
    "    if X_train.shape[1] == 0:\n",
    "        errors.append(\"ç‰¹å¾´é‡ãŒå­˜åœ¨ã—ã¾ã›ã‚“\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯3: NaN\n",
    "    if X_train.isnull().sum().sum() > 0:\n",
    "        errors.append(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«NaNãŒå­˜åœ¨: {X_train.isnull().sum().sum()}\")\n",
    "    \n",
    "    if y_train.isnull().sum() > 0:\n",
    "        errors.append(f\"è¨“ç·´ãƒ©ãƒ™ãƒ«ã«NaNãŒå­˜åœ¨: {y_train.isnull().sum()}\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯4: ç„¡é™å€¤\n",
    "    if np.isinf(X_train.values).sum() > 0:\n",
    "        errors.append(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ç„¡é™å€¤ãŒå­˜åœ¨\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯5: ã‚¿ã‚¹ã‚¯åˆ¥ãƒã‚§ãƒƒã‚¯\n",
    "    if task_type == 'binary':\n",
    "        unique_labels = np.unique(y_train)\n",
    "        if len(unique_labels) < 2:\n",
    "            errors.append(f\"äºŒå€¤åˆ†é¡ãªã®ã«1ã‚¯ãƒ©ã‚¹ã®ã¿: {unique_labels}\")\n",
    "    \n",
    "    elif task_type == 'regression':\n",
    "        if y_train.min() < CONFIG['MIN_RANK'] or y_train.max() > CONFIG['MAX_RANK']:\n",
    "            errors.append(f\"ãƒ©ãƒ™ãƒ«ãŒç¯„å›²å¤–: [{y_train.min()}, {y_train.max()}]\")\n",
    "    \n",
    "    # ã‚¨ãƒ©ãƒ¼å‡ºåŠ›\n",
    "    if errors:\n",
    "        print(f\"\\nâš ï¸  ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼:\")\n",
    "        for error in errors:\n",
    "            print(f\"   â€¢ {error}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"\\nâœ… ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼: OK\")\n",
    "        return True\n",
    "\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«07: ãƒ©ãƒ™ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿æº–å‚™é–¢æ•°ã®å®šç¾©å®Œäº†\")\n",
    "print(\"   ğŸ·ï¸  create_top_labels(df, event, rank)\")\n",
    "print(\"   ğŸ“Š create_rank_labels(df)\")\n",
    "print(\"   ğŸ“¦ prepare_unified_data(df, event, task_type, rank)\")\n",
    "print(\"   âœ”ï¸  validate_data(X_train, y_train, X_test, y_test, task_type)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«08: Optunaæœ€é©åŒ–é–¢æ•°ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, mean_absolute_error\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«08ã€‘Optunaæœ€é©åŒ–é–¢æ•°å®šç¾©\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "def run_optuna_optimization(X_train, y_train, X_test, y_test, task_type='binary', \n",
    "                           ranking_mode=None, n_trials=20, cv_folds=3):\n",
    "    \"\"\"\n",
    "    çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®Optunaæœ€é©åŒ–å®Ÿè¡Œ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : array-like\n",
    "        è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "    X_test, y_test : array-like\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    ranking_mode : str\n",
    "        'baseline' or 'top3_focus' (regressionã®å ´åˆ)\n",
    "    n_trials : int\n",
    "        Optunaè©¦è¡Œå›æ•°\n",
    "    cv_folds : int\n",
    "        Cross-validationåˆ†å‰²æ•°\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    optuna.study.Study\n",
    "        æœ€é©åŒ–çµæœï¼ˆstudy.best_paramsï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Optunaæœ€é©åŒ–é–‹å§‹\")\n",
    "    print(f\"   ã‚¿ã‚¤ãƒ—: {task_type}\")\n",
    "    if ranking_mode:\n",
    "        print(f\"   ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {ranking_mode}\")\n",
    "    print(f\"   è©¦è¡Œå›æ•°: {n_trials}\")\n",
    "    \n",
    "    # ç›®çš„é–¢æ•°å®šç¾©\n",
    "    def objective(trial):\n",
    "        \n",
    "        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—é¸æŠ\n",
    "        model_name = trial.suggest_categorical('model_name', ['RandomForest', 'Ridge', 'LightGBM'])\n",
    "        \n",
    "        if task_type == 'binary':\n",
    "            # äºŒå€¤åˆ†é¡ã®å ´åˆ\n",
    "            if model_name == 'RandomForest':\n",
    "                model = RandomForestClassifier(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "                    min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "                    class_weight='balanced',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                \n",
    "            elif model_name == 'Ridge':\n",
    "                from sklearn.linear_model import LogisticRegression\n",
    "                model = LogisticRegression(\n",
    "                    C=trial.suggest_float('C', 0.01, 10, log=True),\n",
    "                    class_weight='balanced',\n",
    "                    max_iter=1000,\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "            elif model_name == 'LightGBM':\n",
    "                from lightgbm import LGBMClassifier\n",
    "                pos_weight = (y_train == 0).sum() / max((y_train == 1).sum(), 1)\n",
    "                model = LGBMClassifier(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "                    learning_rate=trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "                    scale_pos_weight=pos_weight,\n",
    "                    random_state=42,\n",
    "                    verbose=-1\n",
    "                )\n",
    "            \n",
    "            # CVå®Ÿè¡Œï¼ˆF1ã‚¹ã‚³ã‚¢ï¼‰\n",
    "            cv_scores = cross_val_score(\n",
    "                model, X_train, y_train,\n",
    "                cv=cv_folds,\n",
    "                scoring='f1_weighted'\n",
    "            )\n",
    "            score = cv_scores.mean()\n",
    "            \n",
    "        else:  # regression\n",
    "            # å›å¸°ã®å ´åˆ\n",
    "            if model_name == 'RandomForest':\n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "                    min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                \n",
    "            elif model_name == 'Ridge':\n",
    "                model = Ridge(\n",
    "                    alpha=trial.suggest_float('alpha', 0.1, 100, log=True),\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "            elif model_name == 'LightGBM':\n",
    "                from lightgbm import LGBMRegressor\n",
    "                model = LGBMRegressor(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "                    learning_rate=trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "                    random_state=42,\n",
    "                    verbose=-1\n",
    "                )\n",
    "            \n",
    "            # CVå®Ÿè¡Œï¼ˆMAEï¼‰\n",
    "            cv_scores = cross_val_score(\n",
    "                model, X_train, y_train,\n",
    "                cv=cv_folds,\n",
    "                scoring='neg_mean_absolute_error'\n",
    "            )\n",
    "            score = -cv_scores.mean()  # æœ€å°åŒ–ã™ã‚‹ãŸã‚è² å·åè»¢\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    # æœ€é©åŒ–å®Ÿè¡Œ\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize' if task_type == 'binary' else 'minimize',\n",
    "        pruner=MedianPruner()\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    \n",
    "    print(f\"   âœ… æœ€é©ã‚¹ã‚³ã‚¢: {study.best_value:.4f}\")\n",
    "    print(f\"   ğŸ“‹ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {study.best_params}\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«08: Optunaæœ€é©åŒ–é–¢æ•°å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«09: ç‰¹å¾´é‡é¸æŠé–¢æ•°ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«09ã€‘ç‰¹å¾´é‡é¸æŠé–¢æ•°å®šç¾©\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "def select_features_unified(X_train, y_train, X_test, task_type='binary', method='ensemble'):\n",
    "    \"\"\"\n",
    "    çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ\n",
    "    \n",
    "    è¤‡æ•°ã®æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦å …ç‰¢ãªç‰¹å¾´é‡é¸æŠã‚’å®Ÿç¾\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : DataFrame/ndarray\n",
    "        è¨“ç·´ç‰¹å¾´é‡\n",
    "    y_train : Series/ndarray\n",
    "        è¨“ç·´ãƒ©ãƒ™ãƒ«\n",
    "    X_test : DataFrame/ndarray\n",
    "        ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡\n",
    "    task_type : str\n",
    "        'binary' (äºŒå€¤åˆ†é¡) or 'regression' (å›å¸°)\n",
    "    method : str\n",
    "        'lasso', 'f_test', 'mutual_info', 'ensemble'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : {\n",
    "        'X_train_filtered': é¸æŠå¾Œã®è¨“ç·´ç‰¹å¾´é‡,\n",
    "        'X_test_filtered': é¸æŠå¾Œã®ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡,\n",
    "        'selected_features': é¸æŠç‰¹å¾´é‡ãƒªã‚¹ãƒˆ,\n",
    "        'feature_importance': ç‰¹å¾´é‡é‡è¦åº¦,\n",
    "        'n_selected': é¸æŠç‰¹å¾´é‡æ•°\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.feature_selection import SelectKBest, f_classif, f_regression, mutual_info_classif, mutual_info_regression\n",
    "    from sklearn.linear_model import Lasso, LassoCV\n",
    "    \n",
    "    # DataFrameã‹ã‚‰ã‚«ãƒ©ãƒ åã‚’æŠ½å‡º\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        feature_names = X_train.columns.tolist()\n",
    "        X_train_array = X_train.values\n",
    "        X_test_array = X_test.values\n",
    "    else:\n",
    "        feature_names = [f'feature_{i}' for i in range(X_train.shape[1])]\n",
    "        X_train_array = X_train\n",
    "        X_test_array = X_test\n",
    "    \n",
    "    print(f\"\\nğŸ” ç‰¹å¾´é‡é¸æŠé–‹å§‹ï¼ˆæ–¹æ³•: {method}ï¼‰\")\n",
    "    print(f\"   åˆæœŸç‰¹å¾´é‡æ•°: {len(feature_names)}\")\n",
    "    \n",
    "    # =========================================\n",
    "    # Phase 1: ç›¸é–¢é™¤å»ï¼ˆé«˜ç›¸é–¢ã‚’å‰Šé™¤ï¼‰\n",
    "    # =========================================\n",
    "    \n",
    "    print(f\"\\n   Phase 1: ç›¸é–¢é™¤å» (é–¾å€¤: {CONFIG.get('CORRELATION_THRESHOLD', 0.95)})...\")\n",
    "    \n",
    "    corr_matrix = pd.DataFrame(X_train_array, columns=feature_names).corr().abs()\n",
    "    upper_triangle = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    high_corr_features = set()\n",
    "    for column in upper_triangle.columns:\n",
    "        high_corr_cols = upper_triangle[column][upper_triangle[column] > CONFIG.get('CORRELATION_THRESHOLD', 0.95)].index\n",
    "        high_corr_features.update(high_corr_cols)\n",
    "    \n",
    "    features_after_corr = [f for f in feature_names if f not in high_corr_features]\n",
    "    print(f\"      ç›¸é–¢é™¤å»å¾Œ: {len(features_after_corr)}å€‹ï¼ˆå‰Šé™¤: {len(high_corr_features)}å€‹ï¼‰\")\n",
    "    \n",
    "    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹æˆ\n",
    "    feature_indices = [i for i, f in enumerate(feature_names) if f in features_after_corr]\n",
    "    X_train_filtered = X_train_array[:, feature_indices]\n",
    "    X_test_filtered = X_test_array[:, feature_indices]\n",
    "    feature_names = features_after_corr\n",
    "    \n",
    "    # =========================================\n",
    "    # Phase 2: è¤‡æ•°æ‰‹æ³•ã«ã‚ˆã‚‹ç‰¹å¾´é‡ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°\n",
    "    # =========================================\n",
    "    \n",
    "    print(f\"\\n   Phase 2: ç‰¹å¾´é‡ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°...\")\n",
    "    \n",
    "    feature_votes = {f: 0 for f in feature_names}\n",
    "    \n",
    "    # æ‰‹æ³•1: Lasso (æ­£å‰‡åŒ–)\n",
    "    try:\n",
    "        if task_type == 'binary':\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            model_lasso = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000, random_state=42)\n",
    "            model_lasso.fit(X_train_filtered, y_train)\n",
    "            lasso_coef = np.abs(model_lasso.coef_[0])\n",
    "        else:\n",
    "            lasso_model = LassoCV(cv=3, max_iter=10000, random_state=42)\n",
    "            lasso_model.fit(X_train_filtered, y_train)\n",
    "            lasso_coef = np.abs(lasso_model.coef_)\n",
    "        \n",
    "        lasso_features = [f for f, c in zip(feature_names, lasso_coef) if c > np.percentile(lasso_coef, 50)]\n",
    "        for f in lasso_features:\n",
    "            feature_votes[f] += 1\n",
    "        print(f\"      Lasso: {len(lasso_features)}å€‹æ¨å¥¨\")\n",
    "    except:\n",
    "        print(f\"      Lasso: ã‚¹ã‚­ãƒƒãƒ—\")\n",
    "    \n",
    "    # æ‰‹æ³•2: Fæ¤œå®šã¾ãŸã¯MI\n",
    "    try:\n",
    "        if task_type == 'binary':\n",
    "            selector = SelectKBest(f_classif, k=min(len(feature_names)//2, CONFIG.get('MAX_FEATURES', 80)))\n",
    "        else:\n",
    "            selector = SelectKBest(f_regression, k=min(len(feature_names)//2, CONFIG.get('MAX_FEATURES', 80)))\n",
    "        \n",
    "        selector.fit(X_train_filtered, y_train)\n",
    "        f_test_features = [f for f, s in zip(feature_names, selector.get_support()) if s]\n",
    "        for f in f_test_features:\n",
    "            feature_votes[f] += 1\n",
    "        print(f\"      Fæ¤œå®š: {len(f_test_features)}å€‹æ¨å¥¨\")\n",
    "    except:\n",
    "        print(f\"      Fæ¤œå®š: ã‚¹ã‚­ãƒƒãƒ—\")\n",
    "    \n",
    "    # æ‰‹æ³•3: Tree-based importance\n",
    "    try:\n",
    "        tree_model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1) if task_type == 'binary' \\\n",
    "                    else RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "        tree_model.fit(X_train_filtered, y_train)\n",
    "        tree_features = [f for f, imp in zip(feature_names, tree_model.feature_importances_) \n",
    "                        if imp > np.percentile(tree_model.feature_importances_, 50)]\n",
    "        for f in tree_features:\n",
    "            feature_votes[f] += 1\n",
    "        print(f\"      Tree: {len(tree_features)}å€‹æ¨å¥¨\")\n",
    "    except:\n",
    "        print(f\"      Tree: ã‚¹ã‚­ãƒƒãƒ—\")\n",
    "    \n",
    "    # =========================================\n",
    "    # Phase 3: æŠ•ç¥¨ãƒ™ãƒ¼ã‚¹çµ±åˆ\n",
    "    # =========================================\n",
    "    \n",
    "    print(f\"\\n   Phase 3: æŠ•ç¥¨çµ±åˆ...\")\n",
    "    \n",
    "    # è¤‡æ•°æ‰‹æ³•ã‹ã‚‰æ¨å¥¨ã•ã‚ŒãŸç‰¹å¾´é‡ã®ã¿é¸æŠ\n",
    "    selected_features = [f for f, votes in feature_votes.items() if votes >= 1]\n",
    "    \n",
    "    # ç‰¹å¾´é‡æ•°ã‚’åˆ¶é™\n",
    "    min_features = CONFIG.get('MIN_FEATURES', 20)\n",
    "    max_features = CONFIG.get('MAX_FEATURES', 80)\n",
    "    \n",
    "    if len(selected_features) < min_features:\n",
    "        selected_features = list(feature_votes.keys())[:min_features]\n",
    "    elif len(selected_features) > max_features:\n",
    "        selected_features = sorted(selected_features, key=lambda f: feature_votes[f], reverse=True)[:max_features]\n",
    "    \n",
    "    print(f\"      æœ€çµ‚é¸æŠ: {len(selected_features)}å€‹ï¼ˆæœ€å°: {min_features}, æœ€å¤§: {max_features}ï¼‰\")\n",
    "    \n",
    "    # =========================================\n",
    "    # Phase 4: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "    # =========================================\n",
    "    \n",
    "    selected_indices = [i for i, f in enumerate(feature_names) if f in selected_features]\n",
    "    X_train_final = X_train_filtered[:, selected_indices]\n",
    "    X_test_final = X_test_filtered[:, selected_indices]\n",
    "    selected_features_final = [feature_names[i] for i in selected_indices]\n",
    "    \n",
    "    # ç‰¹å¾´é‡é‡è¦åº¦\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': selected_features_final,\n",
    "        'votes': [feature_votes.get(f, 0) for f in selected_features_final]\n",
    "    }).sort_values('votes', ascending=False)\n",
    "    \n",
    "    result = {\n",
    "        'X_train_filtered': X_train_final,\n",
    "        'X_test_filtered': X_test_final,\n",
    "        'selected_features': selected_features_final,\n",
    "        'feature_importance': feature_importance,\n",
    "        'n_selected': len(selected_features_final)\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ… ç‰¹å¾´é‡é¸æŠå®Œäº†: {result['n_selected']}å€‹\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«09: ç‰¹å¾´é‡é¸æŠé–¢æ•°å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«10ä¿®æ­£ç‰ˆï¼šlast_digit_rank_diff ã‚’ y ã¨ã—ã¦åˆ†é›¢ + ç‰¹å¾´é‡ã‹ã‚‰é™¤å¤–\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«10ä¿®æ­£ç‰ˆã€‘last_digit_rank_diff ã‚’ y ã¨ã—ã¦åˆ†é›¢ï¼ˆç‰¹å¾´é‡ã‹ã‚‰ã¯é™¤å¤–ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—0: å‰ææ¡ä»¶ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—0ã€‘å‰ææ¡ä»¶ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«05ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"âœ… df_merged: {df_merged.shape}\")\n",
    "print(f\"âœ… æ—¥ä»˜ç¯„å›²: {df_merged['date_num'].min()} ï½ {df_merged['date_num'].max()}\")\n",
    "\n",
    "# ç›®çš„å¤‰æ•°ã®ç¢ºèª\n",
    "if 'last_digit_rank_diff' not in df_merged.columns:\n",
    "    raise RuntimeError(\"âŒ last_digit_rank_diff ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«05ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"âœ… last_digit_rank_diff: ä¿æŒ\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—1: å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ï¼‰\n",
    "test_event = 'is_1day'\n",
    "\n",
    "if test_event not in df_merged.columns:\n",
    "    raise RuntimeError(f\"âŒ {test_event} ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "\n",
    "event_data = df_merged[df_merged[test_event] == 1].copy()\n",
    "print(f\"ã‚¤ãƒ™ãƒ³ãƒˆ: {test_event}\")\n",
    "print(f\"ã‚¤ãƒ™ãƒ³ãƒˆæ—¥æ•°: {len(event_data) // 11} æ—¥ï¼ˆ{len(event_data)} è¡Œï¼‰\")\n",
    "\n",
    "if len(event_data) < 22:\n",
    "    raise RuntimeError(f\"âŒ ã‚¤ãƒ™ãƒ³ãƒˆæ—¥æ•°ãŒå°‘ãªã™ãã¾ã™ï¼ˆæœ€ä½2æ—¥å¿…è¦ï¼‰\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—2: æ—¥ä»˜é †ã§ã®ã‚½ãƒ¼ãƒˆ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜é †ã‚½ãƒ¼ãƒˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "event_data = event_data.sort_values(['date_num', 'digit_num']).reset_index(drop=True)\n",
    "\n",
    "# 1æ—¥11è¡Œã®ç¢ºèª\n",
    "day_sizes = event_data.groupby('date_num').size()\n",
    "if day_sizes.min() != 11 or day_sizes.max() != 11:\n",
    "    print(f\"âš ï¸  ç•°å¸¸ãªæ—¥ä»˜ãŒã‚ã‚Šã¾ã™ãŒç¶šè¡Œã—ã¾ã™\")\n",
    "else:\n",
    "    print(f\"âœ… ã™ã¹ã¦ã®æ—¥ä»˜ãŒ11è¡Œï¼ˆæ­£å¸¸ï¼‰\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—3: ç›®çš„å¤‰æ•° y ã®æŠ½å‡º\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘ç›®çš„å¤‰æ•° y ã®æŠ½å‡ºï¼ˆlast_digit_rank_diff ã‚’ä½¿ç”¨ï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# last_digit_rank_diff ã‚’ y ã¨ã—ã¦æŠ½å‡º\n",
    "y_raw = event_data['last_digit_rank_diff'].values\n",
    "\n",
    "print(f\"âœ… ç›®çš„å¤‰æ•° y ã‚’æŠ½å‡º\")\n",
    "print(f\"   å½¢çŠ¶: {y_raw.shape}\")\n",
    "print(f\"   çµ±è¨ˆ: mean={y_raw.mean():.2f}, std={y_raw.std():.2f}, min={y_raw.min()}, max={y_raw.max()}\")\n",
    "print(f\"   å€¤ã®åˆ†å¸ƒ: {np.bincount(y_raw.astype(int))}\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ X ã®æº–å‚™\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘ç‰¹å¾´é‡ X ã®æº–å‚™\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ©ãƒ™ãƒ«ãƒ»ç›®çš„å¤‰æ•°ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰\n",
    "exclude_patterns = [\n",
    "    'date_num', 'digit_num', 'last_digit', 'is_',  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°\n",
    "    'last_digit_rank',  # âœ… ç›®çš„å¤‰æ•°ã¨é–¢é€£ã‚«ãƒ©ãƒ ã‚’é™¤å¤–ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰\n",
    "]\n",
    "\n",
    "numeric_cols = event_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [\n",
    "    col for col in numeric_cols\n",
    "    if not any(pattern in col.lower() for pattern in exclude_patterns)\n",
    "]\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾´é‡ã‚«ãƒ©ãƒ æ•°: {len(feature_cols)}\")\n",
    "print(f\"   ä¾‹: {feature_cols[:10]}\")\n",
    "\n",
    "# ç‰¹å¾´é‡è¡Œåˆ—ã‚’ä½œæˆ\n",
    "X_raw = event_data[feature_cols].fillna(0).values\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾´é‡å½¢çŠ¶: {X_raw.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—5: ã€é‡è¦ã€‘æ—¥ä»˜å˜ä½ã§ã®train/teståˆ†å‰²\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘ã€é‡è¦ã€‘æ—¥ä»˜å˜ä½ã§ã®train/teståˆ†å‰²\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# æ—¥ä»˜ã”ã¨ã®è¡Œæ•°ã‚’è¨ˆç®—\n",
    "date_groups = event_data.groupby('date_num').size()\n",
    "\n",
    "# ç´¯ç©å’Œã‚’è¨ˆç®—\n",
    "cumsum = date_groups.cumsum().values\n",
    "\n",
    "# 0.8åˆ†å‰²ç‚¹ã‚’æ—¥ä»˜å˜ä½ã§è¨ˆç®—\n",
    "total = cumsum[-1]\n",
    "target_idx = int(total * 0.8)\n",
    "split_date_position = np.searchsorted(cumsum, target_idx, side='right') - 1\n",
    "\n",
    "# åˆ†å‰²ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç¢ºå®š\n",
    "if split_date_position >= 0 and split_date_position < len(cumsum):\n",
    "    split_idx = cumsum[split_date_position]\n",
    "else:\n",
    "    split_idx = 0\n",
    "\n",
    "print(f\"âœ… æ—¥ä»˜å˜ä½åˆ†å‰²å®Œäº†\")\n",
    "print(f\"   ç·è¡Œæ•°: {total}\")\n",
    "print(f\"   0.8åˆ†å‰²ç‚¹: {target_idx}\")\n",
    "print(f\"   åˆ†å‰²ä½ç½®ï¼ˆè¡Œï¼‰: {split_idx}\")\n",
    "\n",
    "train_dates = event_data.iloc[:split_idx]['date_num'].unique()\n",
    "test_dates = event_data.iloc[split_idx:]['date_num'].unique()\n",
    "\n",
    "print(f\"   trainæ—¥æ•°: {len(train_dates)}\")\n",
    "print(f\"   testæ—¥æ•°: {len(test_dates)}\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—6: train/testãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘train/testãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "X_train = X_raw[:split_idx]\n",
    "X_test = X_raw[split_idx:]\n",
    "\n",
    "y_train = y_raw[:split_idx]\n",
    "y_test = y_raw[split_idx:]\n",
    "\n",
    "print(f\"âœ… ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "print(f\"   y_train: {y_train.shape}\")\n",
    "print(f\"   y_test: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\n   è¨“ç·´ãƒ©ãƒ™ãƒ«çµ±è¨ˆ: mean={y_train.mean():.2f}, std={y_train.std():.2f}, min={y_train.min()}, max={y_train.max()}\")\n",
    "print(f\"   ãƒ†ã‚¹ãƒˆãƒ©ãƒ™ãƒ«çµ±è¨ˆ: mean={y_test.mean():.2f}, std={y_test.std():.2f}, min={y_test.min()}, max={y_test.max()}\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—7: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—7ã€‘ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"âœ… ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Œäº†\")\n",
    "print(f\"   trainå¹³å‡: {X_train_scaled.mean(axis=0)[:5]}\")\n",
    "print(f\"   trainæ¨™æº–åå·®: {X_train_scaled.std(axis=0)[:5]}\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—8: ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆLGBMRankerç”¨ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—8ã€‘ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆLGBMRankerç”¨ï¼‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "train_dates_values = event_data.iloc[:split_idx]['date_num'].values\n",
    "test_dates_values = event_data.iloc[split_idx:]['date_num'].values\n",
    "\n",
    "group_train = pd.Series(train_dates_values).value_counts().sort_index().values.tolist()\n",
    "group_test = pd.Series(test_dates_values).value_counts().sort_index().values.tolist()\n",
    "\n",
    "print(f\"âœ… ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºè¨ˆç®—å®Œäº†\")\n",
    "print(f\"   group_train: {group_train}\")\n",
    "print(f\"   group_test: {group_test}\")\n",
    "\n",
    "# ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºãŒ11ã®å€æ•°ã‹ç¢ºèª\n",
    "train_abnormal = sum(1 for g in group_train if g != 11)\n",
    "test_abnormal = sum(1 for g in group_test if g != 11)\n",
    "\n",
    "if train_abnormal == 0 and test_abnormal == 0:\n",
    "    print(f\"   âœ… ã™ã¹ã¦ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºãŒ11ï¼ˆå®Œç’§ï¼‰\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  ç•°å¸¸ãªã‚°ãƒ«ãƒ¼ãƒ—: train={train_abnormal}å€‹, test={test_abnormal}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—9: ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¸ã®ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—9ã€‘ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¸ã®ç™»éŒ²\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "globals()['X_train'] = X_train_scaled\n",
    "globals()['X_test'] = X_test_scaled\n",
    "globals()['y_train'] = y_train\n",
    "globals()['y_test'] = y_test\n",
    "globals()['group_train'] = group_train\n",
    "globals()['group_test'] = group_test\n",
    "globals()['scaler'] = scaler\n",
    "globals()['feature_cols'] = feature_cols\n",
    "globals()['event_data'] = event_data\n",
    "globals()['split_idx'] = split_idx\n",
    "\n",
    "print(f\"âœ… ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²å®Œäº†\")\n",
    "\n",
    "# ============================================================\n",
    "# ã‚¹ãƒ†ãƒƒãƒ—10: å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«10ä¿®æ­£ç‰ˆ: å®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nã€å®Ÿè¡Œå†…å®¹ã€‘\")\n",
    "print(f\"  â€¢ last_digit_rank_diff ã‚’ y ã¨ã—ã¦æŠ½å‡º\")\n",
    "print(f\"  â€¢ ç‰¹å¾´é‡ X ã‹ã‚‰ last_digit_rank_* ã‚’é™¤å¤–ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰\")\n",
    "print(f\"  â€¢ æ—¥ä»˜å˜ä½ã§ã® train/test åˆ†å‰²ï¼ˆ0.8 : 0.2ï¼‰\")\n",
    "print(f\"  â€¢ ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\")\n",
    "\n",
    "print(f\"\\nã€ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã€‘\")\n",
    "print(f\"  è¨“ç·´: {len(y_train)} ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "print(f\"  ãƒ†ã‚¹ãƒˆ: {len(y_test)} ã‚µãƒ³ãƒ—ãƒ«\")\n",
    "print(f\"  ç‰¹å¾´é‡æ•°: {X_train.shape[1]}\")\n",
    "print(f\"  ç›®çš„å¤‰æ•°ï¼ˆãƒ©ãƒ³ã‚¯ï¼‰: 1ï½11ã®ç¯„å›²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«11: äºˆæ¸¬å®Ÿè¡Œï¼ˆçµ±ä¸€åŒ–ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def make_predictions(X_test, model_result, task_type='binary', ensemble_method='auto_best'):\n",
    "    \"\"\"\n",
    "    ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_test : DataFrame/ndarray\n",
    "        ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡\n",
    "    model_result : dict\n",
    "        ã‚»ãƒ«10ã® train_final_model_unified ã®æˆ»ã‚Šå€¤\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    ensemble_method : str\n",
    "        'auto_best', 'ensemble', 'manual'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : {\n",
    "        'predictions': äºˆæ¸¬å€¤,\n",
    "        'probabilities': ç¢ºç‡ï¼ˆäºŒå€¤åˆ†é¡ã®ã¿ï¼‰,\n",
    "        'method_used': ä½¿ç”¨æ–¹æ³•,\n",
    "        'confidence': ä¿¡é ¼åº¦\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model_result['model']\n",
    "    scaler = model_result['scaler']\n",
    "    \n",
    "    # =========================================\n",
    "    # 1. ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n",
    "    # =========================================\n",
    "    \n",
    "    if scaler is not None:\n",
    "        X_test_fit = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_test_fit = X_test\n",
    "    \n",
    "    # =========================================\n",
    "    # 2. äºˆæ¸¬å®Ÿè¡Œ\n",
    "    # =========================================\n",
    "    \n",
    "    print(f\"\\nğŸ”® äºˆæ¸¬å®Ÿè¡Œ\")\n",
    "    print(f\"   ãƒ¢ãƒ‡ãƒ«: {model_result['model_name']}\")\n",
    "    print(f\"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_test_fit)}\")\n",
    "    \n",
    "    predictions = model.predict(X_test_fit)\n",
    "    \n",
    "    # =========================================\n",
    "    # 3. å‡ºåŠ›å½¢å¼èª¿æ•´\n",
    "    # =========================================\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        # ===== äºŒå€¤åˆ†é¡ =====\n",
    "        \n",
    "        # ç¢ºç‡å€¤å–å¾—\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probabilities = model.predict_proba(X_test_fit)[:, 1]\n",
    "        else:\n",
    "            probabilities = None\n",
    "        \n",
    "        # ä¿¡é ¼åº¦è¨ˆç®—\n",
    "        if probabilities is not None:\n",
    "            confidence = np.abs(probabilities - 0.5) * 2  # 0-1ã«æ­£è¦åŒ–\n",
    "        else:\n",
    "            confidence = np.ones(len(predictions))\n",
    "        \n",
    "        # é«˜ä¿¡é ¼åº¦ã®äºˆæ¸¬ã®ã¿ã‚’æ¡ç”¨\n",
    "        high_conf_mask = confidence >= CONFIG['PREDICTION_CONFIDENCE_THRESHOLD']\n",
    "        \n",
    "        result = {\n",
    "            'predictions': predictions,\n",
    "            'probabilities': probabilities,\n",
    "            'confidence': confidence,\n",
    "            'high_confidence_mask': high_conf_mask,\n",
    "            'method_used': 'binary_classification',\n",
    "            'n_high_confidence': high_conf_mask.sum()\n",
    "        }\n",
    "        \n",
    "        print(f\"   ç¢ºç‡ç¯„å›²: [{probabilities.min():.3f}, {probabilities.max():.3f}]\")\n",
    "        print(f\"   é«˜ä¿¡é ¼åº¦äºˆæ¸¬: {high_conf_mask.sum()}/{len(predictions)}\")\n",
    "    \n",
    "    else:\n",
    "        # ===== å›å¸°ï¼ˆãƒ©ãƒ³ã‚¯å­¦ç¿’ï¼‰=====\n",
    "        \n",
    "        # ã‚¯ãƒªãƒƒãƒ—å‡¦ç†ï¼ˆãƒ©ãƒ³ã‚¯å­¦ç¿’ã¯1-11ç¯„å›²ï¼‰\n",
    "        predictions_clipped = np.clip(predictions, CONFIG['MIN_RANK'], CONFIG['MAX_RANK'])\n",
    "        \n",
    "        # ä¿¡é ¼åº¦ã¯æ•´æ•°ã¸ã®è¿‘ã•ã§è¨ˆç®—\n",
    "        fractional_part = np.abs(predictions - np.round(predictions))\n",
    "        confidence = 1.0 - fractional_part  # æ•´æ•°ã«è¿‘ã„ã»ã©ä¿¡é ¼åº¦é«˜\n",
    "        \n",
    "        result = {\n",
    "            'predictions': predictions_clipped,\n",
    "            'predictions_raw': predictions,\n",
    "            'confidence': confidence,\n",
    "            'method_used': 'regression',\n",
    "        }\n",
    "        \n",
    "        print(f\"   äºˆæ¸¬ç¯„å›²: [{predictions_clipped.min():.1f}, {predictions_clipped.max():.1f}]\")\n",
    "        print(f\"   å¹³å‡äºˆæ¸¬ãƒ©ãƒ³ã‚¯: {predictions_clipped.mean():.2f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def make_predictions_batch(X_test_list, model_result, task_type='binary'):\n",
    "    \"\"\"\n",
    "    è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ä¸€æ‹¬äºˆæ¸¬\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_test_list : list of DataFrame\n",
    "        è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡\n",
    "    model_result : dict\n",
    "        ãƒ¢ãƒ‡ãƒ«çµæœ\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : äºˆæ¸¬çµæœãƒªã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions_list = []\n",
    "    \n",
    "    for i, X_test in enumerate(X_test_list):\n",
    "        print(f\"   [{i+1}/{len(X_test_list)}] äºˆæ¸¬ä¸­...\", end='\\r')\n",
    "        pred_result = make_predictions(X_test, model_result, task_type)\n",
    "        predictions_list.append(pred_result)\n",
    "    \n",
    "    print(f\"   âœ… å…¨äºˆæ¸¬å®Œäº† ({len(X_test_list)}ã‚»ãƒƒãƒˆ)\")\n",
    "    \n",
    "    return predictions_list\n",
    "\n",
    "\n",
    "def apply_prediction_filter(pred_result, task_type='binary', min_confidence=None):\n",
    "    \"\"\"\n",
    "    ä¿¡é ¼åº¦ã«ã‚ˆã£ã¦äºˆæ¸¬ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pred_result : dict\n",
    "        make_predictions ã®æˆ»ã‚Šå€¤\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    min_confidence : float\n",
    "        æœ€å°ä¿¡é ¼åº¦ï¼ˆNoneã®å ´åˆã¯CONFIGå€¤ã‚’ä½¿ç”¨ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®çµæœ\n",
    "    \"\"\"\n",
    "    \n",
    "    if min_confidence is None:\n",
    "        min_confidence = CONFIG['PREDICTION_CONFIDENCE_THRESHOLD']\n",
    "    \n",
    "    confidence = pred_result['confidence']\n",
    "    mask = confidence >= min_confidence\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        predictions = pred_result['predictions']\n",
    "        probabilities = pred_result.get('probabilities', None)\n",
    "        \n",
    "        filtered = {\n",
    "            'predictions': predictions[mask],\n",
    "            'probabilities': probabilities[mask] if probabilities is not None else None,\n",
    "            'confidence': confidence[mask],\n",
    "            'indices': np.where(mask)[0],\n",
    "            'n_filtered': mask.sum(),\n",
    "            'filter_ratio': mask.sum() / len(mask)\n",
    "        }\n",
    "    else:\n",
    "        predictions = pred_result['predictions']\n",
    "        \n",
    "        filtered = {\n",
    "            'predictions': predictions[mask],\n",
    "            'confidence': confidence[mask],\n",
    "            'indices': np.where(mask)[0],\n",
    "            'n_filtered': mask.sum(),\n",
    "            'filter_ratio': mask.sum() / len(mask)\n",
    "        }\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "def ensemble_predictions(pred_results_list, task_type='binary', weights=None):\n",
    "    \"\"\"\n",
    "    è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pred_results_list : list of dict\n",
    "        è¤‡æ•°ã® make_predictions çµæœ\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    weights : list of float\n",
    "        å„ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ï¼ˆNoneã®å ´åˆã¯ç­‰é‡ã¿ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬çµæœ\n",
    "    \"\"\"\n",
    "    \n",
    "    n_models = len(pred_results_list)\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = np.ones(n_models) / n_models\n",
    "    else:\n",
    "        weights = np.array(weights) / np.sum(weights)\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        # ç¢ºç‡å€¤ã®åŠ é‡å¹³å‡\n",
    "        proba_ensemble = np.zeros_like(pred_results_list[0]['probabilities'])\n",
    "        \n",
    "        for pred_result, w in zip(pred_results_list, weights):\n",
    "            if pred_result['probabilities'] is not None:\n",
    "                proba_ensemble += pred_result['probabilities'] * w\n",
    "        \n",
    "        # ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ã«å¤‰æ›\n",
    "        predictions_ensemble = (proba_ensemble >= 0.5).astype(int)\n",
    "        \n",
    "        # ä¿¡é ¼åº¦: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã§åŒæ„ã—ãŸå‰²åˆ\n",
    "        agreement = 0\n",
    "        for pred_result in pred_results_list:\n",
    "            agreement += (pred_result['predictions'] == predictions_ensemble).astype(int)\n",
    "        agreement = agreement / n_models\n",
    "        \n",
    "        result = {\n",
    "            'predictions': predictions_ensemble,\n",
    "            'probabilities': proba_ensemble,\n",
    "            'confidence': agreement,\n",
    "            'method': 'ensemble_voting',\n",
    "            'n_models': n_models\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        # äºˆæ¸¬å€¤ã®åŠ é‡å¹³å‡\n",
    "        pred_ensemble = np.zeros_like(pred_results_list[0]['predictions'])\n",
    "        \n",
    "        for pred_result, w in zip(pred_results_list, weights):\n",
    "            pred_ensemble += pred_result['predictions'] * w\n",
    "        \n",
    "        # ã‚¯ãƒªãƒƒãƒ—\n",
    "        pred_ensemble = np.clip(pred_ensemble, CONFIG['MIN_RANK'], CONFIG['MAX_RANK'])\n",
    "        \n",
    "        # ä¿¡é ¼åº¦: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã®åˆ†æ•£ï¼ˆå°ã•ã„ã»ã©ä¿¡é ¼åº¦é«˜ï¼‰\n",
    "        pred_variance = np.var([pr['predictions'] for pr in pred_results_list], axis=0)\n",
    "        confidence = 1.0 / (1.0 + pred_variance)\n",
    "        \n",
    "        result = {\n",
    "            'predictions': pred_ensemble,\n",
    "            'confidence': confidence,\n",
    "            'method': 'ensemble_averaging',\n",
    "            'n_models': n_models,\n",
    "            'variance': pred_variance\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«11: äºˆæ¸¬å®Ÿè¡Œé–¢æ•°ã®å®šç¾©å®Œäº†\")\n",
    "print(\"   ğŸ”® make_predictions(X_test, model_result, task_type, ensemble_method)\")\n",
    "print(\"   ğŸ”„ make_predictions_batch(X_test_list, model_result, task_type)\")\n",
    "print(\"   ğŸ¯ apply_prediction_filter(pred_result, task_type, min_confidence)\")\n",
    "print(\"   ğŸ”— ensemble_predictions(pred_results_list, task_type, weights)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«11R: CVå†…ã‚¿ã‚¹ã‚¯åˆ¥ç‰¹å¾´é‡è¦åº¦é¸æŠï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¨ãƒ©ãƒ¼å¯¾ç­–ç‰ˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«11Rã€‘CVå†…ã‚¿ã‚¹ã‚¯åˆ¥ç‰¹å¾´é‡è¦åº¦é¸æŠï¼ˆä¿®æ­£ç‰ˆï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«10ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"âœ… df_merged ãŒåˆ©ç”¨å¯èƒ½: {df_merged.shape}\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆå–å¾—\n",
    "if 'test_events' not in globals():\n",
    "    test_events = CONFIG.get('TEST_EVENTS', ['1day', '4day', '0day', '40day'])\n",
    "else:\n",
    "    test_events = globals()['test_events']\n",
    "\n",
    "print(f\"âœ… ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆ: {test_events}\")\n",
    "\n",
    "# ============================================================\n",
    "# 1. çµ±è¨ˆæœ‰æ„æ€§ãƒ•ã‚£ãƒ«ã‚¿é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def filter_features_by_pvalue(X, y, feature_names, task_type='binary', pvalue_threshold=0.05, min_features=10):\n",
    "    \"\"\"\n",
    "    çµ±è¨ˆæœ‰æ„æ€§ã«åŸºã¥ã„ã¦ç‰¹å¾´ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "    y : ndarray, shape (n_samples,)\n",
    "    feature_names : list of str\n",
    "        ç‰¹å¾´é‡åï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°ç”¨ï¼‰\n",
    "    task_type : str, 'binary' or 'regression'\n",
    "    pvalue_threshold : float, default=0.05\n",
    "    min_features : int, æœ€å°ç‰¹å¾´æ•°\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    significant_feature_names : list of feature names\n",
    "    \"\"\"\n",
    "    \n",
    "    # NaNã€infå€¤ã®å‡¦ç†\n",
    "    X_clean = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        f_scores, p_vals = f_classif(X_clean, y)\n",
    "    else:\n",
    "        f_scores, p_vals = f_regression(X_clean, y)\n",
    "    \n",
    "    # på€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "    significant_indices = np.where(p_vals < pvalue_threshold)[0].tolist()\n",
    "    \n",
    "    # æœ‰æ„ç‰¹å¾´ãŒå°‘ãªã™ãã‚‹å ´åˆã¯ã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ã«è¿½åŠ \n",
    "    if len(significant_indices) < min_features:\n",
    "        sorted_indices = np.argsort(-f_scores).tolist()\n",
    "        for idx in sorted_indices:\n",
    "            if idx not in significant_indices:\n",
    "                significant_indices.append(idx)\n",
    "            if len(significant_indices) >= min_features:\n",
    "                break\n",
    "    \n",
    "    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰ç‰¹å¾´é‡åã«å¤‰æ›\n",
    "    # âš ï¸ ã€é‡è¦ã€‘ã“ã“ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒfeature_namesã®ç¯„å›²å†…ã‹ç¢ºèª\n",
    "    significant_indices = sorted(significant_indices)\n",
    "    \n",
    "    if len(significant_indices) > 0 and max(significant_indices) >= len(feature_names):\n",
    "        print(f\"  âš ï¸  è­¦å‘Š: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {max(significant_indices)} >= ç‰¹å¾´é‡æ•° {len(feature_names)}\")\n",
    "        print(f\"     æœ‰åŠ¹ãªç‰¹å¾´é‡åã®ã¿ã‚’å–å¾—\")\n",
    "        significant_indices = [idx for idx in significant_indices if idx < len(feature_names)]\n",
    "    \n",
    "    significant_feature_names = [feature_names[idx] for idx in significant_indices]\n",
    "    \n",
    "    return significant_feature_names\n",
    "\n",
    "# ============================================================\n",
    "# 2. CVå®Ÿè¡Œ\n",
    "# ============================================================\n",
    "\n",
    "cv_feature_results = {}\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nâœ“ ã‚¤ãƒ™ãƒ³ãƒˆ: {event}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "    event_col = f'is_{event}'\n",
    "    if event_col not in df_merged.columns:\n",
    "        print(f\"  âš ï¸  ã‚«ãƒ©ãƒ  '{event_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    event_data = df_merged[df_merged[event_col] == 1].copy().reset_index(drop=True)\n",
    "    \n",
    "    if len(event_data) == 0:\n",
    "        print(f\"  âš ï¸  ã‚¤ãƒ™ãƒ³ãƒˆ {event} ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    # ============================================================\n",
    "    # ç‰¹å¾´é‡åˆ—ã®æ­£ç¢ºãªæŠ½å‡º\n",
    "    # ============================================================\n",
    "    \n",
    "    # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ˜ç¢ºã«å®šç¾©\n",
    "    exclude_patterns = [\n",
    "        'date', 'digit_num', 'last_digit', 'last_digit_rank_diff',\n",
    "        'is_', 'machine_count', 'description', 'event_type'\n",
    "    ]\n",
    "    \n",
    "    feature_cols = []\n",
    "    for col in event_data.columns:\n",
    "        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã«è©²å½“ã—ãªã„ã‹ãƒã‚§ãƒƒã‚¯\n",
    "        if any(pattern in col.lower() for pattern in exclude_patterns):\n",
    "            continue\n",
    "        # æ•°å€¤å‹ã®ã¿\n",
    "        if event_data[col].dtype in ['int64', 'float64', 'int32', 'float32']:\n",
    "            feature_cols.append(col)\n",
    "    \n",
    "    if len(feature_cols) == 0:\n",
    "        print(f\"  âŒ ç‰¹å¾´åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  ç‰¹å¾´é‡æ•°: {len(feature_cols)}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—ä½œæˆ\n",
    "    X = event_data[feature_cols].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "    print(f\"  X shape: {X.shape}\")\n",
    "    \n",
    "    cv_feature_results[event] = {}\n",
    "    \n",
    "    # ========== TOP1: äºŒå€¤åˆ†é¡ ==========\n",
    "    print(f\"  â€¢ TOP1 (äºŒå€¤åˆ†é¡)...\")\n",
    "    \n",
    "    y_top1 = (event_data['last_digit_rank_diff'].values <= 1).astype(int)\n",
    "    \n",
    "    # çµ±è¨ˆæœ‰æ„æ€§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆä¿®æ­£ç‰ˆï¼šfeature_colsã‚’æ¸¡ã™ï¼‰\n",
    "    sig_feature_names_top1 = filter_features_by_pvalue(\n",
    "        X, y_top1, feature_names=feature_cols, task_type='binary', \n",
    "        pvalue_threshold=0.05, min_features=10\n",
    "    )\n",
    "    \n",
    "    print(f\"    â†’ på€¤ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(sig_feature_names_top1)}å€‹ã®æœ‰æ„ãªç‰¹å¾´\")\n",
    "    cv_feature_results[event]['top1'] = sig_feature_names_top1\n",
    "    \n",
    "    # ========== TOP2: äºŒå€¤åˆ†é¡ ==========\n",
    "    print(f\"  â€¢ TOP2 (äºŒå€¤åˆ†é¡)...\")\n",
    "    \n",
    "    y_top2 = (event_data['last_digit_rank_diff'].values <= 2).astype(int)\n",
    "    \n",
    "    sig_feature_names_top2 = filter_features_by_pvalue(\n",
    "        X, y_top2, feature_names=feature_cols, task_type='binary',\n",
    "        pvalue_threshold=0.05, min_features=10\n",
    "    )\n",
    "    \n",
    "    print(f\"    â†’ på€¤ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(sig_feature_names_top2)}å€‹ã®æœ‰æ„ãªç‰¹å¾´\")\n",
    "    cv_feature_results[event]['top2'] = sig_feature_names_top2\n",
    "    \n",
    "    # ========== RANK: å›å¸° ==========\n",
    "    print(f\"  â€¢ RANK (å›å¸°)...\")\n",
    "    \n",
    "    y_rank = event_data['last_digit_rank_diff'].values\n",
    "    \n",
    "    sig_feature_names_rank = filter_features_by_pvalue(\n",
    "        X, y_rank, feature_names=feature_cols, task_type='regression',\n",
    "        pvalue_threshold=0.05, min_features=10\n",
    "    )\n",
    "    \n",
    "    print(f\"    â†’ på€¤ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(sig_feature_names_rank)}å€‹ã®æœ‰æ„ãªç‰¹å¾´\")\n",
    "    cv_feature_results[event]['rank'] = sig_feature_names_rank\n",
    "\n",
    "# ============================================================\n",
    "# 3. çµæœã®ä¿å­˜ã¨çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… ç‰¹å¾´é‡é¸æŠå®Œäº†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "globals()['cv_feature_results'] = cv_feature_results\n",
    "\n",
    "# çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "print(f\"\\nã€ç‰¹å¾´æ•°ã®çµ±è¨ˆã‚µãƒãƒªãƒ¼ã€‘\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'ã‚¤ãƒ™ãƒ³ãƒˆ':15s} | {'TOP1':15s} | {'TOP2':15s} | {'RANK':15s}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "all_feature_counts = []\n",
    "for event in test_events:\n",
    "    if event in cv_feature_results:\n",
    "        top1_n = len(cv_feature_results[event].get('top1', []))\n",
    "        top2_n = len(cv_feature_results[event].get('top2', []))\n",
    "        rank_n = len(cv_feature_results[event].get('rank', []))\n",
    "        \n",
    "        all_feature_counts.extend([top1_n, top2_n, rank_n])\n",
    "        \n",
    "        print(f\"{event:15s} | {top1_n:3d}å€‹ | {top2_n:3d}å€‹ | {rank_n:3d}å€‹\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "if all_feature_counts:\n",
    "    print(f\"å¹³å‡: {np.mean(all_feature_counts):.1f}å€‹\")\n",
    "    print(f\"ä¸­å¤®å€¤: {np.median(all_feature_counts):.1f}å€‹\")\n",
    "    print(f\"ç¯„å›²: {np.min(all_feature_counts)}ï½{np.max(all_feature_counts)}å€‹\")\n",
    "\n",
    "print(f\"\\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘\")\n",
    "print(f\"  ã‚»ãƒ«12ä»¥é™ã§ã“ã‚Œã‚‰ã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–ã‚’å®Ÿæ–½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«11R-1ä¿®æ­£: ç‰¹å¾´é‡çµæœã®å½¢å¼å¤‰æ›\n",
    "# ============================================================\n",
    "# ã‚»ãƒ«11Rã® cv_feature_results ã‚’ã‚»ãƒ«18ã§ä½¿ç”¨å¯èƒ½ãª\n",
    "# feature_results_by_model å½¢å¼ã«å¤‰æ›\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«11R-1ä¿®æ­£ã€‘ç‰¹å¾´é‡çµæœã®å½¢å¼å¤‰æ›\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 1. cv_feature_results ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "if 'cv_feature_results' not in globals():\n",
    "    raise RuntimeError(\"âŒ cv_feature_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«11Rã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"\\nâœ… cv_feature_results ç¢ºèª\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(cv_feature_results)}\")\n",
    "for event, tasks in cv_feature_results.items():\n",
    "    print(f\"  â€¢ {event}: {list(tasks.keys())}\")\n",
    "    for task, features in tasks.items():\n",
    "        print(f\"      - {task}: {len(features)}å€‹ã®ç‰¹å¾´é‡\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. feature_results_by_model ã«å¤‰æ›\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nâœ… feature_results_by_model ã«å¤‰æ›\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "feature_results_by_model = {}\n",
    "\n",
    "for event, tasks in cv_feature_results.items():\n",
    "    feature_results_by_model[event] = {}\n",
    "    \n",
    "    # baseline: top1ã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨\n",
    "    if 'top1' in tasks:\n",
    "        feature_results_by_model[event]['baseline'] = tasks['top1']\n",
    "        print(f\"  âœ… {event} â†’ baseline: {len(tasks['top1'])}å€‹ã®ç‰¹å¾´é‡\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸  {event}: top1 ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        feature_results_by_model[event]['baseline'] = []\n",
    "    \n",
    "    # top_3: top1, top2, rank ã®æŠ•ç¥¨ãƒ™ãƒ¼ã‚¹\n",
    "    if 'top1' in tasks and 'top2' in tasks and 'rank' in tasks:\n",
    "        from collections import Counter\n",
    "        \n",
    "        all_features = tasks['top1'] + tasks['top2'] + tasks['rank']\n",
    "        feature_votes = Counter(all_features)\n",
    "        \n",
    "        # 2ç¥¨ä»¥ä¸Šã‚’é›†ã‚ãŸç‰¹å¾´é‡ã‚’é¸æŠ\n",
    "        common_features = [f for f, votes in feature_votes.items() if votes >= 2]\n",
    "        common_features = sorted(\n",
    "            common_features, \n",
    "            key=lambda f: feature_votes[f], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        feature_results_by_model[event]['top_3'] = common_features\n",
    "        print(f\"  âœ… {event} â†’ top_3: {len(common_features)}å€‹ã®ç‰¹å¾´é‡ï¼ˆæŠ•ç¥¨ãƒ™ãƒ¼ã‚¹ï¼‰\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸  {event}: top1, top2, rank ãŒæƒã£ã¦ã„ã¾ã›ã‚“\")\n",
    "        feature_results_by_model[event]['top_3'] = feature_results_by_model[event].get('baseline', [])\n",
    "\n",
    "# ============================================================\n",
    "# 3. æœ€çµ‚ç¢ºèªã¨çµ±è¨ˆ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nâœ… å¤‰æ›å®Œäº†\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nã€æ§‹é€ ç¢ºèªã€‘\")\n",
    "print(\"  feature_results_by_model ã®æ§‹é€ :\")\n",
    "print(\"  {\")\n",
    "\n",
    "for event, models in feature_results_by_model.items():\n",
    "    print(\"    '\" + event + \"': \" + \"{\")\n",
    "    for model_key, features in models.items():\n",
    "        print(f\"      '{model_key}': [{len(features)}å€‹ã®ç‰¹å¾´é‡],\")\n",
    "    print(\"    },\")\n",
    "\n",
    "print(\"  }\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ç‰¹å¾´é‡ã®å†…è¨³ã‚’è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ç‰¹å¾´é‡ã®å†…è¨³ã€‘\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for event in sorted(feature_results_by_model.keys()):\n",
    "    print(f\"\\n{event}:\")\n",
    "    \n",
    "    baseline_features = feature_results_by_model[event].get('baseline', [])\n",
    "    top3_features = feature_results_by_model[event].get('top_3', [])\n",
    "    \n",
    "    print(f\"  baseline: {len(baseline_features)}å€‹\")\n",
    "    if baseline_features:\n",
    "        print(\"    ä¾‹: \" + str(baseline_features[:5]))\n",
    "    \n",
    "    print(f\"  top_3: {len(top3_features)}å€‹\")\n",
    "    if top3_features:\n",
    "        print(\"    ä¾‹: \" + str(top3_features[:5]))\n",
    "\n",
    "# ============================================================\n",
    "# 5. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['feature_results_by_model'] = feature_results_by_model\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«11R-1ä¿®æ­£: ç‰¹å¾´é‡çµæœã®å½¢å¼å¤‰æ›å®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘\")\n",
    "print(f\"  ã‚»ãƒ«18_æº–å‚™: feature_results_by_model ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚’å®Ÿè¡Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«12: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒ­ã‚°å‡ºåŠ›\n",
    "# ============================================================\n",
    "\n",
    "def validate_event(df, event, task_type='binary', rank=1):\n",
    "    \"\"\"\n",
    "    ã‚¤ãƒ™ãƒ³ãƒˆã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        ãƒãƒ¼ã‚¸æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "    event : str\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    rank : int\n",
    "        TOPé †ä½ï¼ˆäºŒå€¤åˆ†é¡ã®å ´åˆï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : å¦¥å½“ãªå ´åˆTrueã€ç†ç”±ã‚’è¡¨ç¤º\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆæ¤œè¨¼: {event}\")\n",
    "    \n",
    "    errors = []\n",
    "    warnings = []\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯1: ã‚¤ãƒ™ãƒ³ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹\n",
    "    if 'event_type' in df.columns:\n",
    "        event_count = (df['event_type'] == event).sum()\n",
    "        if event_count == 0:\n",
    "            errors.append(f\"ã‚¤ãƒ™ãƒ³ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“: {event}\")\n",
    "        else:\n",
    "            print(f\"   âœ… ã‚¤ãƒ™ãƒ³ãƒˆå­˜åœ¨: {event_count}è¡Œ\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯2: ãƒ©ãƒ™ãƒ«ã®åˆ†å¸ƒ\n",
    "    if 'last_digit_rank_diff' in df.columns:\n",
    "        if task_type == 'binary':\n",
    "            labels = (df['last_digit_rank_diff'] <= rank).astype(int)\n",
    "            label_dist = labels.value_counts().to_dict()\n",
    "            \n",
    "            if 0 not in label_dist or 1 not in label_dist:\n",
    "                errors.append(f\"ãƒ©ãƒ™ãƒ«åˆ†å¸ƒãŒåã£ã¦ã„ã¾ã™: {label_dist}\")\n",
    "            else:\n",
    "                ratio = label_dist[1] / len(labels) * 100\n",
    "                if ratio < 10 or ratio > 90:\n",
    "                    warnings.append(f\"ãƒ©ãƒ™ãƒ«ä¸å‡è¡¡: {ratio:.1f}%\")\n",
    "                print(f\"   âœ… ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {label_dist}\")\n",
    "        \n",
    "        else:\n",
    "            rank_stats = df['last_digit_rank_diff'].describe()\n",
    "            print(f\"   âœ… ãƒ©ãƒ³ã‚¯çµ±è¨ˆ: mean={rank_stats['mean']:.2f}, std={rank_stats['std']:.2f}\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯3: ç‰¹å¾´é‡ã®é‡\n",
    "    exclude_patterns = [\n",
    "        'date', 'event', 'target', 'label', 'current_diff',\n",
    "        'last_digit_rank', 'digit_num', 'last_digit'\n",
    "    ]\n",
    "    \n",
    "    feature_count = sum(\n",
    "        1 for col in df.columns\n",
    "        if not any(p in col.lower() for p in exclude_patterns) \n",
    "        and df[col].dtype in ['int64', 'float64']\n",
    "    )\n",
    "    \n",
    "    if feature_count < 20:\n",
    "        warnings.append(f\"ç‰¹å¾´é‡ãŒå°‘ãªã‚: {feature_count}å€‹\")\n",
    "    else:\n",
    "        print(f\"   âœ… ç‰¹å¾´é‡æ•°: {feature_count}å€‹\")\n",
    "    \n",
    "    # å‡ºåŠ›\n",
    "    if errors:\n",
    "        print(f\"\\n   âŒ ã‚¨ãƒ©ãƒ¼:\")\n",
    "        for err in errors:\n",
    "            print(f\"      â€¢ {err}\")\n",
    "        return False\n",
    "    \n",
    "    if warnings:\n",
    "        print(f\"\\n   âš ï¸  è­¦å‘Š:\")\n",
    "        for warn in warnings:\n",
    "            print(f\"      â€¢ {warn}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def print_progress(current, total, task_name=''):\n",
    "    \"\"\"\n",
    "    é€²æ—è¡¨ç¤º\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    current : int\n",
    "        ç¾åœ¨ã®å‡¦ç†ç•ªå·\n",
    "    total : int\n",
    "        ç·å‡¦ç†æ•°\n",
    "    task_name : str\n",
    "        ã‚¿ã‚¹ã‚¯å\n",
    "    \"\"\"\n",
    "    \n",
    "    progress = current / total * 100\n",
    "    bar_length = 30\n",
    "    filled = int(bar_length * current / total)\n",
    "    bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)\n",
    "    \n",
    "    print(f\"\\r[{bar}] {progress:.1f}% ({current}/{total}) {task_name}\", end='')\n",
    "    \n",
    "    if current == total:\n",
    "        print()  # æ”¹è¡Œ\n",
    "\n",
    "\n",
    "def log_error(error_type, message, context=None):\n",
    "    \"\"\"\n",
    "    ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    error_type : str\n",
    "        ã‚¨ãƒ©ãƒ¼ç¨®é¡\n",
    "    message : str\n",
    "        ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
    "    context : dict, optional\n",
    "        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±\n",
    "    \"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    print(f\"\\nâŒ [{timestamp}] {error_type}\")\n",
    "    print(f\"   ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message}\")\n",
    "    \n",
    "    if context:\n",
    "        print(f\"   ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\")\n",
    "        for key, value in context.items():\n",
    "            print(f\"      â€¢ {key}: {value}\")\n",
    "\n",
    "\n",
    "def print_config():\n",
    "    \"\"\"\n",
    "    CONFIGã®å…¨è¨­å®šå€¤ã‚’è¡¨ç¤º\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ CONFIGè¨­å®šä¸€è¦§\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for key, value in CONFIG.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"\\n{key}:\")\n",
    "            for k, v in value.items():\n",
    "                print(f\"  â€¢ {k}: {v}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"\\n{key}:\")\n",
    "            for item in value:\n",
    "                print(f\"  â€¢ {item}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "def diagnose_error(error_type, df=None, X_train=None, y_train=None):\n",
    "    \"\"\"\n",
    "    ã‚¨ãƒ©ãƒ¼ã®åŸå› ã‚’è¨ºæ–­\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    error_type : str\n",
    "        ã‚¨ãƒ©ãƒ¼ç¨®é¡ ('data', 'features', 'model', etc.)\n",
    "    df : DataFrame, optional\n",
    "    X_train : DataFrame, optional\n",
    "    y_train : Series, optional\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ” ã‚¨ãƒ©ãƒ¼è¨ºæ–­: {error_type}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if error_type == 'data' and df is not None:\n",
    "        print(f\"\\nã€ãƒ‡ãƒ¼ã‚¿è¨ºæ–­ã€‘\")\n",
    "        print(f\"  å½¢çŠ¶: {df.shape}\")\n",
    "        print(f\"  ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}\")\n",
    "        print(f\"  è¡Œæ•°: {len(df)}\")\n",
    "        print(f\"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "        print(f\"\\n  NaNå€¤:\")\n",
    "        nan_info = df.isnull().sum()\n",
    "        if nan_info.sum() > 0:\n",
    "            print(f\"    â€¢ {nan_info[nan_info > 0].to_dict()}\")\n",
    "        else:\n",
    "            print(f\"    â€¢ ãªã—\")\n",
    "        \n",
    "        print(f\"\\n  ãƒ‡ãƒ¼ã‚¿å‹:\")\n",
    "        for dtype in df.dtypes.unique():\n",
    "            count = (df.dtypes == dtype).sum()\n",
    "            print(f\"    â€¢ {dtype}: {count}åˆ—\")\n",
    "    \n",
    "    elif error_type == 'features' and X_train is not None:\n",
    "        print(f\"\\nã€ç‰¹å¾´é‡è¨ºæ–­ã€‘\")\n",
    "        print(f\"  å½¢çŠ¶: {X_train.shape}\")\n",
    "        print(f\"  ç‰¹å¾´é‡æ•°: {X_train.shape[1]}\")\n",
    "        print(f\"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {X_train.shape[0]}\")\n",
    "        \n",
    "        print(f\"\\n  ç‰¹å¾´é‡ã®çµ±è¨ˆ:\")\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            print(X_train.describe().T[['mean', 'std', 'min', 'max']])\n",
    "        else:\n",
    "            print(f\"    â€¢ å¹³å‡: {X_train.mean(axis=0)}\")\n",
    "            print(f\"    â€¢ æ¨™æº–åå·®: {X_train.std(axis=0)}\")\n",
    "    \n",
    "    elif error_type == 'model' and y_train is not None:\n",
    "        print(f\"\\nã€ãƒ©ãƒ™ãƒ«è¨ºæ–­ã€‘\")\n",
    "        print(f\"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(y_train)}\")\n",
    "        print(f\"  ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤: {len(np.unique(y_train))}\")\n",
    "        print(f\"  åˆ†å¸ƒ: {pd.Series(y_train).value_counts().to_dict()}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "\n",
    "\n",
    "def compare_metrics(metrics_dict, event_names=None):\n",
    "    \"\"\"\n",
    "    è¤‡æ•°ã‚¤ãƒ™ãƒ³ãƒˆã®è©•ä¾¡æŒ‡æ¨™ã‚’æ¯”è¼ƒè¡¨ç¤º\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metrics_dict : dict\n",
    "        {event: metrics} ã®å½¢å¼\n",
    "    event_names : list, optional\n",
    "        è¡¨ç¤ºé †åº\n",
    "    \"\"\"\n",
    "    \n",
    "    if event_names is None:\n",
    "        event_names = list(metrics_dict.keys())\n",
    "    \n",
    "    print(f\"\\nğŸ“Š è©•ä¾¡æŒ‡æ¨™æ¯”è¼ƒ\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # å…±é€šã‚­ãƒ¼ã‚’æŠ½å‡º\n",
    "    all_keys = set()\n",
    "    for metrics in metrics_dict.values():\n",
    "        all_keys.update(metrics.keys())\n",
    "    \n",
    "    # æ¯”è¼ƒè¡¨ã‚’ä½œæˆ\n",
    "    comparison_data = []\n",
    "    for event in event_names:\n",
    "        if event not in metrics_dict:\n",
    "            continue\n",
    "        \n",
    "        metrics = metrics_dict[event]\n",
    "        row = {'Event': event}\n",
    "        \n",
    "        # ä¸»è¦æŒ‡æ¨™ã®ã¿è¡¨ç¤º\n",
    "        for key in ['mae', 'rmse', 'f1', 'accuracy', 'top3_hit_rate', 'spearman_corr']:\n",
    "            if key in metrics:\n",
    "                row[key] = metrics[key]\n",
    "        \n",
    "        comparison_data.append(row)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¡¨ç¤º\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«12: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒ­ã‚°å‡ºåŠ›é–¢æ•°ã®å®šç¾©å®Œäº†\")\n",
    "print(\"   âœ”ï¸  validate_event(df, event, task_type, rank)\")\n",
    "print(\"   ğŸ“Š print_progress(current, total, task_name)\")\n",
    "print(\"   âŒ log_error(error_type, message, context)\")\n",
    "print(\"   ğŸ“‹ print_config()\")\n",
    "print(\"   ğŸ” diagnose_error(error_type, df, X_train, y_train)\")\n",
    "print(\"   ğŸ“ˆ compare_metrics(metrics_dict, event_names)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«12R: ã‚¿ã‚¹ã‚¯åˆ¥Optunaæœ€é©åŒ–ï¼ˆç¢ºå®šç‰¹å¾´é‡ã§ãƒ¢ãƒ‡ãƒ«+ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«12Rã€‘ã‚¿ã‚¹ã‚¯åˆ¥Optunaæœ€é©åŒ–ï¼ˆç¢ºå®šç‰¹å¾´é‡ã§ãƒ¢ãƒ‡ãƒ«+ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 0. äº‹å‰æº–å‚™\n",
    "# ============================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'cv_feature_results' not in globals():\n",
    "    raise RuntimeError(\"âŒ cv_feature_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«11Rã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "\n",
    "print(f\"âœ… cv_feature_results ãŒåˆ©ç”¨å¯èƒ½\")\n",
    "print(f\"âœ… df_merged ãŒåˆ©ç”¨å¯èƒ½: {df_merged.shape}\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆå–å¾—\n",
    "if 'test_events' not in globals():\n",
    "    test_events = CONFIG.get('TEST_EVENTS', ['1day', '4day', '0day', '40day'])\n",
    "else:\n",
    "    test_events = globals()['test_events']\n",
    "\n",
    "print(f\"âœ… ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆ: {test_events}\")\n",
    "\n",
    "# ============================================================\n",
    "# 1. Optunaç›®çš„é–¢æ•°ï¼ˆäºŒå€¤åˆ†é¡ç”¨ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_objective_binary(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    äºŒå€¤åˆ†é¡ã‚¿ã‚¹ã‚¯ç”¨ã®Optunaç›®çš„é–¢æ•°\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        model_name = trial.suggest_categorical('model_name', ['LogReg', 'RF', 'XGB'])\n",
    "        \n",
    "        try:\n",
    "            if model_name == 'LogReg':\n",
    "                model = LogisticRegression(\n",
    "                    C=trial.suggest_float('C', 0.01, 100, log=True),\n",
    "                    max_iter=1000,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            elif model_name == 'RF':\n",
    "                model = RandomForestClassifier(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "                    min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            else:  # XGB\n",
    "                from xgboost import XGBClassifier\n",
    "                model = XGBClassifier(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "                    learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                )\n",
    "            \n",
    "            # CVå®Ÿè¡Œ\n",
    "            cv = StratifiedKFold(n_splits=CONFIG.get('CV_FOLDS', 3), shuffle=False)\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1_weighted')\n",
    "            score = cv_scores.mean()\n",
    "            \n",
    "            return score\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# ============================================================\n",
    "# 2. Optunaç›®çš„é–¢æ•°ï¼ˆå›å¸°ç”¨ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def create_objective_regression(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    å›å¸°ã‚¿ã‚¹ã‚¯ç”¨ã®Optunaç›®çš„é–¢æ•°\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        model_name = trial.suggest_categorical('model_name', ['Ridge', 'RF', 'XGB'])\n",
    "        \n",
    "        try:\n",
    "            if model_name == 'Ridge':\n",
    "                model = Ridge(\n",
    "                    alpha=trial.suggest_float('alpha', 0.1, 100, log=True),\n",
    "                    random_state=42\n",
    "                )\n",
    "            elif model_name == 'RF':\n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "                    min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            else:  # XGB\n",
    "                from xgboost import XGBRegressor\n",
    "                model = XGBRegressor(\n",
    "                    n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "                    max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "                    learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                )\n",
    "            \n",
    "            # CVå®Ÿè¡Œï¼ˆRÂ²ã‚¹ã‚³ã‚¢ï¼‰\n",
    "            cv = KFold(n_splits=CONFIG.get('CV_FOLDS', 3), shuffle=False)\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "            score = cv_scores.mean()\n",
    "            \n",
    "            return score\n",
    "        except:\n",
    "            return -np.inf\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# ============================================================\n",
    "# 3. å„ã‚¤ãƒ™ãƒ³ãƒˆãƒ»ã‚¿ã‚¹ã‚¯åˆ¥Optunaå®Ÿè¡Œ\n",
    "# ============================================================\n",
    "\n",
    "optuna_results = {\n",
    "    'top1': {},\n",
    "    'top2': {},\n",
    "    'rank': {}\n",
    "}\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nâœ“ ã‚¤ãƒ™ãƒ³ãƒˆ: {event}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "    event_col = f'is_{event}'\n",
    "    if event_col not in df_merged.columns:\n",
    "        print(f\"  âš ï¸  ã‚«ãƒ©ãƒ  '{event_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    event_data = df_merged[df_merged[event_col] == 1].copy().reset_index(drop=True)\n",
    "    \n",
    "    if len(event_data) < CONFIG.get('MIN_EVENT_DAYS', 8):\n",
    "        print(f\"  âš ï¸  ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(event_data)}æ—¥\")\n",
    "        continue\n",
    "    \n",
    "    # ========== TOP1: äºŒå€¤åˆ†é¡ ==========\n",
    "    if event in cv_feature_results and 'top1' in cv_feature_results[event]:\n",
    "        print(f\"  â€¢ TOP1 (äºŒå€¤åˆ†é¡) Optunaæœ€é©åŒ–ä¸­...\")\n",
    "        \n",
    "        selected_features = cv_feature_results[event]['top1']\n",
    "        \n",
    "        if len(selected_features) == 0:\n",
    "            print(f\"    âš ï¸  ç‰¹å¾´é‡ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "        else:\n",
    "            X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "            y_top1 = (event_data['last_digit_rank_diff'].values <= 1).astype(int)\n",
    "            \n",
    "            # è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²\n",
    "            split_idx = int(len(X) * 0.75)\n",
    "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "            y_train, y_test = y_top1[:split_idx], y_top1[split_idx:]\n",
    "            \n",
    "            try:\n",
    "                # Optunaæœ€é©åŒ–\n",
    "                sampler = TPESampler(seed=42)\n",
    "                study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "                objective = create_objective_binary(X_train, y_train, X_test, y_test)\n",
    "                \n",
    "                study.optimize(objective, n_trials=CONFIG.get('N_TRIALS', 20), show_progress_bar=False)\n",
    "                \n",
    "                best_params = study.best_params\n",
    "                best_score = study.best_value\n",
    "                \n",
    "                optuna_results['top1'][event] = {\n",
    "                    'best_params': best_params,\n",
    "                    'best_score': best_score,\n",
    "                    'n_trials': len(study.trials),\n",
    "                    'selected_features': selected_features\n",
    "                }\n",
    "                \n",
    "                print(f\"    âœ… æœ€é©åŒ–å®Œäº†\")\n",
    "                print(f\"       æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_params.get('model_name', 'N/A')}\")\n",
    "                print(f\"       F1ã‚¹ã‚³ã‚¢: {best_score:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    âš ï¸  ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}\")\n",
    "    \n",
    "    # ========== TOP2: äºŒå€¤åˆ†é¡ ==========\n",
    "    if event in cv_feature_results and 'top2' in cv_feature_results[event]:\n",
    "        print(f\"  â€¢ TOP2 (äºŒå€¤åˆ†é¡) Optunaæœ€é©åŒ–ä¸­...\")\n",
    "        \n",
    "        selected_features = cv_feature_results[event]['top2']\n",
    "        \n",
    "        if len(selected_features) == 0:\n",
    "            print(f\"    âš ï¸  ç‰¹å¾´é‡ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "        else:\n",
    "            X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "            y_top2 = (event_data['last_digit_rank_diff'].values <= 2).astype(int)\n",
    "            \n",
    "            split_idx = int(len(X) * 0.75)\n",
    "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "            y_train, y_test = y_top2[:split_idx], y_top2[split_idx:]\n",
    "            \n",
    "            try:\n",
    "                sampler = TPESampler(seed=42)\n",
    "                study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "                objective = create_objective_binary(X_train, y_train, X_test, y_test)\n",
    "                \n",
    "                study.optimize(objective, n_trials=CONFIG.get('N_TRIALS', 20), show_progress_bar=False)\n",
    "                \n",
    "                best_params = study.best_params\n",
    "                best_score = study.best_value\n",
    "                \n",
    "                optuna_results['top2'][event] = {\n",
    "                    'best_params': best_params,\n",
    "                    'best_score': best_score,\n",
    "                    'n_trials': len(study.trials),\n",
    "                    'selected_features': selected_features\n",
    "                }\n",
    "                \n",
    "                print(f\"    âœ… æœ€é©åŒ–å®Œäº†\")\n",
    "                print(f\"       æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_params.get('model_name', 'N/A')}\")\n",
    "                print(f\"       F1ã‚¹ã‚³ã‚¢: {best_score:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    âš ï¸  ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}\")\n",
    "    \n",
    "    # ========== RANK: å›å¸° ==========\n",
    "    if event in cv_feature_results and 'rank' in cv_feature_results[event]:\n",
    "        print(f\"  â€¢ RANK (å›å¸°) Optunaæœ€é©åŒ–ä¸­...\")\n",
    "        \n",
    "        selected_features = cv_feature_results[event]['rank']\n",
    "        \n",
    "        if len(selected_features) == 0:\n",
    "            print(f\"    âš ï¸  ç‰¹å¾´é‡ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "        else:\n",
    "            X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "            y_rank = event_data['last_digit_rank_diff'].values\n",
    "            \n",
    "            split_idx = int(len(X) * 0.75)\n",
    "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "            y_train, y_test = y_rank[:split_idx], y_rank[split_idx:]\n",
    "            \n",
    "            try:\n",
    "                sampler = TPESampler(seed=42)\n",
    "                study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "                objective = create_objective_regression(X_train, y_train, X_test, y_test)\n",
    "                \n",
    "                study.optimize(objective, n_trials=CONFIG.get('N_TRIALS', 20), show_progress_bar=False)\n",
    "                \n",
    "                best_params = study.best_params\n",
    "                best_score = study.best_value\n",
    "                \n",
    "                optuna_results['rank'][event] = {\n",
    "                    'best_params': best_params,\n",
    "                    'best_score': best_score,\n",
    "                    'n_trials': len(study.trials),\n",
    "                    'selected_features': selected_features\n",
    "                }\n",
    "                \n",
    "                print(f\"    âœ… æœ€é©åŒ–å®Œäº†\")\n",
    "                print(f\"       æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_params.get('model_name', 'N/A')}\")\n",
    "                print(f\"       RÂ²ã‚¹ã‚³ã‚¢: {best_score:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    âš ï¸  ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. çµæœã®ä¿å­˜\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… Optunaæœ€é©åŒ–å®Œäº†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "globals()['optuna_results'] = optuna_results\n",
    "\n",
    "# çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "print(f\"\\nã€Optunaæœ€é©åŒ–çµæœã‚µãƒãƒªãƒ¼ã€‘\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for task in ['top1', 'top2', 'rank']:\n",
    "    print(f\"\\n{task.upper()}:\")\n",
    "    for event in test_events:\n",
    "        if event in optuna_results[task]:\n",
    "            result = optuna_results[task][event]\n",
    "            print(f\"  {event:8s}: {result['best_params'].get('model_name', 'N/A'):8s} | ã‚¹ã‚³ã‚¢: {result['best_score']:.4f}\")\n",
    "\n",
    "print(f\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã‚»ãƒ«13ä»¥é™ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’å®Ÿæ–½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«13: ç¢ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«13ã€‘ç¢ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 0. äº‹å‰æº–å‚™\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, mean_absolute_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'optuna_results' not in globals():\n",
    "    raise RuntimeError(\"âŒ optuna_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«12Rã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "\n",
    "print(f\"âœ… optuna_results ãŒåˆ©ç”¨å¯èƒ½\")\n",
    "print(f\"âœ… df_merged ãŒåˆ©ç”¨å¯èƒ½: {df_merged.shape}\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆå–å¾—\n",
    "if 'test_events' not in globals():\n",
    "    test_events = CONFIG.get('TEST_EVENTS', ['1day', '4day', '0day', '40day'])\n",
    "else:\n",
    "    test_events = globals()['test_events']\n",
    "\n",
    "# ============================================================\n",
    "# 1. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰é–¢æ•°ï¼ˆãƒ¢ãƒ‡ãƒ«åã‚’çµ±ä¸€ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def build_model_from_params(model_name, params, task_type='binary'):\n",
    "    \"\"\"\n",
    "    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ï¼ˆmodel_nameã‚’çµ±ä¸€ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name : str\n",
    "        'LogReg', 'RF', 'XGB' ãªã©\n",
    "    params : dict\n",
    "        ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : scikit-learn compatible model\n",
    "    \"\"\"\n",
    "    \n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ model_name ã‚’é™¤å»\n",
    "    params_copy = {k: v for k, v in params.items() if k != 'model_name'}\n",
    "    \n",
    "    # model_nameã‚’çµ±ä¸€ï¼ˆã‚»ãƒ«12Rã¨ã®æ•´åˆæ€§ï¼‰\n",
    "    if model_name == 'XGB':\n",
    "        model_name_resolved = 'XGB'\n",
    "    elif model_name == 'LogReg':\n",
    "        model_name_resolved = 'LogReg'\n",
    "    elif model_name == 'RF':\n",
    "        model_name_resolved = 'RF'\n",
    "    else:\n",
    "        model_name_resolved = model_name\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        if model_name_resolved == 'LogReg':\n",
    "            return LogisticRegression(\n",
    "                C=params_copy.get('C', 1.0),\n",
    "                max_iter=1000,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif model_name_resolved == 'RF':\n",
    "            return RandomForestClassifier(\n",
    "                n_estimators=params_copy.get('n_estimators', 100),\n",
    "                max_depth=params_copy.get('max_depth', 10),\n",
    "                min_samples_split=params_copy.get('min_samples_split', 2),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif model_name_resolved == 'XGB':\n",
    "            try:\n",
    "                from xgboost import XGBClassifier\n",
    "                return XGBClassifier(\n",
    "                    n_estimators=params_copy.get('n_estimators', 100),\n",
    "                    max_depth=params_copy.get('max_depth', 6),\n",
    "                    learning_rate=params_copy.get('learning_rate', 0.1),\n",
    "                    random_state=42,\n",
    "                    verbosity=0,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            except ImportError:\n",
    "                print(\"âš ï¸  XGBoost not installed, using RandomForest instead\")\n",
    "                return RandomForestClassifier(\n",
    "                    n_estimators=100,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name_resolved}\")\n",
    "    \n",
    "    else:  # regression\n",
    "        if model_name_resolved == 'Ridge':\n",
    "            return Ridge(\n",
    "                alpha=params_copy.get('alpha', 1.0),\n",
    "                random_state=42\n",
    "            )\n",
    "        elif model_name_resolved == 'RF':\n",
    "            return RandomForestRegressor(\n",
    "                n_estimators=params_copy.get('n_estimators', 100),\n",
    "                max_depth=params_copy.get('max_depth', 10),\n",
    "                min_samples_split=params_copy.get('min_samples_split', 2),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif model_name_resolved == 'XGB':\n",
    "            try:\n",
    "                from xgboost import XGBRegressor\n",
    "                return XGBRegressor(\n",
    "                    n_estimators=params_copy.get('n_estimators', 100),\n",
    "                    max_depth=params_copy.get('max_depth', 6),\n",
    "                    learning_rate=params_copy.get('learning_rate', 0.1),\n",
    "                    random_state=42,\n",
    "                    verbosity=0,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            except ImportError:\n",
    "                print(\"âš ï¸  XGBoost not installed, using RandomForest instead\")\n",
    "                return RandomForestRegressor(\n",
    "                    n_estimators=100,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name_resolved}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. å„ã‚¤ãƒ™ãƒ³ãƒˆãƒ»ã‚¿ã‚¹ã‚¯åˆ¥ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "final_models = {\n",
    "    'top1': {},\n",
    "    'top2': {},\n",
    "    'rank': {}\n",
    "}\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nâœ“ ã‚¤ãƒ™ãƒ³ãƒˆ: {event.upper()}\")\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "    event_col = f'is_{event}'\n",
    "    if event_col not in df_merged.columns:\n",
    "        print(f\"  âš ï¸  ã‚«ãƒ©ãƒ  '{event_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    event_data = df_merged[df_merged[event_col] == 1].copy().reset_index(drop=True)\n",
    "    \n",
    "    if len(event_data) < CONFIG.get('MIN_EVENT_DAYS', 8):\n",
    "        print(f\"  âš ï¸  ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(event_data)}æ—¥\")\n",
    "        continue\n",
    "    \n",
    "    # ========== TOP1: äºŒå€¤åˆ†é¡ ==========\n",
    "    if 'top1' in optuna_results and event in optuna_results['top1']:\n",
    "        print(f\"  â€¢ TOP1 æœ€çµ‚è¨“ç·´ä¸­...\")\n",
    "        \n",
    "        try:\n",
    "            result_top1 = optuna_results['top1'][event]\n",
    "            best_params = result_top1['best_params']\n",
    "            selected_features = result_top1['selected_features']\n",
    "            \n",
    "            X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "            y_top1 = (event_data['last_digit_rank_diff'].values <= 1).astype(int)\n",
    "            \n",
    "            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "            model_name = best_params.get('model_name', 'LogReg')\n",
    "            model = build_model_from_params(model_name, best_params, task_type='binary')\n",
    "            \n",
    "            # è¨“ç·´\n",
    "            model.fit(X_scaled, y_top1)\n",
    "            \n",
    "            # ã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "            y_pred = model.predict(X_scaled)\n",
    "            f1 = f1_score(y_top1, y_pred, zero_division=0)\n",
    "            \n",
    "            final_models['top1'][event] = {\n",
    "                'model': model,\n",
    "                'scaler': scaler,\n",
    "                'model_name': model_name,\n",
    "                'features': selected_features,\n",
    "                'f1_score': f1,\n",
    "                'n_features': len(selected_features)\n",
    "            }\n",
    "            \n",
    "            print(f\"    âœ… è¨“ç·´å®Œäº†\")\n",
    "            print(f\"       ãƒ¢ãƒ‡ãƒ«: {model_name}\")\n",
    "            print(f\"       F1ã‚¹ã‚³ã‚¢: {f1:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    âš ï¸  ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}\")\n",
    "    \n",
    "    # ========== TOP2: äºŒå€¤åˆ†é¡ ==========\n",
    "    if 'top2' in optuna_results and event in optuna_results['top2']:\n",
    "        print(f\"  â€¢ TOP2 æœ€çµ‚è¨“ç·´ä¸­...\")\n",
    "        \n",
    "        try:\n",
    "            result_top2 = optuna_results['top2'][event]\n",
    "            best_params = result_top2['best_params']\n",
    "            selected_features = result_top2['selected_features']\n",
    "            \n",
    "            X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "            y_top2 = (event_data['last_digit_rank_diff'].values <= 2).astype(int)\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            model_name = best_params.get('model_name', 'LogReg')\n",
    "            model = build_model_from_params(model_name, best_params, task_type='binary')\n",
    "            \n",
    "            model.fit(X_scaled, y_top2)\n",
    "            \n",
    "            y_pred = model.predict(X_scaled)\n",
    "            f1 = f1_score(y_top2, y_pred, zero_division=0)\n",
    "            \n",
    "            final_models['top2'][event] = {\n",
    "                'model': model,\n",
    "                'scaler': scaler,\n",
    "                'model_name': model_name,\n",
    "                'features': selected_features,\n",
    "                'f1_score': f1,\n",
    "                'n_features': len(selected_features)\n",
    "            }\n",
    "            \n",
    "            print(f\"    âœ… è¨“ç·´å®Œäº†\")\n",
    "            print(f\"       ãƒ¢ãƒ‡ãƒ«: {model_name}\")\n",
    "            print(f\"       F1ã‚¹ã‚³ã‚¢: {f1:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    âš ï¸  ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}\")\n",
    "    \n",
    "    # ========== RANK: å›å¸° ==========\n",
    "    if 'rank' in optuna_results and event in optuna_results['rank']:\n",
    "        print(f\"  â€¢ RANK æœ€çµ‚è¨“ç·´ä¸­...\")\n",
    "        \n",
    "        try:\n",
    "            result_rank = optuna_results['rank'][event]\n",
    "            best_params = result_rank['best_params']\n",
    "            selected_features = result_rank['selected_features']\n",
    "            \n",
    "            X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "            y_rank = event_data['last_digit_rank_diff'].values\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            model_name = best_params.get('model_name', 'Ridge')\n",
    "            model = build_model_from_params(model_name, best_params, task_type='regression')\n",
    "            \n",
    "            model.fit(X_scaled, y_rank)\n",
    "            \n",
    "            y_pred = model.predict(X_scaled)\n",
    "            y_pred = np.clip(y_pred, 1, 11)\n",
    "            mae = mean_absolute_error(y_rank, y_pred)\n",
    "            r2 = r2_score(y_rank, y_pred)\n",
    "            \n",
    "            final_models['rank'][event] = {\n",
    "                'model': model,\n",
    "                'scaler': scaler,\n",
    "                'model_name': model_name,\n",
    "                'features': selected_features,\n",
    "                'mae': mae,\n",
    "                'r2': r2,\n",
    "                'n_features': len(selected_features)\n",
    "            }\n",
    "            \n",
    "            print(f\"    âœ… è¨“ç·´å®Œäº†\")\n",
    "            print(f\"       ãƒ¢ãƒ‡ãƒ«: {model_name}\")\n",
    "            print(f\"       MAE: {mae:.4f}, RÂ²: {r2:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    âš ï¸  ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. çµæœã®ä¿å­˜\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "globals()['final_models'] = final_models\n",
    "\n",
    "# çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "print(f\"\\nã€æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ã€‘\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for task in ['top1', 'top2', 'rank']:\n",
    "    print(f\"\\n{task.upper()}:\")\n",
    "    for event in test_events:\n",
    "        if event in final_models[task]:\n",
    "            result = final_models[task][event]\n",
    "            if task in ['top1', 'top2']:\n",
    "                print(f\"  {event:8s}: {result['model_name']:10s} | F1: {result['f1_score']:.4f} | ç‰¹å¾´: {result['n_features']}\")\n",
    "            else:\n",
    "                print(f\"  {event:8s}: {result['model_name']:10s} | MAE: {result['mae']:.4f} | RÂ²: {result['r2']:.4f} | ç‰¹å¾´: {result['n_features']}\")\n",
    "\n",
    "print(f\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã‚»ãƒ«14-15ã§è©•ä¾¡ãƒ»äºˆæ¸¬ã‚’å®Ÿæ–½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«14: ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def check_data_integrity(df, verbose=True):\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ã‚’ç¢ºèª\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        æ¤œæŸ»å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿\n",
    "    verbose : bool\n",
    "        è©³ç´°å‡ºåŠ›\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : ãƒã‚§ãƒƒã‚¯çµæœ\n",
    "    \"\"\"\n",
    "    \n",
    "    checks = {}\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯1: å½¢çŠ¶\n",
    "    checks['shape'] = df.shape\n",
    "    checks['n_rows'] = len(df)\n",
    "    checks['n_cols'] = len(df.columns)\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯2: NaN\n",
    "    checks['nan_total'] = df.isnull().sum().sum()\n",
    "    checks['nan_ratio'] = checks['nan_total'] / (df.shape[0] * df.shape[1]) * 100\n",
    "    checks['nan_by_col'] = df.isnull().sum().to_dict()\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯3: ç„¡é™å€¤\n",
    "    checks['inf_total'] = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯4: ãƒ‡ãƒ¼ã‚¿å‹\n",
    "    checks['dtypes'] = df.dtypes.to_dict()\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯5: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡\n",
    "    checks['memory_mb'] = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nğŸ” ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"  å½¢çŠ¶: {checks['shape']}\")\n",
    "        print(f\"  è¡Œæ•°: {checks['n_rows']}\")\n",
    "        print(f\"  åˆ—æ•°: {checks['n_cols']}\")\n",
    "        print(f\"  NaNå€¤: {checks['nan_total']} ({checks['nan_ratio']:.2f}%)\")\n",
    "        print(f\"  ç„¡é™å€¤: {checks['inf_total']}\")\n",
    "        print(f\"  ãƒ¡ãƒ¢ãƒª: {checks['memory_mb']:.2f} MB\")\n",
    "        \n",
    "        if checks['nan_total'] > 0:\n",
    "            print(f\"\\n  NaNåˆ—:\")\n",
    "            for col, count in sorted(checks['nan_by_col'].items(), \n",
    "                                    key=lambda x: x[1], reverse=True):\n",
    "                if count > 0:\n",
    "                    print(f\"    â€¢ {col}: {count}\")\n",
    "    \n",
    "    return checks\n",
    "\n",
    "\n",
    "def check_model_compatibility(model, X_train, task_type='binary'):\n",
    "    \"\"\"\n",
    "    ãƒ¢ãƒ‡ãƒ«ã¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®äº’æ›æ€§ã‚’ç¢ºèª\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : sklearn model\n",
    "        ãƒ¢ãƒ‡ãƒ«\n",
    "    X_train : DataFrame/ndarray\n",
    "        è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : äº’æ›æ€§ã‚ã‚Š\n",
    "    \"\"\"\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯1: ã‚µãƒ³ãƒ—ãƒ«æ•°\n",
    "    if len(X_train) < 10:\n",
    "        checks.append(\"âŒ ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„\")\n",
    "    else:\n",
    "        checks.append(\"âœ… ã‚µãƒ³ãƒ—ãƒ«æ•°: OK\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯2: ç‰¹å¾´é‡æ•°\n",
    "    if X_train.shape[1] == 0:\n",
    "        checks.append(\"âŒ ç‰¹å¾´é‡ãŒãªã„\")\n",
    "    else:\n",
    "        checks.append(f\"âœ… ç‰¹å¾´é‡: {X_train.shape[1]}å€‹\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯3: NaN\n",
    "    if pd.isna(X_train).any().any():\n",
    "        checks.append(\"âŒ NaNãŒå­˜åœ¨\")\n",
    "    else:\n",
    "        checks.append(\"âœ… NaN: ãªã—\")\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯4: ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›äº’æ›æ€§\n",
    "    try:\n",
    "        if task_type == 'binary':\n",
    "            if not hasattr(model, 'predict_proba'):\n",
    "                checks.append(\"âš ï¸  predict_probaãªã—\")\n",
    "        checks.append(\"âœ… ãƒ¢ãƒ‡ãƒ«äº’æ›æ€§: OK\")\n",
    "    except:\n",
    "        checks.append(\"âŒ ãƒ¢ãƒ‡ãƒ«äº’æ›æ€§ã‚¨ãƒ©ãƒ¼\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ãƒ¢ãƒ‡ãƒ«äº’æ›æ€§ãƒã‚§ãƒƒã‚¯\")\n",
    "    for check in checks:\n",
    "        print(f\"  {check}\")\n",
    "    \n",
    "    return all('âœ…' in str(c) for c in checks)\n",
    "\n",
    "\n",
    "def compare_predictions(y_true, y_pred1, y_pred2, model_names=('Model1', 'Model2')):\n",
    "    \"\"\"\n",
    "    2ã¤ã®äºˆæ¸¬ã‚’æ¯”è¼ƒ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        çœŸå®Ÿå€¤\n",
    "    y_pred1 : array-like\n",
    "        ãƒ¢ãƒ‡ãƒ«1ã®äºˆæ¸¬\n",
    "    y_pred2 : array-like\n",
    "        ãƒ¢ãƒ‡ãƒ«2ã®äºˆæ¸¬\n",
    "    model_names : tuple\n",
    "        ãƒ¢ãƒ‡ãƒ«å\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : æ¯”è¼ƒçµæœ\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "    \n",
    "    print(f\"\\nğŸ“Š äºˆæ¸¬æ¯”è¼ƒ: {model_names[0]} vs {model_names[1]}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ä¸€è‡´åº¦\n",
    "    agreement = np.mean(y_pred1 == y_pred2)\n",
    "    print(f\"  äºˆæ¸¬ä¸€è‡´åº¦: {agreement:.4f} ({int(agreement*len(y_true))}/{len(y_true)})\")\n",
    "    \n",
    "    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—\n",
    "    if len(np.unique(y_true)) <= 2:\n",
    "        # åˆ†é¡\n",
    "        acc1 = accuracy_score(y_true, y_pred1)\n",
    "        acc2 = accuracy_score(y_true, y_pred2)\n",
    "        print(f\"\\n  {model_names[0]} Accuracy: {acc1:.4f}\")\n",
    "        print(f\"  {model_names[1]} Accuracy: {acc2:.4f}\")\n",
    "        print(f\"  å·®åˆ†: {abs(acc1 - acc2):.4f}\")\n",
    "    else:\n",
    "        # å›å¸°\n",
    "        mae1 = mean_absolute_error(y_true, y_pred1)\n",
    "        mae2 = mean_absolute_error(y_true, y_pred2)\n",
    "        print(f\"\\n  {model_names[0]} MAE: {mae1:.4f}\")\n",
    "        print(f\"  {model_names[1]} MAE: {mae2:.4f}\")\n",
    "        print(f\"  å·®åˆ†: {abs(mae1 - mae2):.4f}\")\n",
    "\n",
    "\n",
    "def debug_model_predictions(model, X_test, y_test, top_n=10):\n",
    "    \"\"\"\n",
    "    ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’è©³ç´°ã«ãƒ‡ãƒãƒƒã‚°\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : sklearn model\n",
    "        è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«\n",
    "    X_test : DataFrame\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    y_test : Series\n",
    "        ãƒ†ã‚¹ãƒˆãƒ©ãƒ™ãƒ«\n",
    "    top_n : int\n",
    "        è¡¨ç¤ºã™ã‚‹äºˆæ¸¬æ•°\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        y_proba = None\n",
    "    \n",
    "    print(f\"\\nğŸ› äºˆæ¸¬ãƒ‡ãƒãƒƒã‚° (æœ€åˆã®{top_n}ä»¶)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for i in range(min(top_n, len(y_test))):\n",
    "        print(f\"\\n[{i+1}] çœŸå®Ÿ: {y_test.iloc[i]}, äºˆæ¸¬: {y_pred[i]}\", end='')\n",
    "        \n",
    "        if y_proba is not None:\n",
    "            print(f\", ç¢ºç‡: [{y_proba[i][0]:.3f}, {y_proba[i][1]:.3f}]\")\n",
    "        else:\n",
    "            print()\n",
    "        \n",
    "        # ç‰¹å¾´é‡ã®ä¸Šä½5å€‹ã‚’è¡¨ç¤º\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            print(f\"      ç‰¹å¾´é‡TOP3: {X_test.iloc[i].nlargest(3).to_dict()}\")\n",
    "\n",
    "\n",
    "def save_experiment_state(experiment_results, models_dict, filepath='experiment_state.pkl'):\n",
    "    \"\"\"\n",
    "    å®Ÿé¨“çŠ¶æ…‹ã‚’ä¿å­˜\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    experiment_results : ExperimentResults\n",
    "        çµæœç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    models_dict : dict\n",
    "        ãƒ¢ãƒ‡ãƒ«è¾æ›¸\n",
    "    filepath : str\n",
    "        ä¿å­˜å…ˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    state = {\n",
    "        'experiment_results': experiment_results,\n",
    "        'models': models_dict,\n",
    "        'saved_at': datetime.now(),\n",
    "        'config': CONFIG.copy()\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(state, f)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ å®Ÿé¨“çŠ¶æ…‹ã‚’ä¿å­˜\")\n",
    "    print(f\"   ãƒ•ã‚¡ã‚¤ãƒ«: {filepath}\")\n",
    "    print(f\"   çµæœæ•°: {sum(len(tasks) for tasks in experiment_results.results.values())}\")\n",
    "    print(f\"   ã‚µã‚¤ã‚º: {os.path.getsize(filepath) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "\n",
    "def load_experiment_state(filepath='experiment_state.pkl'):\n",
    "    \"\"\"\n",
    "    å®Ÿé¨“çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : å®Ÿé¨“çŠ¶æ…‹\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filepath, 'rb') as f:\n",
    "        state = pickle.load(f)\n",
    "    \n",
    "    print(f\"\\nğŸ“‚ å®Ÿé¨“çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿\")\n",
    "    print(f\"   ãƒ•ã‚¡ã‚¤ãƒ«: {filepath}\")\n",
    "    print(f\"   ä¿å­˜æ—¥æ™‚: {state['saved_at']}\")\n",
    "    print(f\"   çµæœæ•°: {sum(len(tasks) for tasks in state['experiment_results'].results.values())}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def performance_analysis(experiment_results):\n",
    "    \"\"\"\n",
    "    å®Ÿé¨“å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    experiment_results : ExperimentResults\n",
    "        çµæœç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    comparison_df = experiment_results.get_comparison_table()\n",
    "    \n",
    "    if len(comparison_df) == 0:\n",
    "        print(\"  çµæœãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "        return\n",
    "    \n",
    "    # ã‚¹ã‚³ã‚¢çµ±è¨ˆ\n",
    "    print(f\"\\nã€ã‚¹ã‚³ã‚¢çµ±è¨ˆã€‘\")\n",
    "    print(f\"  å¹³å‡: {comparison_df['Score'].mean():.4f}\")\n",
    "    print(f\"  æœ€å¤§: {comparison_df['Score'].max():.4f}\")\n",
    "    print(f\"  æœ€å°: {comparison_df['Score'].min():.4f}\")\n",
    "    print(f\"  ä¸­å¤®å€¤: {comparison_df['Score'].median():.4f}\")\n",
    "    \n",
    "    # è¨“ç·´æ™‚é–“çµ±è¨ˆ\n",
    "    print(f\"\\nã€è¨“ç·´æ™‚é–“ã€‘\")\n",
    "    print(f\"  å¹³å‡: {comparison_df['Time(s)'].mean():.2f}ç§’\")\n",
    "    print(f\"  æœ€å¤§: {comparison_df['Time(s)'].max():.2f}ç§’\")\n",
    "    print(f\"  æœ€å°: {comparison_df['Time(s)'].min():.2f}ç§’\")\n",
    "    print(f\"  åˆè¨ˆ: {comparison_df['Time(s)'].sum():.2f}ç§’\")\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«åˆ¥é›†è¨ˆ\n",
    "    print(f\"\\nã€ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘\")\n",
    "    model_stats = comparison_df.groupby('Model')['Score'].agg(['mean', 'count'])\n",
    "    print(model_stats)\n",
    "    \n",
    "    # ã‚¿ã‚¹ã‚¯åˆ¥é›†è¨ˆ\n",
    "    print(f\"\\nã€ã‚¿ã‚¹ã‚¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘\")\n",
    "    task_stats = comparison_df.groupby('Task')['Score'].agg(['mean', 'count'])\n",
    "    print(task_stats)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«14: ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã®å®šç¾©å®Œäº†\")\n",
    "print(\"   ğŸ” check_data_integrity(df, verbose)\")\n",
    "print(\"   ğŸ“‹ check_model_compatibility(model, X_train, task_type)\")\n",
    "print(\"   ğŸ“Š compare_predictions(y_true, y_pred1, y_pred2, model_names)\")\n",
    "print(\"   ğŸ› debug_model_predictions(model, X_test, y_test, top_n)\")\n",
    "print(\"   ğŸ’¾ save_experiment_state(experiment_results, models_dict, filepath)\")\n",
    "print(\"   ğŸ“‚ load_experiment_state(filepath)\")\n",
    "print(\"   âš¡ performance_analysis(experiment_results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«15: ã‚¤ãƒ™ãƒ³ãƒˆé¸æŠï¼ˆã‚»ãƒ«01ã®CONFIG['TEST_EVENTS']ã‚’å‚ç…§ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«15: ã‚¤ãƒ™ãƒ³ãƒˆé¸æŠã€‘\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 1. å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€æº–å‚™ç¢ºèªã€‘\")\n",
    "\n",
    "if 'CONFIG' not in globals():\n",
    "    raise RuntimeError(\"âŒ CONFIGãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚»ãƒ«01ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "print(\"  âœ… CONFIGå­˜åœ¨ç¢ºèª\")\n",
    "\n",
    "if 'df_merged' not in globals() or df_merged is None:\n",
    "    raise RuntimeError(\"âŒ df_mergedãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«05ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "df_merged = globals()['df_merged']\n",
    "print(f\"  âœ… df_mergedç¢ºèª: {df_merged.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. TEST_EVENTSã‚’CONFIGã‹ã‚‰å–å¾—\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘CONFIG['TEST_EVENTS']ã‚’å–å¾—\")\n",
    "\n",
    "test_events_config = CONFIG.get('TEST_EVENTS', [])\n",
    "\n",
    "if not test_events_config:\n",
    "    raise RuntimeError(\"âŒ CONFIG['TEST_EVENTS']ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚»ãƒ«01ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"  è¨­å®šå€¤: {test_events_config}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. åˆ©ç”¨å¯èƒ½ãªã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã‚’æ¤œå‡º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º\")\n",
    "\n",
    "# df_merged å†…ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ã‚«ãƒ©ãƒ ã‚’æ¤œå‡º\n",
    "available_event_flags = {}\n",
    "for col in df_merged.columns:\n",
    "    if col.startswith('is_'):\n",
    "        event_name = col.replace('is_', '')\n",
    "        available_event_flags[event_name] = col\n",
    "\n",
    "print(f\"  åˆ©ç”¨å¯èƒ½ã‚¤ãƒ™ãƒ³ãƒˆ: {len(available_event_flags)}ç¨®\")\n",
    "print(f\"    ä¾‹: {list(available_event_flags.keys())[:10]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ã‚¤ãƒ™ãƒ³ãƒˆæ¤œè¨¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘ã‚¤ãƒ™ãƒ³ãƒˆæ¤œè¨¼\")\n",
    "\n",
    "valid_events = []\n",
    "invalid_events = []\n",
    "\n",
    "for event in test_events_config:\n",
    "    flag_col = f'is_{event}'\n",
    "    \n",
    "    if flag_col not in df_merged.columns:\n",
    "        invalid_events.append(event)\n",
    "        print(f\"   âŒ {event}: ã‚«ãƒ©ãƒ ä¸åœ¨\")\n",
    "        continue\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿæ—¥æ•°ç¢ºèª\n",
    "    event_count = (df_merged[flag_col] == 1).sum()\n",
    "    min_required = CONFIG.get('MIN_EVENT_DAYS', 8)\n",
    "    \n",
    "    if event_count < min_required:\n",
    "        invalid_events.append(event)\n",
    "        print(f\"   âš ï¸  {event}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({event_count}æ—¥ < {min_required}æ—¥)\")\n",
    "    else:\n",
    "        valid_events.append(event)\n",
    "        print(f\"   âœ… {event}: {event_count}æ—¥\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. æœ€çµ‚ã‚¤ãƒ™ãƒ³ãƒˆæ±ºå®š\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘æœ€çµ‚ã‚¤ãƒ™ãƒ³ãƒˆæ±ºå®š\")\n",
    "\n",
    "if invalid_events:\n",
    "    print(f\"  é™¤å¤–ã‚¤ãƒ™ãƒ³ãƒˆ: {invalid_events}\")\n",
    "\n",
    "if not valid_events:\n",
    "    print(f\"  âš ï¸  æœ‰åŠ¹ãªã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®æ¤œå‡ºã‚¤ãƒ™ãƒ³ãƒˆã‚’ä½¿ç”¨\n",
    "    if available_event_flags:\n",
    "        valid_events = [list(available_event_flags.keys())[0]]\n",
    "        print(f\"  ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {valid_events[0]}ã‚’ä½¿ç”¨\")\n",
    "    else:\n",
    "        raise RuntimeError(\"âŒ åˆ©ç”¨å¯èƒ½ãªã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "test_events = valid_events\n",
    "\n",
    "print(f\"\\n  ğŸ“Š æœ€çµ‚å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆ: {len(test_events)}ç¨®\")\n",
    "for i, event in enumerate(test_events, 1):\n",
    "    flag_col = f'is_{event}'\n",
    "    event_count = (df_merged[flag_col] == 1).sum()\n",
    "    print(f\"    {i}. {event:10s} ({event_count}æ—¥)\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['test_events'] = test_events\n",
    "\n",
    "# ============================================================\n",
    "# 7. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«15: ã‚¤ãƒ™ãƒ³ãƒˆé¸æŠå®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\n  ğŸ“¦ ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²:\")\n",
    "print(f\"     - test_events: {test_events}\")\n",
    "\n",
    "print(f\"\\n  ğŸ“Œ æ¬¡ã®ã‚»ãƒ«ã§ä½¿ç”¨:\")\n",
    "print(f\"     ã‚»ãƒ«16-18: test_events ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«è¨“ç·´\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«16: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯åˆ¥ç‰¹å¾´é‡å¯¾å¿œç‰ˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMRanker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«16ã€‘ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯åˆ¥ç‰¹å¾´é‡å¯¾å¿œç‰ˆï¼‰\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================\n",
    "# 1. å…±é€šã®åˆ†å‰²é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯åˆ¥ç‰¹å¾´é‡å¯¾å¿œï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def split_train_test_by_task(event_data, task_name, task_type='binary', test_size=0.25):\n",
    "    \"\"\"\n",
    "    æ—¥æ™‚ãƒ™ãƒ¼ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã€ã‚¿ã‚¹ã‚¯åˆ¥ã«å‡¦ç†\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    event_data : DataFrame\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå˜ä½ã®ãƒ‡ãƒ¼ã‚¿\n",
    "    task_name : str\n",
    "        ã‚¿ã‚¹ã‚¯å ('top1', 'top2', 'baseline', 'top3')\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    test_size : float\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : {\n",
    "        'X_train': è¨“ç·´ç‰¹å¾´é‡,\n",
    "        'y_train': è¨“ç·´ãƒ©ãƒ™ãƒ«,\n",
    "        'X_test': ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡,\n",
    "        'y_test': ãƒ†ã‚¹ãƒˆãƒ©ãƒ™ãƒ«,\n",
    "        'scaler': StandardScaler,\n",
    "        'feature_names': ä½¿ç”¨ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # combined_task_configã‹ã‚‰ç‰¹å¾´é‡ã‚’å–å¾—\n",
    "    event = event_data['event'].iloc[0] if 'event' in event_data.columns else 'unknown'\n",
    "    \n",
    "    if event in combined_task_config and task_name in combined_task_config[event]:\n",
    "        feature_cols = combined_task_config[event][task_name]['selected_features']\n",
    "    else:\n",
    "        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ç‰¹å¾´é‡ä½¿ç”¨\n",
    "        feature_cols = [col for col in event_data.columns \n",
    "                       if col not in ['date', 'event', 'digit_num', 'current_diff', \n",
    "                                     'last_digit_rank_diff', 'last_digit_rank']]\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ\n",
    "    event_data_sorted = event_data.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # æ™‚ç³»åˆ—åˆ†å‰²\n",
    "    split_idx = int(len(event_data_sorted) * (1 - test_size))\n",
    "    \n",
    "    # ç‰¹å¾´é‡æŠ½å‡º\n",
    "    X_train_raw = event_data_sorted.iloc[:split_idx][feature_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    X_test_raw = event_data_sorted.iloc[split_idx:][feature_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train_raw)\n",
    "    X_test = scaler.transform(X_test_raw)\n",
    "    \n",
    "    # ãƒ©ãƒ™ãƒ«ç”Ÿæˆ\n",
    "    if task_name == 'top1':\n",
    "        y_train = (event_data_sorted.iloc[:split_idx]['last_digit_rank'] == 1).astype(int).values\n",
    "        y_test = (event_data_sorted.iloc[split_idx:]['last_digit_rank'] == 1).astype(int).values\n",
    "    elif task_name == 'top2':\n",
    "        y_train = (event_data_sorted.iloc[:split_idx]['last_digit_rank'] == 2).astype(int).values\n",
    "        y_test = (event_data_sorted.iloc[split_idx:]['last_digit_rank'] == 2).astype(int).values\n",
    "    elif task_name == 'baseline':\n",
    "        y_train = event_data_sorted.iloc[:split_idx]['last_digit_rank_diff'].values\n",
    "        y_test = event_data_sorted.iloc[split_idx:]['last_digit_rank_diff'].values\n",
    "    elif task_name == 'top3':\n",
    "        y_train = event_data_sorted.iloc[:split_idx]['last_digit_rank_diff'].values\n",
    "        y_test = event_data_sorted.iloc[split_idx:]['last_digit_rank_diff'].values\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown task_name: {task_name}\")\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'scaler': scaler,\n",
    "        'feature_names': feature_cols,\n",
    "        'train_indices': event_data_sorted.iloc[:split_idx].index,\n",
    "        'test_indices': event_data_sorted.iloc[split_idx:].index\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# 2. ãƒ¢ãƒ‡ãƒ«ãƒ“ãƒ«ãƒ€ãƒ¼é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯åˆ¥ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "def build_model_from_params(model_name, task_type='binary', params=None):\n",
    "    \"\"\"\n",
    "    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name : str\n",
    "        ãƒ¢ãƒ‡ãƒ«ç¨®é¡\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    params : dict\n",
    "        ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : scikit-learn compatible model\n",
    "    \"\"\"\n",
    "    \n",
    "    if params is None:\n",
    "        params = {}\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        if model_name == 'LogisticRegression':\n",
    "            return LogisticRegression(\n",
    "                C=params.get('C', 1.0),\n",
    "                max_iter=1000,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif model_name == 'RandomForest':\n",
    "            return RandomForestClassifier(\n",
    "                n_estimators=params.get('n_estimators', 100),\n",
    "                max_depth=params.get('max_depth', 10),\n",
    "                min_samples_split=params.get('min_samples_split', 2),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif model_name == 'XGBoost':\n",
    "            return XGBClassifier(\n",
    "                n_estimators=params.get('n_estimators', 100),\n",
    "                max_depth=params.get('max_depth', 6),\n",
    "                learning_rate=params.get('learning_rate', 0.1),\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                verbosity=0\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    else:  # regression\n",
    "        if model_name == 'Ridge':\n",
    "            return Ridge(\n",
    "                alpha=params.get('alpha', 1.0),\n",
    "                random_state=42\n",
    "            )\n",
    "        elif model_name == 'RandomForest':\n",
    "            return RandomForestRegressor(\n",
    "                n_estimators=params.get('n_estimators', 100),\n",
    "                max_depth=params.get('max_depth', 10),\n",
    "                min_samples_split=params.get('min_samples_split', 2),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif model_name == 'LightGBM':\n",
    "            return LGBMRegressor(\n",
    "                n_estimators=params.get('n_estimators', 100),\n",
    "                max_depth=params.get('max_depth', 7),\n",
    "                learning_rate=params.get('learning_rate', 0.1),\n",
    "                num_leaves=params.get('num_leaves', 31),\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                verbosity=-1\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. è©•ä¾¡ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_binary_model(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"äºŒå€¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡\"\"\"\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            metrics['auc'] = roc_auc_score(y_true, y_pred_proba)\n",
    "        except:\n",
    "            metrics['auc'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluate_regression_model(y_true, y_pred):\n",
    "    \"\"\"å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡\"\"\"\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from scipy.stats import spearmanr\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    spearman_r, _ = spearmanr(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'spearman': spearman_r\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# 4. ãƒ­ã‚°å‡ºåŠ›é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def print_model_info(event, task_name, config):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å‡ºåŠ›\"\"\"\n",
    "    print(f\"  ğŸ“‹ {task_name.upper()}:\")\n",
    "    print(f\"     ãƒ¢ãƒ‡ãƒ«: {config['model_name']}\")\n",
    "    print(f\"     ç‰¹å¾´é‡: {len(config['selected_features'])}å€‹\")\n",
    "    print(f\"     ã‚¹ã‚³ã‚¢: {config['best_score']:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… ã‚»ãƒ«16å®Œäº†: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’å®šç¾©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«17: TOP1å­¦ç¿’ï¼ˆæ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾å¿œç‰ˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«17ã€‘TOP1å­¦ç¿’ï¼ˆäºŒå€¤åˆ†é¡ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 0. äº‹å‰æº–å‚™\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'final_models' not in globals():\n",
    "    raise RuntimeError(\"âŒ final_models ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«13ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "\n",
    "if 'cv_feature_results' not in globals():\n",
    "    raise RuntimeError(\"âŒ cv_feature_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«11Rã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"âœ… final_models ãŒåˆ©ç”¨å¯èƒ½\")\n",
    "print(f\"âœ… df_merged ãŒåˆ©ç”¨å¯èƒ½: {df_merged.shape}\")\n",
    "print(f\"âœ… cv_feature_results ãŒåˆ©ç”¨å¯èƒ½\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆå–å¾—\n",
    "if 'test_events' not in globals():\n",
    "    test_events = CONFIG.get('TEST_EVENTS', ['1day', '4day', '0day', '40day'])\n",
    "else:\n",
    "    test_events = globals()['test_events']\n",
    "\n",
    "# ============================================================\n",
    "# 1. çµæœæ ¼ç´ç”¨ï¼ˆã¾ã ãªã‘ã‚Œã°åˆæœŸåŒ–ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "if 'top_rank_results' not in globals():\n",
    "    top_rank_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# 2. TOP1å­¦ç¿’å®Ÿæ–½\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€TOP1å­¦ç¿’é–‹å§‹ã€‘\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nâœ“ ã‚¤ãƒ™ãƒ³ãƒˆ: {event.upper()}\")\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "    event_col = f'is_{event}'\n",
    "    if event_col not in df_merged.columns:\n",
    "        print(f\"  âš ï¸  ã‚«ãƒ©ãƒ  '{event_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    event_data = df_merged[df_merged[event_col] == 1].copy().reset_index(drop=True)\n",
    "    \n",
    "    if len(event_data) < CONFIG.get('MIN_EVENT_DAYS', 8):\n",
    "        print(f\"  âš ï¸  ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(event_data)}æ—¥\")\n",
    "        continue\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆç”¨ã®çµæœè¾æ›¸ã‚’åˆæœŸåŒ–\n",
    "    if event not in top_rank_results:\n",
    "        top_rank_results[event] = {}\n",
    "    \n",
    "    # ========== TOP1ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª ==========\n",
    "    if 'top1' not in final_models or event not in final_models['top1']:\n",
    "        print(f\"  âš ï¸  TOP1ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  â€¢ TOP1ãƒ¢ãƒ‡ãƒ«å–å¾—...\")\n",
    "    \n",
    "    try:\n",
    "        model_info = final_models['top1'][event]\n",
    "        model = model_info['model']\n",
    "        scaler = model_info['scaler']\n",
    "        selected_features = model_info['features']\n",
    "        \n",
    "        print(f\"    âœ… ãƒ¢ãƒ‡ãƒ«æƒ…å ±: {model_info['model_name']}\")\n",
    "        print(f\"       ç‰¹å¾´é‡æ•°: {len(selected_features)}\")\n",
    "        \n",
    "        # ========== ãƒ‡ãƒ¼ã‚¿æº–å‚™ ==========\n",
    "        print(f\"  â€¢ ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...\")\n",
    "        \n",
    "        X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "        X_scaled = scaler.transform(X)\n",
    "        y = (event_data['last_digit_rank_diff'].values <= 1).astype(int)\n",
    "        \n",
    "        print(f\"    âœ… ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: X={X_scaled.shape}, y={y.shape}\")\n",
    "        print(f\"       ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: æ­£ä¾‹={np.sum(y)}, è² ä¾‹={np.sum(1-y)}\")\n",
    "        \n",
    "        # ========== äºˆæ¸¬ ==========\n",
    "        print(f\"  â€¢ äºˆæ¸¬å®Ÿæ–½ä¸­...\")\n",
    "        \n",
    "        y_pred = model.predict(X_scaled)\n",
    "        \n",
    "        # ç¢ºç‡æ¨å®š\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = y_pred.astype(float)\n",
    "        \n",
    "        print(f\"    âœ… äºˆæ¸¬å®Œäº†\")\n",
    "        \n",
    "        # ========== è©•ä¾¡æŒ‡æ¨™è¨ˆç®— ==========\n",
    "        print(f\"  â€¢ è©•ä¾¡æŒ‡æ¨™è¨ˆç®—ä¸­...\")\n",
    "        \n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        f1 = f1_score(y, y_pred, zero_division=0)\n",
    "        precision = precision_score(y, y_pred, zero_division=0)\n",
    "        recall = recall_score(y, y_pred, zero_division=0)\n",
    "        \n",
    "        print(f\"    âœ… è©•ä¾¡å®Œäº†\")\n",
    "        print(f\"       Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"       F1ã‚¹ã‚³ã‚¢: {f1:.4f}\")\n",
    "        print(f\"       Precision: {precision:.4f}\")\n",
    "        print(f\"       Recall: {recall:.4f}\")\n",
    "        \n",
    "        # ========== çµæœä¿å­˜ ==========\n",
    "        top_rank_results[event]['top1'] = {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'model_name': model_info['model_name'],\n",
    "            'selected_features': selected_features,\n",
    "            'metrics': {\n",
    "                'accuracy': accuracy,\n",
    "                'f1': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall\n",
    "            },\n",
    "            'predictions': y_pred_proba,\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y,\n",
    "            'n_features': len(selected_features)\n",
    "        }\n",
    "        \n",
    "        print(f\"    âœ… çµæœä¿å­˜å®Œäº†\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ============================================================\n",
    "# 3. ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¿å­˜\n",
    "# ============================================================\n",
    "\n",
    "globals()['top_rank_results'] = top_rank_results\n",
    "\n",
    "# ============================================================\n",
    "# 4. ã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… ã‚»ãƒ«17: TOP1å­¦ç¿’å®Œäº†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "completed_count = sum(1 for e in test_events if e in top_rank_results and 'top1' in top_rank_results[e])\n",
    "print(f\"\\n  å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆ: {completed_count}/{len(test_events)}\")\n",
    "\n",
    "if completed_count > 0:\n",
    "    print(f\"\\n  ã€çµæœã‚µãƒãƒªãƒ¼ã€‘\")\n",
    "    for event in test_events:\n",
    "        if event in top_rank_results and 'top1' in top_rank_results[event]:\n",
    "            result = top_rank_results[event]['top1']\n",
    "            print(f\"    {event:8s}: F1={result['metrics']['f1']:.4f}, Acc={result['metrics']['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã‚»ãƒ«18ã§ TOP2å­¦ç¿’ã‚’å®Ÿæ–½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«17-2: TOP2å­¦ç¿’ï¼ˆæ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾å¿œç‰ˆï¼‰\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«18ã€‘TOP2å­¦ç¿’ï¼ˆäºŒå€¤åˆ†é¡ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 0. äº‹å‰æº–å‚™\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'final_models' not in globals():\n",
    "    raise RuntimeError(\"âŒ final_models ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«13ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "\n",
    "if 'top_rank_results' not in globals():\n",
    "    raise RuntimeError(\"âŒ top_rank_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«17ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"âœ… final_models ãŒåˆ©ç”¨å¯èƒ½\")\n",
    "print(f\"âœ… df_merged ãŒåˆ©ç”¨å¯èƒ½: {df_merged.shape}\")\n",
    "print(f\"âœ… top_rank_results ãŒåˆ©ç”¨å¯èƒ½\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆå–å¾—\n",
    "if 'test_events' not in globals():\n",
    "    test_events = CONFIG.get('TEST_EVENTS', ['1day', '4day', '0day', '40day'])\n",
    "else:\n",
    "    test_events = globals()['test_events']\n",
    "\n",
    "# ============================================================\n",
    "# 1. TOP2å­¦ç¿’å®Ÿæ–½\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€TOP2å­¦ç¿’é–‹å§‹ã€‘\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nâœ“ ã‚¤ãƒ™ãƒ³ãƒˆ: {event.upper()}\")\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "    event_col = f'is_{event}'\n",
    "    if event_col not in df_merged.columns:\n",
    "        print(f\"  âš ï¸  ã‚«ãƒ©ãƒ  '{event_col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    event_data = df_merged[df_merged[event_col] == 1].copy().reset_index(drop=True)\n",
    "    \n",
    "    if len(event_data) < CONFIG.get('MIN_EVENT_DAYS', 8):\n",
    "        print(f\"  âš ï¸  ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(event_data)}æ—¥\")\n",
    "        continue\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆç”¨ã®çµæœè¾æ›¸ã‚’ç¢ºèª\n",
    "    if event not in top_rank_results:\n",
    "        top_rank_results[event] = {}\n",
    "    \n",
    "    # ========== TOP2ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª ==========\n",
    "    if 'top2' not in final_models or event not in final_models['top2']:\n",
    "        print(f\"  âš ï¸  TOP2ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  â€¢ TOP2ãƒ¢ãƒ‡ãƒ«å–å¾—...\")\n",
    "    \n",
    "    try:\n",
    "        model_info = final_models['top2'][event]\n",
    "        model = model_info['model']\n",
    "        scaler = model_info['scaler']\n",
    "        selected_features = model_info['features']\n",
    "        \n",
    "        print(f\"    âœ… ãƒ¢ãƒ‡ãƒ«æƒ…å ±: {model_info['model_name']}\")\n",
    "        print(f\"       ç‰¹å¾´é‡æ•°: {len(selected_features)}\")\n",
    "        \n",
    "        # ========== ãƒ‡ãƒ¼ã‚¿æº–å‚™ ==========\n",
    "        print(f\"  â€¢ ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...\")\n",
    "        \n",
    "        X = event_data[selected_features].fillna(0).replace([np.inf, -np.inf], 0).values\n",
    "        X_scaled = scaler.transform(X)\n",
    "        y = (event_data['last_digit_rank_diff'].values <= 2).astype(int)\n",
    "        \n",
    "        print(f\"    âœ… ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: X={X_scaled.shape}, y={y.shape}\")\n",
    "        print(f\"       ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: æ­£ä¾‹={np.sum(y)}, è² ä¾‹={np.sum(1-y)}\")\n",
    "        \n",
    "        # ========== äºˆæ¸¬ ==========\n",
    "        print(f\"  â€¢ äºˆæ¸¬å®Ÿæ–½ä¸­...\")\n",
    "        \n",
    "        y_pred = model.predict(X_scaled)\n",
    "        \n",
    "        # ç¢ºç‡æ¨å®š\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = y_pred.astype(float)\n",
    "        \n",
    "        print(f\"    âœ… äºˆæ¸¬å®Œäº†\")\n",
    "        \n",
    "        # ========== è©•ä¾¡æŒ‡æ¨™è¨ˆç®— ==========\n",
    "        print(f\"  â€¢ è©•ä¾¡æŒ‡æ¨™è¨ˆç®—ä¸­...\")\n",
    "        \n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        f1 = f1_score(y, y_pred, zero_division=0)\n",
    "        precision = precision_score(y, y_pred, zero_division=0)\n",
    "        recall = recall_score(y, y_pred, zero_division=0)\n",
    "        \n",
    "        print(f\"    âœ… è©•ä¾¡å®Œäº†\")\n",
    "        print(f\"       Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"       F1ã‚¹ã‚³ã‚¢: {f1:.4f}\")\n",
    "        print(f\"       Precision: {precision:.4f}\")\n",
    "        print(f\"       Recall: {recall:.4f}\")\n",
    "        \n",
    "        # ========== çµæœä¿å­˜ ==========\n",
    "        top_rank_results[event]['top2'] = {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'model_name': model_info['model_name'],\n",
    "            'selected_features': selected_features,\n",
    "            'metrics': {\n",
    "                'accuracy': accuracy,\n",
    "                'f1': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall\n",
    "            },\n",
    "            'predictions': y_pred_proba,\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y,\n",
    "            'n_features': len(selected_features)\n",
    "        }\n",
    "        \n",
    "        print(f\"    âœ… çµæœä¿å­˜å®Œäº†\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ============================================================\n",
    "# 2. ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¿å­˜\n",
    "# ============================================================\n",
    "\n",
    "globals()['top_rank_results'] = top_rank_results\n",
    "\n",
    "# ============================================================\n",
    "# 3. ã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… ã‚»ãƒ«18: TOP2å­¦ç¿’å®Œäº†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "completed_count = sum(1 for e in test_events if e in top_rank_results and 'top2' in top_rank_results[e])\n",
    "print(f\"\\n  å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆ: {completed_count}/{len(test_events)}\")\n",
    "\n",
    "if completed_count > 0:\n",
    "    print(f\"\\n  ã€çµæœã‚µãƒãƒªãƒ¼ã€‘\")\n",
    "    for event in test_events:\n",
    "        if event in top_rank_results and 'top2' in top_rank_results[event]:\n",
    "            result = top_rank_results[event]['top2']\n",
    "            print(f\"    {event:8s}: F1={result['metrics']['f1']:.4f}, Acc={result['metrics']['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã‚»ãƒ«19ã§ RANKå­¦ç¿’ï¼ˆå›å¸°ï¼‰ã‚’å®Ÿæ–½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«18_æº–å‚™: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã¨ç›®çš„é–¢æ•°ã®å®šç¾©\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, ndcg_score\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from lightgbm import LGBMRanker\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«18_æº–å‚™ã€‘ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã¨ç›®çš„é–¢æ•°ã®å®šç¾©\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 1. ãƒ©ãƒ™ãƒ«å¤‰æ›é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def convert_rank_to_int_label_baseline(rank_diff):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ã‚¯å·®ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆé‡ã¿ä»˜ã‘ãªã—ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rank_diff : array-like\n",
    "        å…ƒã®ãƒ©ãƒ³ã‚¯å·®ï¼ˆ1-11ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    array : ãã®ã¾ã¾è¿”ã™ï¼ˆé‡ã¿ä»˜ã‘ãªã—ï¼‰\n",
    "    \"\"\"\n",
    "    return np.asarray(rank_diff)\n",
    "\n",
    "\n",
    "def convert_rank_to_int_label_top3(rank_diff):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ã‚¯å·®ã‚’éç·šå½¢ãƒ©ãƒ™ãƒ«ã«å¤‰æ›ï¼ˆTOP3ç‰¹åŒ–ã®é‡ã¿ä»˜ã‘ï¼‰\n",
    "    LightGBM rankingç”¨ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰\n",
    "    \n",
    "    rank_diff=1 â†’ 10 (1ä½)\n",
    "    rank_diff=2 â†’ 7  (2ä½)\n",
    "    rank_diff=3 â†’ 4  (3ä½)\n",
    "    rank_diff>3 â†’ 1  (4ä½ä»¥ä¸‹)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rank_diff : array-like\n",
    "        å…ƒã®ãƒ©ãƒ³ã‚¯å·®ï¼ˆ1-11ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    array : é‡ã¿ä»˜ã‘ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«\n",
    "    \"\"\"\n",
    "    rank_diff = np.asarray(rank_diff)\n",
    "    return np.where(rank_diff == 1, 10,\n",
    "                   np.where(rank_diff == 2, 7,\n",
    "                           np.where(rank_diff == 3, 4, 1)))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def compute_rank_metrics(y_test_orig, y_pred_rank):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ã‚¯äºˆæ¸¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_test_orig : array-like\n",
    "        ãƒ†ã‚¹ãƒˆç”¨ç›®çš„å¤‰æ•°ï¼ˆå…ƒã®ãƒ©ãƒ³ã‚¯å€¤ï¼‰\n",
    "    y_pred_rank : array-like\n",
    "        äºˆæ¸¬å€¤\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : è©•ä¾¡æŒ‡æ¨™ã‚’å«ã‚€è¾æ›¸\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_test_orig, y_pred_rank)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_rank))\n",
    "    r2 = r2_score(y_test_orig, y_pred_rank)\n",
    "    spearman, _ = spearmanr(y_test_orig, y_pred_rank)\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'spearman': spearman\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_ndcg_by_group(y_pred, y_test_int, group_test, k=5):\n",
    "    \"\"\"\n",
    "    ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«NDCG@kã‚’è¨ˆç®—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_pred : array-like\n",
    "        ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚¹ã‚³ã‚¢\n",
    "    y_test_int : array-like\n",
    "        ãƒ†ã‚¹ãƒˆç”¨ãƒ©ãƒ™ãƒ«ï¼ˆæ•´æ•°ï¼‰\n",
    "    group_test : list\n",
    "        å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µã‚¤ã‚º\n",
    "    k : int\n",
    "        NDCGè¨ˆç®—æ™‚ã®@kå€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : å¹³å‡NDCG@k\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    test_idx = 0\n",
    "    \n",
    "    for group_size in group_test:\n",
    "        group_pred = y_pred[test_idx:test_idx + group_size]\n",
    "        group_true = y_test_int[test_idx:test_idx + group_size]\n",
    "        \n",
    "        try:\n",
    "            ndcg = ndcg_score([group_true], [group_pred], k=k)\n",
    "            ndcg_scores.append(ndcg)\n",
    "        except:\n",
    "            ndcg_scores.append(0.0)\n",
    "        \n",
    "        test_idx += group_size\n",
    "    \n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. å›å¸°å­¦ç¿’ç”¨ç›®çš„é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def objective_regression(trial, X_train, y_train, X_test, y_test, cv=5):\n",
    "    \"\"\"\n",
    "    å›å¸°å­¦ç¿’ã®ç›®çš„é–¢æ•°\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trial : optuna.trial.Trial\n",
    "        Optuna trial ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    X_train, y_train : array-like\n",
    "        è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "    X_test, y_test : array-like\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    cv : int\n",
    "        ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²æ•°\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : æœ€å°åŒ–ã™ã‚‹ç›®çš„å€¤ï¼ˆMSEï¼‰\n",
    "    \"\"\"\n",
    "    model_name = trial.suggest_categorical('model_name', ['RandomForest', 'Ridge'])\n",
    "    \n",
    "    if model_name == 'RandomForest':\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "            max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "            min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:  # Ridge\n",
    "        model = Ridge(\n",
    "            alpha=trial.suggest_float('alpha', 0.01, 100, log=True)\n",
    "        )\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, \n",
    "                               scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    return -np.mean(cv_scores)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. ãƒ©ãƒ³ã‚­ãƒ³ã‚°å­¦ç¿’ç”¨ç›®çš„é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def objective_ranking_baseline(trial, X_train, y_train_int, X_test, y_test_int, \n",
    "                              group_train, group_test):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ã‚­ãƒ³ã‚°å­¦ç¿’ã®ç›®çš„é–¢æ•°ï¼ˆBASELINEç‰ˆï¼šé‡ã¿ä»˜ã‘ãªã—ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trial : optuna.trial.Trial\n",
    "        Optuna trial ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    X_train, y_train_int : array-like\n",
    "        è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "    X_test, y_test_int : array-like\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "    group_train, group_test : list\n",
    "        å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : æœ€å¤§åŒ–ã™ã‚‹ç›®çš„å€¤ï¼ˆNDCGï¼‰\n",
    "    \"\"\"\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 10, 50)\n",
    "    \n",
    "    model = LGBMRanker(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        num_leaves=num_leaves,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(\n",
    "            X_train, y_train_int,\n",
    "            group=group_train,\n",
    "            eval_set=[(X_test, y_test_int)],\n",
    "            eval_group=[group_test]\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        mean_ndcg = compute_ndcg_by_group(y_pred, y_test_int, group_test, k=5)\n",
    "        \n",
    "        return mean_ndcg\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def objective_ranking_top3(trial, X_train, y_train_int, X_test, y_test_int, \n",
    "                          group_train, group_test):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ã‚­ãƒ³ã‚°å­¦ç¿’ã®ç›®çš„é–¢æ•°ï¼ˆTOP3ç‰ˆï¼šéç·šå½¢é‡ã¿ä»˜ã‘ï¼‰\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trial : optuna.trial.Trial\n",
    "        Optuna trial ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    X_train, y_train_int : array-like\n",
    "        è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼ˆTOP3é‡ã¿ä»˜ã‘ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ï¼‰\n",
    "    X_test, y_test_int : array-like\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆTOP3é‡ã¿ä»˜ã‘ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ï¼‰\n",
    "    group_train, group_test : list\n",
    "        å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : æœ€å¤§åŒ–ã™ã‚‹ç›®çš„å€¤ï¼ˆNDCGï¼‰\n",
    "    \"\"\"\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 10, 50)\n",
    "    \n",
    "    model = LGBMRanker(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        num_leaves=num_leaves,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(\n",
    "            X_train, y_train_int,\n",
    "            group=group_train,\n",
    "            eval_set=[(X_test, y_test_int)],\n",
    "            eval_group=[group_test]\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        mean_ndcg = compute_ndcg_by_group(y_pred, y_test_int, group_test, k=5)\n",
    "        \n",
    "        return mean_ndcg\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nâœ… ã‚»ãƒ«18_æº–å‚™: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã¨ç›®çš„é–¢æ•°ã‚’å®šç¾©å®Œäº†\")\n",
    "print(\"\\nå®šç¾©ã•ã‚ŒãŸé–¢æ•°:\")\n",
    "print(\"  â€¢ convert_rank_to_int_label_baseline()\")\n",
    "print(\"  â€¢ convert_rank_to_int_label_top3()\")\n",
    "print(\"  â€¢ compute_rank_metrics()\")\n",
    "print(\"  â€¢ compute_ndcg_by_group()\")\n",
    "print(\"  â€¢ objective_regression()\")\n",
    "print(\"  â€¢ objective_ranking_baseline()\")\n",
    "print(\"  â€¢ objective_ranking_top3()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«18: çµ±åˆãƒ©ãƒ³ã‚¯å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆ4ãƒ¢ãƒ‡ãƒ«ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, ndcg_score\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRanker\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«18ã€‘çµ±åˆãƒ©ãƒ³ã‚¯å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆ4ãƒ¢ãƒ‡ãƒ«ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 1. ãƒ©ãƒ™ãƒ«å¤‰æ›é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def convert_rank_to_int_label_baseline(rank_diff):\n",
    "    \"\"\"ãƒ©ãƒ³ã‚¯å·®ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆé‡ã¿ä»˜ã‘ãªã—ï¼‰\"\"\"\n",
    "    return np.asarray(rank_diff)\n",
    "\n",
    "\n",
    "def convert_rank_to_int_label_top3(rank_diff):\n",
    "    \"\"\"ãƒ©ãƒ³ã‚¯å·®ã‚’éç·šå½¢ãƒ©ãƒ™ãƒ«ã«å¤‰æ›ï¼ˆTOP3ç‰¹åŒ–ã®é‡ã¿ä»˜ã‘ï¼‰\"\"\"\n",
    "    rank_diff = np.asarray(rank_diff)\n",
    "    return np.where(rank_diff == 1, 10,\n",
    "                   np.where(rank_diff == 2, 7,\n",
    "                           np.where(rank_diff == 3, 4, 1)))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def compute_rank_metrics(y_test_orig, y_pred_rank):\n",
    "    \"\"\"ãƒ©ãƒ³ã‚¯äºˆæ¸¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—\"\"\"\n",
    "    mae = mean_absolute_error(y_test_orig, y_pred_rank)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_rank))\n",
    "    r2 = r2_score(y_test_orig, y_pred_rank)\n",
    "    spearman, _ = spearmanr(y_test_orig, y_pred_rank)\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'spearman': spearman\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_ndcg_by_group(y_pred, y_test_int, group_test, k=5):\n",
    "    \"\"\"ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«NDCG@kã‚’è¨ˆç®—\"\"\"\n",
    "    ndcg_scores = []\n",
    "    test_idx = 0\n",
    "    \n",
    "    for group_size in group_test:\n",
    "        group_pred = y_pred[test_idx:test_idx + group_size]\n",
    "        group_true = y_test_int[test_idx:test_idx + group_size]\n",
    "        \n",
    "        try:\n",
    "            ndcg = ndcg_score([group_true], [group_pred], k=k)\n",
    "            ndcg_scores.append(ndcg)\n",
    "        except:\n",
    "            ndcg_scores.append(0.0)\n",
    "        \n",
    "        test_idx += group_size\n",
    "    \n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. ç›®çš„é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def objective_regression(trial, X_train, y_train, X_test, y_test, cv=5):\n",
    "    \"\"\"å›å¸°å­¦ç¿’ã®ç›®çš„é–¢æ•°\"\"\"\n",
    "    model_name = trial.suggest_categorical('model_name', ['RandomForest', 'Ridge'])\n",
    "    \n",
    "    if model_name == 'RandomForest':\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "            max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "            min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        model = Ridge(alpha=trial.suggest_float('alpha', 0.01, 100, log=True))\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, \n",
    "                               scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -np.mean(cv_scores)\n",
    "\n",
    "\n",
    "def objective_ranking(trial, X_train, y_train_int, X_test, y_test_int, \n",
    "                     group_train, group_test):\n",
    "    \"\"\"ãƒ©ãƒ³ã‚­ãƒ³ã‚°å­¦ç¿’ã®ç›®çš„é–¢æ•°\"\"\"\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 10, 50)\n",
    "    \n",
    "    model = LGBMRanker(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        num_leaves=num_leaves,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(\n",
    "            X_train, y_train_int,\n",
    "            group=group_train,\n",
    "            eval_set=[(X_test, y_test_int)],\n",
    "            eval_group=[group_test]\n",
    "        )\n",
    "        y_pred = model.predict(X_test)\n",
    "        return compute_ndcg_by_group(y_pred, y_test_int, group_test, k=5)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™ã®å…±é€šé–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def prepare_event_data(event, event_data, feature_cols):\n",
    "    \"\"\"\n",
    "    ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆåˆ†å‰²ãƒ»ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : X_train, X_test, y_train, y_test, scaler, split_idx, group_train, group_test\n",
    "    \"\"\"\n",
    "    date_groups = event_data.groupby('date_num').size()\n",
    "    cumsum = date_groups.cumsum().values\n",
    "    total = cumsum[-1]\n",
    "    target_idx = int(total * CONFIG.get('TRAIN_TEST_SPLIT', 0.8))\n",
    "    split_date_position = np.searchsorted(cumsum, target_idx, side='right') - 1\n",
    "    split_idx = cumsum[split_date_position] if split_date_position >= 0 else 0\n",
    "    \n",
    "    X = event_data[feature_cols].values\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    y_rank_diff = event_data['last_digit_rank_diff'].values\n",
    "    \n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y_rank_diff[:split_idx], y_rank_diff[split_idx:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    train_dates = event_data.iloc[:split_idx]['date_num'].values\n",
    "    test_dates = event_data.iloc[split_idx:]['date_num'].values\n",
    "    group_train = pd.Series(train_dates).value_counts().sort_index().values.tolist()\n",
    "    group_test = pd.Series(test_dates).value_counts().sort_index().values.tolist()\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train, 'X_test': X_test,\n",
    "        'y_train': y_train, 'y_test': y_test,\n",
    "        'scaler': scaler, 'split_idx': split_idx,\n",
    "        'group_train': group_train, 'group_test': group_test\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. çµ±åˆå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "def run_rank_learning(event, learning_type, weighting_type, feature_mode):\n",
    "    \"\"\"\n",
    "    çµ±åˆãƒ©ãƒ³ã‚¯å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    event : str\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "    learning_type : str\n",
    "        'regression' or 'ranking'\n",
    "    weighting_type : str\n",
    "        'none' (BASELINE) or 'top3' (TOP3)\n",
    "    feature_mode : str\n",
    "        'baseline' or 'top_3'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict or None : å­¦ç¿’çµæœ\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        event_col = f'is_{event}'\n",
    "        \n",
    "        # ========================================================\n",
    "        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼\n",
    "        # ========================================================\n",
    "        \n",
    "        event_data = df_merged[df_merged[event_col] == 1].copy().sort_values('date_num')\n",
    "        \n",
    "        if len(event_data) < CONFIG.get('MIN_EVENT_DAYS', 8):\n",
    "            return None\n",
    "        \n",
    "        if event not in feature_results_by_model or feature_mode not in feature_results_by_model[event]:\n",
    "            return None\n",
    "        \n",
    "        feature_cols = feature_results_by_model[event][feature_mode]\n",
    "        \n",
    "        # ========================================================\n",
    "        # ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "        # ========================================================\n",
    "        \n",
    "        data = prepare_event_data(event, event_data, feature_cols)\n",
    "        X_train = data['X_train']\n",
    "        X_test = data['X_test']\n",
    "        y_train = data['y_train']\n",
    "        y_test = data['y_test']\n",
    "        scaler = data['scaler']\n",
    "        split_idx = data['split_idx']\n",
    "        group_train = data['group_train']\n",
    "        group_test = data['group_test']\n",
    "        \n",
    "        # ========================================================\n",
    "        # ãƒ©ãƒ™ãƒ«å¤‰æ›\n",
    "        # ========================================================\n",
    "        \n",
    "        if weighting_type == 'top3':\n",
    "            y_train_transformed = convert_rank_to_int_label_top3(y_train)\n",
    "            y_test_transformed = convert_rank_to_int_label_top3(y_test)\n",
    "        else:  # none\n",
    "            y_train_transformed = convert_rank_to_int_label_baseline(y_train)\n",
    "            y_test_transformed = convert_rank_to_int_label_baseline(y_test)\n",
    "        \n",
    "        # ========================================================\n",
    "        # å­¦ç¿’å®Ÿè¡Œ\n",
    "        # ========================================================\n",
    "        \n",
    "        if learning_type == 'regression':\n",
    "            # ===== å›å¸°å­¦ç¿’ =====\n",
    "            sampler = TPESampler(seed=42)\n",
    "            study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "            study.optimize(\n",
    "                lambda trial: objective_regression(trial, X_train, y_train_transformed, X_test, y_test_transformed),\n",
    "                n_trials=CONFIG.get('N_TRIALS', 20),\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "            \n",
    "            best_params = study.best_params.copy()\n",
    "            best_score = study.best_value\n",
    "            \n",
    "            # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "            model_name = best_params['model_name']\n",
    "            if model_name == 'RandomForest':\n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=best_params.get('n_estimators', 100),\n",
    "                    max_depth=best_params.get('max_depth', 10),\n",
    "                    min_samples_split=best_params.get('min_samples_split', 2),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            else:\n",
    "                model = Ridge(alpha=best_params.get('alpha', 1.0))\n",
    "            \n",
    "            model.fit(X_train, y_train_transformed)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # è©•ä¾¡ï¼ˆå…ƒã®ãƒ©ãƒ³ã‚¯å€¤ã§è©•ä¾¡ï¼‰\n",
    "            metrics = compute_rank_metrics(y_test, y_pred)\n",
    "            \n",
    "            return {\n",
    "                'model': model,\n",
    "                'scaler': scaler,\n",
    "                'model_name': model_name,\n",
    "                'selected_features': feature_cols,\n",
    "                'metrics': metrics,\n",
    "                'best_score': best_score,\n",
    "                'best_params': best_params,\n",
    "                'test_data': event_data.iloc[split_idx:].reset_index(drop=True),\n",
    "                'y_pred': y_pred,\n",
    "                'y_test': y_test,\n",
    "                'learning_type': 'regression',\n",
    "                'weighting_applied': weighting_type == 'top3'\n",
    "            }\n",
    "        \n",
    "        else:  # ranking\n",
    "            # ===== ãƒ©ãƒ³ã‚­ãƒ³ã‚°å­¦ç¿’ =====\n",
    "            sampler = TPESampler(seed=42)\n",
    "            study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "            study.optimize(\n",
    "                lambda trial: objective_ranking(trial, X_train, y_train_transformed, X_test, y_test_transformed,\n",
    "                                               group_train, group_test),\n",
    "                n_trials=CONFIG.get('N_TRIALS', 20),\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "            \n",
    "            best_params = study.best_params.copy()\n",
    "            best_score = study.best_value\n",
    "            \n",
    "            # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "            model = LGBMRanker(\n",
    "                n_estimators=best_params.get('n_estimators', 100),\n",
    "                max_depth=best_params.get('max_depth', 5),\n",
    "                learning_rate=best_params.get('learning_rate', 0.1),\n",
    "                num_leaves=best_params.get('num_leaves', 31),\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                verbose=-1\n",
    "            )\n",
    "            \n",
    "            model.fit(\n",
    "                X_train, y_train_transformed,\n",
    "                group=group_train,\n",
    "                eval_set=[(X_test, y_test_transformed)],\n",
    "                eval_group=[group_test]\n",
    "            )\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # è©•ä¾¡\n",
    "            ndcg_val = compute_ndcg_by_group(y_pred, y_test_transformed, group_test, k=5)\n",
    "            metrics = compute_rank_metrics(y_test, y_pred)\n",
    "            metrics['ndcg'] = ndcg_val\n",
    "            \n",
    "            return {\n",
    "                'model': model,\n",
    "                'scaler': scaler,\n",
    "                'model_name': 'LGBMRanker',\n",
    "                'selected_features': feature_cols,\n",
    "                'metrics': metrics,\n",
    "                'best_score': best_score,\n",
    "                'best_params': best_params,\n",
    "                'group_train': group_train,\n",
    "                'group_test': group_test,\n",
    "                'test_data': event_data.iloc[split_idx:].reset_index(drop=True),\n",
    "                'y_pred': y_pred,\n",
    "                'y_test': y_test,\n",
    "                'learning_type': 'ranking',\n",
    "                'weighting_applied': weighting_type == 'top3'\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. çµæœä¿å­˜ç”¨è¾æ›¸ã®åˆæœŸåŒ–\n",
    "# ============================================================\n",
    "\n",
    "rank_baseline_results = {}\n",
    "rank_baseline_ranking_results = {}\n",
    "rank_top3_regression_results = {}\n",
    "rank_top3_ranking_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# 7. ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "learning_configs = [\n",
    "    ('baseline_reg', 'regression', 'none', 'baseline', rank_baseline_results),\n",
    "    ('baseline_rank', 'ranking', 'none', 'baseline', rank_baseline_ranking_results),\n",
    "    ('top3_reg', 'regression', 'top3', 'top_3', rank_top3_regression_results),\n",
    "    ('top3_rank', 'ranking', 'top3', 'top_3', rank_top3_ranking_results),\n",
    "]\n",
    "\n",
    "learning_names = {\n",
    "    'baseline_reg': 'BASELINEå›å¸°ç‰ˆ',\n",
    "    'baseline_rank': 'BASELINE rankingç‰ˆ',\n",
    "    'top3_reg': 'TOP3å›å¸°ç‰ˆ',\n",
    "    'top3_rank': 'TOP3 rankingç‰ˆ',\n",
    "}\n",
    "\n",
    "for config_name, learning_type, weighting_type, feature_mode, results_dict in learning_configs:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ“Œ å­¦ç¿’æ–¹æ³•: {learning_names[config_name]}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for event_idx, event in enumerate(test_events, 1):\n",
    "        if event_idx % 5 == 1 or event_idx == len(test_events):\n",
    "            print(f\"\\n  é€²æ—: [{event_idx}/{len(test_events)}]\", end=\" \")\n",
    "        \n",
    "        result = run_rank_learning(event, learning_type, weighting_type, feature_mode)\n",
    "        results_dict[event] = result\n",
    "        \n",
    "        if result is not None:\n",
    "            print(\"âœ…\", end=\"\")\n",
    "        else:\n",
    "            print(\"âŠ˜\", end=\"\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # ã‚µãƒãƒªãƒ¼\n",
    "    completed = len([e for e in results_dict if results_dict[e] is not None])\n",
    "    print(f\"  å®Œäº†: {completed}/{len(test_events)}\")\n",
    "    \n",
    "    if completed > 0:\n",
    "        results_list = [\n",
    "            (event, results['metrics'].get('rmse', results['metrics'].get('ndcg', 0)))\n",
    "            for event, results in results_dict.items()\n",
    "            if results is not None\n",
    "        ]\n",
    "        metric_name = 'RMSE' if learning_type == 'regression' else 'NDCG'\n",
    "        results_list.sort(key=lambda x: x[1], reverse=(learning_type == 'ranking'))\n",
    "        \n",
    "        print(f\"  ã€ä¸Šä½3ä»¶ï¼ˆ{metric_name}ï¼‰ã€‘\")\n",
    "        for i, (event, value) in enumerate(results_list[:3], 1):\n",
    "            print(f\"    {i}. {event}: {value:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['rank_baseline_results'] = rank_baseline_results\n",
    "globals()['rank_baseline_ranking_results'] = rank_baseline_ranking_results\n",
    "globals()['rank_top3_regression_results'] = rank_top3_regression_results\n",
    "globals()['rank_top3_ranking_results'] = rank_top3_ranking_results\n",
    "\n",
    "# ============================================================\n",
    "# 9. æœ€çµ‚ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«18: çµ±åˆãƒ©ãƒ³ã‚¯å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "baseline_reg_count = len([e for e in rank_baseline_results if rank_baseline_results[e] is not None])\n",
    "baseline_rank_count = len([e for e in rank_baseline_ranking_results if rank_baseline_ranking_results[e] is not None])\n",
    "top3_reg_count = len([e for e in rank_top3_regression_results if rank_top3_regression_results[e] is not None])\n",
    "top3_rank_count = len([e for e in rank_top3_ranking_results if rank_top3_ranking_results[e] is not None])\n",
    "\n",
    "print(f\"\\n  ğŸ“Š å®Œäº†ã‚µãƒãƒªãƒ¼:\")\n",
    "print(f\"     ğŸ”¸ BASELINEå›å¸°ç‰ˆ:       {baseline_reg_count:2d}/{len(test_events)}\")\n",
    "print(f\"     ğŸ”¹ BASELINE rankingç‰ˆ:  {baseline_rank_count:2d}/{len(test_events)}\")\n",
    "print(f\"     ğŸŸ¢ TOP3å›å¸°ç‰ˆ:          {top3_reg_count:2d}/{len(test_events)}\")\n",
    "print(f\"     ğŸŸ¡ TOP3 rankingç‰ˆ:      {top3_rank_count:2d}/{len(test_events)}\")\n",
    "\n",
    "print(f\"\\n  âœ¨ ã‚»ãƒ«19ã§4ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤ºã—ã¾ã™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒãƒƒã‚°: å›å¸°ç‰ˆãŒ NaN ã«ãªã‚‹åŸå› ç‰¹å®š\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ãƒ‡ãƒãƒƒã‚°ã€‘å›å¸°ç‰ˆ (BASELINE/TOP3) ãŒ NaN ã«ãªã‚‹åŸå› \")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================\n",
    "# 1. rank_baseline_results ã®è©³ç´°ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€1ã€‘rank_baseline_results ã®è©³ç´°\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "if 'rank_baseline_results' in globals():\n",
    "    for event, result in rank_baseline_results.items():\n",
    "        if result is None:\n",
    "            print(f\"\\n{event}: Noneï¼ˆã‚¨ãƒ©ãƒ¼ã§å¤±æ•—ï¼‰\")\n",
    "        else:\n",
    "            print(f\"\\n{event}:\")\n",
    "            print(f\"  å‹: {type(result)}\")\n",
    "            \n",
    "            if isinstance(result, dict):\n",
    "                print(f\"  ã‚­ãƒ¼: {list(result.keys())}\")\n",
    "                \n",
    "                # metrics ã‚’ç¢ºèª\n",
    "                if 'metrics' in result:\n",
    "                    print(f\"  metrics:\")\n",
    "                    for key, val in result['metrics'].items():\n",
    "                        if isinstance(val, float):\n",
    "                            print(f\"    {key}: {val:.4f}\" if not np.isnan(val) else f\"    {key}: NaN\")\n",
    "                        else:\n",
    "                            print(f\"    {key}: {val}\")\n",
    "                \n",
    "                # y_pred ã¨ y_test ã‚’ç¢ºèª\n",
    "                if 'y_pred' in result:\n",
    "                    y_pred = result['y_pred']\n",
    "                    print(f\"  y_pred: shape={np.array(y_pred).shape if isinstance(y_pred, (list, np.ndarray)) else 'unknown'}, type={type(y_pred)}\")\n",
    "                    if isinstance(y_pred, (list, np.ndarray)):\n",
    "                        print(f\"          min={np.min(y_pred):.2f}, max={np.max(y_pred):.2f}\")\n",
    "                \n",
    "                if 'y_test' in result:\n",
    "                    y_test = result['y_test']\n",
    "                    print(f\"  y_test: shape={np.array(y_test).shape if isinstance(y_test, (list, np.ndarray)) else 'unknown'}, type={type(y_test)}\")\n",
    "                    if isinstance(y_test, (list, np.ndarray)):\n",
    "                        print(f\"          min={np.min(y_test):.2f}, max={np.max(y_test):.2f}\")\n",
    "else:\n",
    "    print(\"âŒ rank_baseline_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. rank_top3_regression_results ã®è©³ç´°ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\nã€2ã€‘rank_top3_regression_results ã®è©³ç´°\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "if 'rank_top3_regression_results' in globals():\n",
    "    for event, result in rank_top3_regression_results.items():\n",
    "        if result is None:\n",
    "            print(f\"\\n{event}: Noneï¼ˆã‚¨ãƒ©ãƒ¼ã§å¤±æ•—ï¼‰\")\n",
    "        else:\n",
    "            print(f\"\\n{event}:\")\n",
    "            print(f\"  å‹: {type(result)}\")\n",
    "            \n",
    "            if isinstance(result, dict):\n",
    "                print(f\"  ã‚­ãƒ¼: {list(result.keys())}\")\n",
    "                \n",
    "                if 'metrics' in result:\n",
    "                    print(f\"  metrics:\")\n",
    "                    for key, val in result['metrics'].items():\n",
    "                        if isinstance(val, float):\n",
    "                            print(f\"    {key}: {val:.4f}\" if not np.isnan(val) else f\"    {key}: NaN\")\n",
    "                        else:\n",
    "                            print(f\"    {key}: {val}\")\n",
    "else:\n",
    "    print(\"âŒ rank_top3_regression_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. ã‚»ãƒ«19ã®ã‚³ãƒ¼ãƒ‰ã§ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\nã€3ã€‘ã‚»ãƒ«19ã§ NaN ãŒç™ºç”Ÿã™ã‚‹åŸå› \")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "print(f\"\"\"\n",
    "ã‚»ãƒ«19 ã®ä»¥ä¸‹ã®è¡Œã‚’è¦‹ã¦ãã ã•ã„ï¼š\n",
    "\n",
    "```python\n",
    "bl = rank_baseline_results.get(event)\n",
    "...\n",
    "if bl and bl['metrics'].get('rmse_on_rank', np.nan):\n",
    "    regression_results.append({{\n",
    "        'BL_RMSE': bl['metrics'].get('rmse_on_rank', np.nan),\n",
    "        ...\n",
    "    }})\n",
    "```\n",
    "\n",
    "ã€äºˆæƒ³ã•ã‚Œã‚‹å•é¡Œã€‘\n",
    "\n",
    "1. rank_baseline_results ãŒç©ºã®å¯èƒ½æ€§\n",
    "   â†’ ã‚»ãƒ«18ã§å›å¸°ç‰ˆãŒå®Ÿè¡Œã•ã‚Œãªã‹ã£ãŸ\n",
    "\n",
    "2. metrics ã« 'rmse_on_rank' ã‚­ãƒ¼ãŒãªã„\n",
    "   â†’ ç•°ãªã‚‹ã‚­ãƒ¼åã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å¯èƒ½æ€§\n",
    "\n",
    "3. metrics ã®å€¤ãŒå®Ÿéš›ã« NaN\n",
    "   â†’ è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸ\n",
    "\n",
    "ã€ç¢ºèªã™ã‚‹ã«ã¯ã€‘\n",
    "\"\"\")\n",
    "\n",
    "# ã‚»ãƒ«19 ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ‰‹å‹•ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ\n",
    "print(\"\\nã€3-1ã€‘ã‚»ãƒ«19 ã® regression_results æ§‹ç¯‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ\")\n",
    "\n",
    "regression_results = []\n",
    "\n",
    "for event in sorted(rank_baseline_results.keys()):\n",
    "    bl = rank_baseline_results.get(event)\n",
    "    t3 = rank_top3_regression_results.get(event)\n",
    "    \n",
    "    print(f\"\\n{event}:\")\n",
    "    print(f\"  bl: {bl is not None}\")\n",
    "    print(f\"  t3: {t3 is not None}\")\n",
    "    \n",
    "    if bl:\n",
    "        print(f\"  bl['metrics'] keys: {list(bl['metrics'].keys()) if 'metrics' in bl else 'N/A'}\")\n",
    "        if 'metrics' in bl:\n",
    "            rmse_val = bl['metrics'].get('rmse_on_rank', np.nan)\n",
    "            print(f\"  rmse_on_rank: {rmse_val} (NaN: {np.isnan(rmse_val) if isinstance(rmse_val, float) else 'N/A'})\")\n",
    "    \n",
    "    if t3:\n",
    "        print(f\"  t3['metrics'] keys: {list(t3['metrics'].keys()) if 'metrics' in t3 else 'N/A'}\")\n",
    "        if 'metrics' in t3:\n",
    "            rmse_val = t3['metrics'].get('rmse_on_rank', np.nan)\n",
    "            print(f\"  rmse_on_rank: {rmse_val} (NaN: {np.isnan(rmse_val) if isinstance(rmse_val, float) else 'N/A'})\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. åŸå› ã®æ¨æ¸¬\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\nã€4ã€‘åŸå› ã®æ¨æ¸¬ã¨å¯¾å¿œæ–¹æ³•\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "print(f\"\"\"\n",
    "ã€æœ€ã‚‚å¯èƒ½æ€§ãŒé«˜ã„åŸå› ã€‘\n",
    "\n",
    "ã‚»ãƒ«18 ã®å›å¸°ç‰ˆï¼ˆBASELINE_å›å¸° ã¨ TOP3_å›å¸°ï¼‰ãŒ\n",
    "å®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¨ãƒ©ãƒ¼ã§å¤±æ•—ã—ã¦ã„ã‚‹ã€‚\n",
    "\n",
    "ç†ç”±:\n",
    "  â€¢ rank_baseline_results ã¨ rank_top3_regression_results ã«\n",
    "    ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¦ã„ãªã„\n",
    "  â€¢ ã¾ãŸã¯ 'metrics' ã®å€¤ãŒå…¨ã¦ NaN\n",
    "\n",
    "ã€å¯¾å¿œæ–¹æ³•ã€‘\n",
    "\n",
    "1. ã‚»ãƒ«18 ã‚’ç¢ºèªã—ã¦ã€ä»¥ä¸‹ã‚’æ¢ã—ã¦ãã ã•ã„ï¼š\n",
    "\n",
    "   # å­¦ç¿’æ–¹æ³•1: BASELINEå›å¸°ç‰ˆ\n",
    "   # å­¦ç¿’æ–¹æ³•2: TOP3å›å¸°ç‰ˆ\n",
    "\n",
    "2. ã“ã‚Œã‚‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä»¥ä¸‹ã‚’ç¢ºèªï¼š\n",
    "   \n",
    "   âœ“ å®Ÿéš›ã«å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹\n",
    "   âœ“ ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå‡ºã¦ã„ãªã„ã‹\n",
    "   âœ“ rank_baseline_results ã‚„ rank_top3_regression_results ã«\n",
    "     ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‹\n",
    "\n",
    "3. ã‚»ãƒ«18 å®Ÿè¡Œä¸­ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n",
    "\n",
    "ã€ç°¡å˜ãªç¢ºèªæ–¹æ³•ã€‘\n",
    "\n",
    "```python\n",
    "print(len(rank_baseline_results))  # 4 ã§ã‚ã‚‹ã¹ã\n",
    "print(len(rank_baseline_ranking_results))  # 4 ã§ã‚ã‚‹ã¹ã\n",
    "print(len(rank_top3_regression_results))  # 4 ã§ã‚ã‚‹ã¹ã\n",
    "print(len(rank_top3_ranking_results))  # 4 ã§ã‚ã‚‹ã¹ã\n",
    "```\n",
    "\n",
    "å…¨ã¦ 4 ã§ã‚ã‚Œã°ã€metrics ã®ä¸­èº«ãŒ NaN ã®å¯èƒ½æ€§ãŒé«˜ã„ã€‚\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«19: 4ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒçµæœè¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«19ã€‘4ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒçµæœè¡¨ç¤º\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================\n",
    "# 1. çµæœè¾æ›¸ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "results_dicts = {\n",
    "    'BL_reg': rank_baseline_results,\n",
    "    'BL_rank': rank_baseline_ranking_results,\n",
    "    'TOP3_reg': rank_top3_regression_results,\n",
    "    'TOP3_rank': rank_top3_ranking_results,\n",
    "}\n",
    "\n",
    "print(\"\\nâœ… çµæœè¾æ›¸ç¢ºèª:\")\n",
    "for key, results_dict in results_dicts.items():\n",
    "    completed = len([e for e in results_dict if results_dict[e] is not None])\n",
    "    print(f\"   {key:10s}: {completed}/{len(test_events)}å®Œäº†\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "# ============================================================\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for event in test_events:\n",
    "    row = {'Event': event}\n",
    "    \n",
    "    # BASELINEå›å¸°ç‰ˆ\n",
    "    if rank_baseline_results.get(event) is not None:\n",
    "        bl_reg = rank_baseline_results[event]\n",
    "        row['BL_RMSE'] = bl_reg['metrics'].get('rmse', np.nan)\n",
    "        row['BL_R2'] = bl_reg['metrics'].get('r2', np.nan)\n",
    "        row['BL_Spearman'] = bl_reg['metrics'].get('spearman', np.nan)\n",
    "    else:\n",
    "        row['BL_RMSE'] = np.nan\n",
    "        row['BL_R2'] = np.nan\n",
    "        row['BL_Spearman'] = np.nan\n",
    "    \n",
    "    # TOP3å›å¸°ç‰ˆ\n",
    "    if rank_top3_regression_results.get(event) is not None:\n",
    "        top3_reg = rank_top3_regression_results[event]\n",
    "        row['TOP3_RMSE'] = top3_reg['metrics'].get('rmse', np.nan)\n",
    "        row['TOP3_R2'] = top3_reg['metrics'].get('r2', np.nan)\n",
    "        row['TOP3_Spearman'] = top3_reg['metrics'].get('spearman', np.nan)\n",
    "    else:\n",
    "        row['TOP3_RMSE'] = np.nan\n",
    "        row['TOP3_R2'] = np.nan\n",
    "        row['TOP3_Spearman'] = np.nan\n",
    "    \n",
    "    # æ”¹å–„ç‡è¨ˆç®—\n",
    "    if not np.isnan(row['BL_RMSE']) and not np.isnan(row['TOP3_RMSE']):\n",
    "        row['RMSEæ”¹å–„%'] = ((row['TOP3_RMSE'] - row['BL_RMSE']) / row['BL_RMSE']) * 100\n",
    "    else:\n",
    "        row['RMSEæ”¹å–„%'] = np.nan\n",
    "    \n",
    "    if not np.isnan(row['BL_R2']) and not np.isnan(row['TOP3_R2']):\n",
    "        row['R2å·®åˆ†'] = row['TOP3_R2'] - row['BL_R2']\n",
    "    else:\n",
    "        row['R2å·®åˆ†'] = np.nan\n",
    "    \n",
    "    comparison_data.append(row)\n",
    "\n",
    "df_comparison_regression = pd.DataFrame(comparison_data)\n",
    "\n",
    "# ============================================================\n",
    "# 3. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆã®æ¯”è¼ƒ\n",
    "# ============================================================\n",
    "\n",
    "ranking_comparison_data = []\n",
    "\n",
    "for event in test_events:\n",
    "    row = {'Event': event}\n",
    "    \n",
    "    # BASELINE rankingç‰ˆ\n",
    "    if rank_baseline_ranking_results.get(event) is not None:\n",
    "        bl_rank = rank_baseline_ranking_results[event]\n",
    "        row['BL_NDCG'] = bl_rank['metrics'].get('ndcg', np.nan)\n",
    "        row['BL_Spearman'] = bl_rank['metrics'].get('spearman', np.nan)\n",
    "        row['BL_RMSE'] = bl_rank['metrics'].get('rmse', np.nan)\n",
    "    else:\n",
    "        row['BL_NDCG'] = np.nan\n",
    "        row['BL_Spearman'] = np.nan\n",
    "        row['BL_RMSE'] = np.nan\n",
    "    \n",
    "    # TOP3 rankingç‰ˆ\n",
    "    if rank_top3_ranking_results.get(event) is not None:\n",
    "        top3_rank = rank_top3_ranking_results[event]\n",
    "        row['TOP3_NDCG'] = top3_rank['metrics'].get('ndcg', np.nan)\n",
    "        row['TOP3_Spearman'] = top3_rank['metrics'].get('spearman', np.nan)\n",
    "        row['TOP3_RMSE'] = top3_rank['metrics'].get('rmse', np.nan)\n",
    "    else:\n",
    "        row['TOP3_NDCG'] = np.nan\n",
    "        row['TOP3_Spearman'] = np.nan\n",
    "        row['TOP3_RMSE'] = np.nan\n",
    "    \n",
    "    # æ”¹å–„ç‡è¨ˆç®—\n",
    "    if not np.isnan(row['BL_NDCG']) and not np.isnan(row['TOP3_NDCG']):\n",
    "        row['NDCGæ”¹å–„%'] = ((row['TOP3_NDCG'] - row['BL_NDCG']) / row['BL_NDCG']) * 100\n",
    "    else:\n",
    "        row['NDCGæ”¹å–„%'] = np.nan\n",
    "    \n",
    "    if not np.isnan(row['BL_Spearman']) and not np.isnan(row['TOP3_Spearman']):\n",
    "        row['Spearmanæ”¹å–„%'] = ((row['TOP3_Spearman'] - row['BL_Spearman']) / row['BL_Spearman']) * 100\n",
    "    else:\n",
    "        row['Spearmanæ”¹å–„%'] = np.nan\n",
    "    \n",
    "    ranking_comparison_data.append(row)\n",
    "\n",
    "df_comparison_ranking = pd.DataFrame(ranking_comparison_data)\n",
    "\n",
    "# ============================================================\n",
    "# 4. è¡¨ç¤ºé–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def format_number(val, decimal=4):\n",
    "    \"\"\"æ•°å€¤ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ\"\"\"\n",
    "    if np.isnan(val):\n",
    "        return \"NaN\"\n",
    "    return f\"{val:.{decimal}f}\"\n",
    "\n",
    "\n",
    "def print_comparison_table(df, title, columns):\n",
    "    \"\"\"æ¯”è¼ƒè¡¨ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º\"\"\"\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # ãƒ˜ãƒƒãƒ€ãƒ¼\n",
    "    header = f\"{'Event':8s}\"\n",
    "    for col in columns:\n",
    "        header += f\"  {col:12s}\"\n",
    "    print(header)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿è¡Œ\n",
    "    for _, row in df.iterrows():\n",
    "        line = f\"{row['Event']:8s}\"\n",
    "        for col in columns:\n",
    "            val = row.get(col, np.nan)\n",
    "            if isinstance(val, (int, float)):\n",
    "                line += f\"  {format_number(val):12s}\"\n",
    "            else:\n",
    "                line += f\"  {str(val):12s}\"\n",
    "        print(line)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "# å›å¸°ç‰ˆ\n",
    "regression_columns = ['BL_RMSE', 'BL_R2', 'BL_Spearman', 'TOP3_RMSE', 'TOP3_R2', 'TOP3_Spearman', 'RMSEæ”¹å–„%', 'R2å·®åˆ†']\n",
    "print_comparison_table(df_comparison_regression, \n",
    "                      \"ã€è¡¨1ã€‘ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥æ¯”è¼ƒ - å›å¸°ç‰ˆï¼ˆBASELINE vs TOP3ï¼‰\",\n",
    "                      regression_columns)\n",
    "\n",
    "# ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆ\n",
    "ranking_columns = ['BL_NDCG', 'BL_Spearman', 'BL_RMSE', 'TOP3_NDCG', 'TOP3_Spearman', 'TOP3_RMSE', 'NDCGæ”¹å–„%', 'Spearmanæ”¹å–„%']\n",
    "print_comparison_table(df_comparison_ranking,\n",
    "                      \"ã€è¡¨2ã€‘ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥æ¯”è¼ƒ - ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆï¼ˆBASELINE vs TOP3ï¼‰\",\n",
    "                      ranking_columns)\n",
    "\n",
    "# ============================================================\n",
    "# 6. è©³ç´°ãªçµ±è¨ˆæƒ…å ±\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€è©³ç´°çµ±è¨ˆæƒ…å ±ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "# å›å¸°ç‰ˆã®çµ±è¨ˆ\n",
    "print(\"\\nã€å›å¸°ç‰ˆã®çµ±è¨ˆã€‘\")\n",
    "print(\"\\nBASELINEå›å¸°ç‰ˆ:\")\n",
    "bl_reg_rmse = df_comparison_regression['BL_RMSE'].dropna()\n",
    "if len(bl_reg_rmse) > 0:\n",
    "    print(f\"  RMSE: mean={bl_reg_rmse.mean():.4f}, std={bl_reg_rmse.std():.4f}, min={bl_reg_rmse.min():.4f}, max={bl_reg_rmse.max():.4f}\")\n",
    "    print(f\"  RÂ²:   mean={df_comparison_regression['BL_R2'].mean():.4f}, std={df_comparison_regression['BL_R2'].std():.4f}\")\n",
    "\n",
    "print(\"\\nTOP3å›å¸°ç‰ˆ:\")\n",
    "top3_reg_rmse = df_comparison_regression['TOP3_RMSE'].dropna()\n",
    "if len(top3_reg_rmse) > 0:\n",
    "    print(f\"  RMSE: mean={top3_reg_rmse.mean():.4f}, std={top3_reg_rmse.std():.4f}, min={top3_reg_rmse.min():.4f}, max={top3_reg_rmse.max():.4f}\")\n",
    "    print(f\"  RÂ²:   mean={df_comparison_regression['TOP3_R2'].mean():.4f}, std={df_comparison_regression['TOP3_R2'].std():.4f}\")\n",
    "\n",
    "# ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆã®çµ±è¨ˆ\n",
    "print(\"\\nã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆã®çµ±è¨ˆã€‘\")\n",
    "print(\"\\nBASELINE rankingç‰ˆ:\")\n",
    "bl_rank_ndcg = df_comparison_ranking['BL_NDCG'].dropna()\n",
    "if len(bl_rank_ndcg) > 0:\n",
    "    print(f\"  NDCG:     mean={bl_rank_ndcg.mean():.4f}, std={bl_rank_ndcg.std():.4f}, min={bl_rank_ndcg.min():.4f}, max={bl_rank_ndcg.max():.4f}\")\n",
    "    print(f\"  Spearman: mean={df_comparison_ranking['BL_Spearman'].mean():.4f}, std={df_comparison_ranking['BL_Spearman'].std():.4f}\")\n",
    "else:\n",
    "    print(\"  ãƒ‡ãƒ¼ã‚¿ãªã—\")\n",
    "\n",
    "print(\"\\nTOP3 rankingç‰ˆ:\")\n",
    "top3_rank_ndcg = df_comparison_ranking['TOP3_NDCG'].dropna()\n",
    "if len(top3_rank_ndcg) > 0:\n",
    "    print(f\"  NDCG:     mean={top3_rank_ndcg.mean():.4f}, std={top3_rank_ndcg.std():.4f}, min={top3_rank_ndcg.min():.4f}, max={top3_rank_ndcg.max():.4f}\")\n",
    "    print(f\"  Spearman: mean={df_comparison_ranking['TOP3_Spearman'].mean():.4f}, std={df_comparison_ranking['TOP3_Spearman'].std():.4f}\")\n",
    "else:\n",
    "    print(\"  ãƒ‡ãƒ¼ã‚¿ãªã—\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«æŠ½å‡º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "print(\"\\nå›å¸°ç‰ˆ:\")\n",
    "best_rmse_idx = df_comparison_regression['BL_RMSE'].idxmin()\n",
    "best_rmse_event = df_comparison_regression.loc[best_rmse_idx, 'Event']\n",
    "best_rmse_value = df_comparison_regression.loc[best_rmse_idx, 'BL_RMSE']\n",
    "print(f\"  BASELINEå›å¸°ç‰ˆ: {best_rmse_event} (RMSE={best_rmse_value:.4f})\")\n",
    "\n",
    "best_r2_idx = df_comparison_regression['BL_R2'].idxmax()\n",
    "best_r2_event = df_comparison_regression.loc[best_r2_idx, 'Event']\n",
    "best_r2_value = df_comparison_regression.loc[best_r2_idx, 'BL_R2']\n",
    "print(f\"  BASELINEå›å¸°ç‰ˆï¼ˆRÂ²ï¼‰: {best_r2_event} (RÂ²={best_r2_value:.4f})\")\n",
    "\n",
    "print(\"\\nãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆ:\")\n",
    "best_ndcg_idx = df_comparison_ranking['BL_NDCG'].idxmax()\n",
    "if not pd.isna(best_ndcg_idx):\n",
    "    best_ndcg_event = df_comparison_ranking.loc[best_ndcg_idx, 'Event']\n",
    "    best_ndcg_value = df_comparison_ranking.loc[best_ndcg_idx, 'BL_NDCG']\n",
    "    print(f\"  BASELINE rankingç‰ˆ: {best_ndcg_event} (NDCG={best_ndcg_value:.4f})\")\n",
    "else:\n",
    "    print(f\"  BASELINE rankingç‰ˆ: ãƒ‡ãƒ¼ã‚¿ãªã—\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['df_comparison_regression'] = df_comparison_regression\n",
    "globals()['df_comparison_ranking'] = df_comparison_ranking\n",
    "\n",
    "# ============================================================\n",
    "# 9. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"âœ… ã‚»ãƒ«19: 4ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒçµæœè¡¨ç¤ºå®Œäº†\")\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"\\nå¤‰æ•°ä¿å­˜:\")\n",
    "print(f\"  â€¢ df_comparison_regression - å›å¸°ç‰ˆã®æ¯”è¼ƒè¡¨\")\n",
    "print(f\"  â€¢ df_comparison_ranking - ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆã®æ¯”è¼ƒè¡¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ã€€20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«21: åŸºæœ¬çµ±è¨ˆ\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ã‚»ãƒ«21: åŸºæœ¬çµ±è¨ˆ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'top_rank_results' not in globals():\n",
    "    print(\"âŒ top_rank_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    top_rank_results = globals()['top_rank_results']\n",
    "    \n",
    "    print(f\"\\nã€åŸºæœ¬çµ±è¨ˆæƒ…å ±ã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # ===== åˆ†é¡ã‚¿ã‚¹ã‚¯çµ±è¨ˆ =====\n",
    "    print(f\"\\nã€åˆ†é¡ã‚¿ã‚¹ã‚¯ï¼ˆTOP1/TOP2ï¼‰çµ±è¨ˆã€‘\")\n",
    "    \n",
    "    classification_stats = []\n",
    "    \n",
    "    for event in sorted(top_rank_results.keys()):\n",
    "        tasks = top_rank_results[event]\n",
    "        \n",
    "        row = {\n",
    "            'Event': event.upper(),\n",
    "        }\n",
    "        \n",
    "        # TOP1çµ±è¨ˆ\n",
    "        if 'top1' in tasks:\n",
    "            metrics = tasks['top1']['metrics']\n",
    "            row.update({\n",
    "                'TOP1_Accuracy': f\"{metrics.get('accuracy', 0):.4f}\",\n",
    "                'TOP1_F1': f\"{metrics.get('f1', 0):.4f}\",\n",
    "                'TOP1_Precision': f\"{metrics.get('precision', 0):.4f}\",\n",
    "                'TOP1_Recall': f\"{metrics.get('recall', 0):.4f}\",\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                'TOP1_Accuracy': 'N/A',\n",
    "                'TOP1_F1': 'N/A',\n",
    "                'TOP1_Precision': 'N/A',\n",
    "                'TOP1_Recall': 'N/A',\n",
    "            })\n",
    "        \n",
    "        # TOP2çµ±è¨ˆ\n",
    "        if 'top2' in tasks:\n",
    "            metrics = tasks['top2']['metrics']\n",
    "            row.update({\n",
    "                'TOP2_Accuracy': f\"{metrics.get('accuracy', 0):.4f}\",\n",
    "                'TOP2_F1': f\"{metrics.get('f1', 0):.4f}\",\n",
    "                'TOP2_Precision': f\"{metrics.get('precision', 0):.4f}\",\n",
    "                'TOP2_Recall': f\"{metrics.get('recall', 0):.4f}\",\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                'TOP2_Accuracy': 'N/A',\n",
    "                'TOP2_F1': 'N/A',\n",
    "                'TOP2_Precision': 'N/A',\n",
    "                'TOP2_Recall': 'N/A',\n",
    "            })\n",
    "        \n",
    "        classification_stats.append(row)\n",
    "    \n",
    "    classification_df = pd.DataFrame(classification_stats)\n",
    "    \n",
    "    print(f\"\\nåˆ†é¡ã‚¿ã‚¹ã‚¯è©³ç´°:\")\n",
    "    print(classification_df.to_string(index=False))\n",
    "    \n",
    "    # ===== å›å¸°ã‚¿ã‚¹ã‚¯çµ±è¨ˆ =====\n",
    "    print(f\"\\nã€å›å¸°ã‚¿ã‚¹ã‚¯ï¼ˆãƒ©ãƒ³ã‚¯å­¦ç¿’ï¼‰çµ±è¨ˆã€‘\")\n",
    "    \n",
    "    regression_stats = []\n",
    "    \n",
    "    for event in sorted(top_rank_results.keys()):\n",
    "        tasks = top_rank_results[event]\n",
    "        \n",
    "        row = {\n",
    "            'Event': event.upper(),\n",
    "        }\n",
    "        \n",
    "        # BASELINEçµ±è¨ˆ\n",
    "        if 'rank_baseline' in tasks:\n",
    "            metrics = tasks['rank_baseline']['metrics']\n",
    "            row.update({\n",
    "                'Baseline_MAE': f\"{metrics.get('mae', 0):.4f}\",\n",
    "                'Baseline_RMSE': f\"{metrics.get('rmse', 0):.4f}\",\n",
    "                'Baseline_Spearman': f\"{metrics.get('spearman_corr', 0):.4f}\",\n",
    "                'Baseline_Top3HR': f\"{metrics.get('top3_hit_rate', 0):.4f}\",\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                'Baseline_MAE': 'N/A',\n",
    "                'Baseline_RMSE': 'N/A',\n",
    "                'Baseline_Spearman': 'N/A',\n",
    "                'Baseline_Top3HR': 'N/A',\n",
    "            })\n",
    "        \n",
    "        # TOP3çµ±è¨ˆ\n",
    "        if 'rank_top3' in tasks:\n",
    "            metrics = tasks['rank_top3']['metrics']\n",
    "            row.update({\n",
    "                'Top3_MAE': f\"{metrics.get('mae', 0):.4f}\",\n",
    "                'Top3_RMSE': f\"{metrics.get('rmse', 0):.4f}\",\n",
    "                'Top3_Spearman': f\"{metrics.get('spearman_corr', 0):.4f}\",\n",
    "                'Top3_HR': f\"{metrics.get('top3_hit_rate', 0):.4f}\",\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                'Top3_MAE': 'N/A',\n",
    "                'Top3_RMSE': 'N/A',\n",
    "                'Top3_Spearman': 'N/A',\n",
    "                'Top3_HR': 'N/A',\n",
    "            })\n",
    "        \n",
    "        regression_stats.append(row)\n",
    "    \n",
    "    regression_df = pd.DataFrame(regression_stats)\n",
    "    \n",
    "    print(f\"\\nå›å¸°ã‚¿ã‚¹ã‚¯è©³ç´°:\")\n",
    "    print(regression_df.to_string(index=False))\n",
    "    \n",
    "    # ===== å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®— =====\n",
    "    print(f\"\\nã€å¹³å‡ã‚¹ã‚³ã‚¢ã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # TOP1å¹³å‡F1\n",
    "    top1_f1_scores = []\n",
    "    for tasks in top_rank_results.values():\n",
    "        if 'top1' in tasks:\n",
    "            f1 = tasks['top1']['metrics'].get('f1', np.nan)\n",
    "            if not np.isnan(f1):\n",
    "                top1_f1_scores.append(f1)\n",
    "    \n",
    "    # TOP2å¹³å‡F1\n",
    "    top2_f1_scores = []\n",
    "    for tasks in top_rank_results.values():\n",
    "        if 'top2' in tasks:\n",
    "            f1 = tasks['top2']['metrics'].get('f1', np.nan)\n",
    "            if not np.isnan(f1):\n",
    "                top2_f1_scores.append(f1)\n",
    "    \n",
    "    # BASELINEå¹³å‡MAE\n",
    "    baseline_mae_scores = []\n",
    "    for tasks in top_rank_results.values():\n",
    "        if 'rank_baseline' in tasks:\n",
    "            mae = tasks['rank_baseline']['metrics'].get('mae', np.nan)\n",
    "            if not np.isnan(mae):\n",
    "                baseline_mae_scores.append(mae)\n",
    "    \n",
    "    # TOP3å¹³å‡MAE\n",
    "    top3_mae_scores = []\n",
    "    for tasks in top_rank_results.values():\n",
    "        if 'rank_top3' in tasks:\n",
    "            mae = tasks['rank_top3']['metrics'].get('mae', np.nan)\n",
    "            if not np.isnan(mae):\n",
    "                top3_mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"\\nTOP1 F1ã‚¹ã‚³ã‚¢:\")\n",
    "    print(f\"  å¹³å‡: {np.mean(top1_f1_scores):.4f}\")\n",
    "    print(f\"  æ¨™æº–åå·®: {np.std(top1_f1_scores):.4f}\")\n",
    "    print(f\"  æœ€å°: {np.min(top1_f1_scores):.4f}\")\n",
    "    print(f\"  æœ€å¤§: {np.max(top1_f1_scores):.4f}\")\n",
    "    \n",
    "    print(f\"\\nTOP2 F1ã‚¹ã‚³ã‚¢:\")\n",
    "    print(f\"  å¹³å‡: {np.mean(top2_f1_scores):.4f}\")\n",
    "    print(f\"  æ¨™æº–åå·®: {np.std(top2_f1_scores):.4f}\")\n",
    "    print(f\"  æœ€å°: {np.min(top2_f1_scores):.4f}\")\n",
    "    print(f\"  æœ€å¤§: {np.max(top2_f1_scores):.4f}\")\n",
    "    \n",
    "    print(f\"\\nãƒ©ãƒ³ã‚¯å­¦ç¿’ BASELINE MAE:\")\n",
    "    print(f\"  å¹³å‡: {np.mean(baseline_mae_scores):.4f}\")\n",
    "    print(f\"  æ¨™æº–åå·®: {np.std(baseline_mae_scores):.4f}\")\n",
    "    print(f\"  æœ€å°: {np.min(baseline_mae_scores):.4f}\")\n",
    "    print(f\"  æœ€å¤§: {np.max(baseline_mae_scores):.4f}\")\n",
    "    \n",
    "    if len(top3_mae_scores) > 0:\n",
    "        print(f\"\\nãƒ©ãƒ³ã‚¯å­¦ç¿’ TOP3ç‰¹åŒ– MAE:\")\n",
    "        print(f\"  å¹³å‡: {np.mean(top3_mae_scores):.4f}\")\n",
    "        print(f\"  æ¨™æº–åå·®: {np.std(top3_mae_scores):.4f}\")\n",
    "        print(f\"  æœ€å°: {np.min(top3_mae_scores):.4f}\")\n",
    "        print(f\"  æœ€å¤§: {np.max(top3_mae_scores):.4f}\")\n",
    "        \n",
    "        # æ”¹å–„ç‡\n",
    "        improvement = ((np.mean(baseline_mae_scores) - np.mean(top3_mae_scores)) / \n",
    "                      np.mean(baseline_mae_scores) * 100)\n",
    "        print(f\"  TOP3ã«ã‚ˆã‚‹æ”¹å–„ç‡: {improvement:.2f}%\")\n",
    "    \n",
    "    # ===== ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¿å­˜ =====\n",
    "    print(f\"\\nã€çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    globals()['classification_df'] = classification_df\n",
    "    globals()['regression_df'] = regression_df\n",
    "    \n",
    "    print(f\"  âœ… classification_df: {len(classification_df)} Ã— {len(classification_df.columns)}\")\n",
    "    print(f\"  âœ… regression_df: {len(regression_df)} Ã— {len(regression_df.columns)}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ… åŸºæœ¬çµ±è¨ˆå®Œäº†\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«22: ç‰¹å¾´é‡åˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ã‚»ãƒ«22: ç‰¹å¾´é‡åˆ†æ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'top_rank_results' not in globals():\n",
    "    print(\"âŒ top_rank_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    top_rank_results = globals()['top_rank_results']\n",
    "    \n",
    "    print(f\"\\nã€ç‰¹å¾´é‡åˆ†æã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # ===== ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ†é¡ =====\n",
    "    feature_type_patterns = {\n",
    "        'prev_*': r'^prev_\\d+_',\n",
    "        'allday_lag*': r'^allday_lag\\d+_',\n",
    "        'allday_ma*': r'^allday_ma\\d+_',\n",
    "        'allday_std*': r'^allday_std\\d+_',\n",
    "        'allday_max*': r'^allday_max_',\n",
    "        'allday_min*': r'^allday_min_',\n",
    "        'distance_*': r'^distance_',\n",
    "        'rank_change*': r'^(rank_change|rank_improved)',\n",
    "        'is_*': r'^is_',\n",
    "        'ãã®ä»–': r'^.*'\n",
    "    }\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    def classify_feature_type(feat_name):\n",
    "        \"\"\"ç‰¹å¾´é‡åã‹ã‚‰ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡\"\"\"\n",
    "        for ftype, pattern in feature_type_patterns.items():\n",
    "            if re.match(pattern, feat_name):\n",
    "                return ftype\n",
    "        return 'ãã®ä»–'\n",
    "    \n",
    "    # ===---- TOP1ç‰¹å¾´é‡åˆ†æ =====\n",
    "    print(f\"\\nã€TOP1é¸æŠç‰¹å¾´é‡åˆ†æã€‘\")\n",
    "    \n",
    "    top1_features = []\n",
    "    for event, tasks in top_rank_results.items():\n",
    "        if 'top1' in tasks:\n",
    "            features = tasks['top1']['selected_features']\n",
    "            top1_features.extend(features)\n",
    "    \n",
    "    if top1_features:\n",
    "        top1_feature_counts = {}\n",
    "        top1_feature_types = {}\n",
    "        \n",
    "        for feat in top1_features:\n",
    "            top1_feature_counts[feat] = top1_feature_counts.get(feat, 0) + 1\n",
    "            ftype = classify_feature_type(feat)\n",
    "            top1_feature_types[ftype] = top1_feature_types.get(ftype, 0) + 1\n",
    "        \n",
    "        # TOP1ã§æœ€ã‚‚é »ç¹ã«é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡\n",
    "        top1_sorted = sorted(top1_feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\nTOP1ã§æœ€ã‚‚å¤šãé¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ï¼ˆTOP10ï¼‰:\")\n",
    "        for rank, (feat, count) in enumerate(top1_sorted[:10], 1):\n",
    "            pct = count / len(top_rank_results) * 100\n",
    "            ftype = classify_feature_type(feat)\n",
    "            print(f\"  {rank:2d}. {feat:40s} | ä½¿ç”¨: {count}/{len(top_rank_results)} ({pct:5.1f}%) | ã‚¿ã‚¤ãƒ—: {ftype}\")\n",
    "        \n",
    "        print(f\"\\nTOP1ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ:\")\n",
    "        for ftype, count in sorted(top1_feature_types.items(), key=lambda x: x[1], reverse=True):\n",
    "            total_top1 = len(set(top1_features))\n",
    "            pct = count / total_top1 * 100 if total_top1 > 0 else 0\n",
    "            print(f\"  {ftype:15s}: {count:3d}å€‹ ({pct:5.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nç·ãƒ¦ãƒ‹ãƒ¼ã‚¯ç‰¹å¾´é‡æ•°: {len(set(top1_features))}\")\n",
    "    \n",
    "    # ===---- TOP2ç‰¹å¾´é‡åˆ†æ =====\n",
    "    print(f\"\\nã€TOP2é¸æŠç‰¹å¾´é‡åˆ†æã€‘\")\n",
    "    \n",
    "    top2_features = []\n",
    "    for event, tasks in top_rank_results.items():\n",
    "        if 'top2' in tasks:\n",
    "            features = tasks['top2']['selected_features']\n",
    "            top2_features.extend(features)\n",
    "    \n",
    "    if top2_features:\n",
    "        top2_feature_counts = {}\n",
    "        top2_feature_types = {}\n",
    "        \n",
    "        for feat in top2_features:\n",
    "            top2_feature_counts[feat] = top2_feature_counts.get(feat, 0) + 1\n",
    "            ftype = classify_feature_type(feat)\n",
    "            top2_feature_types[ftype] = top2_feature_types.get(ftype, 0) + 1\n",
    "        \n",
    "        # TOP2ã§æœ€ã‚‚é »ç¹ã«é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡\n",
    "        top2_sorted = sorted(top2_feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\nTOP2ã§æœ€ã‚‚å¤šãé¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ï¼ˆTOP10ï¼‰:\")\n",
    "        for rank, (feat, count) in enumerate(top2_sorted[:10], 1):\n",
    "            pct = count / len(top_rank_results) * 100\n",
    "            ftype = classify_feature_type(feat)\n",
    "            print(f\"  {rank:2d}. {feat:40s} | ä½¿ç”¨: {count}/{len(top_rank_results)} ({pct:5.1f}%) | ã‚¿ã‚¤ãƒ—: {ftype}\")\n",
    "        \n",
    "        print(f\"\\nTOP2ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ:\")\n",
    "        for ftype, count in sorted(top2_feature_types.items(), key=lambda x: x[1], reverse=True):\n",
    "            total_top2 = len(set(top2_features))\n",
    "            pct = count / total_top2 * 100 if total_top2 > 0 else 0\n",
    "            print(f\"  {ftype:15s}: {count:3d}å€‹ ({pct:5.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nç·ãƒ¦ãƒ‹ãƒ¼ã‚¯ç‰¹å¾´é‡æ•°: {len(set(top2_features))}\")\n",
    "    \n",
    "    # ===---- ãƒ©ãƒ³ã‚¯å­¦ç¿’ç‰¹å¾´é‡åˆ†æ =====\n",
    "    print(f\"\\nã€ãƒ©ãƒ³ã‚¯å­¦ç¿’é¸æŠç‰¹å¾´é‡åˆ†æã€‘\")\n",
    "    \n",
    "    rank_features = []\n",
    "    for event, tasks in top_rank_results.items():\n",
    "        if 'rank_baseline' in tasks:\n",
    "            features = tasks['rank_baseline']['selected_features']\n",
    "            rank_features.extend(features)\n",
    "    \n",
    "    if rank_features:\n",
    "        rank_feature_counts = {}\n",
    "        rank_feature_types = {}\n",
    "        \n",
    "        for feat in rank_features:\n",
    "            rank_feature_counts[feat] = rank_feature_counts.get(feat, 0) + 1\n",
    "            ftype = classify_feature_type(feat)\n",
    "            rank_feature_types[ftype] = rank_feature_types.get(ftype, 0) + 1\n",
    "        \n",
    "        # ãƒ©ãƒ³ã‚¯å­¦ç¿’ã§æœ€ã‚‚é »ç¹ã«é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡\n",
    "        rank_sorted = sorted(rank_feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\nãƒ©ãƒ³ã‚¯å­¦ç¿’ã§æœ€ã‚‚å¤šãé¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ï¼ˆTOP10ï¼‰:\")\n",
    "        for rank, (feat, count) in enumerate(rank_sorted[:10], 1):\n",
    "            pct = count / len(top_rank_results) * 100\n",
    "            ftype = classify_feature_type(feat)\n",
    "            print(f\"  {rank:2d}. {feat:40s} | ä½¿ç”¨: {count}/{len(top_rank_results)} ({pct:5.1f}%) | ã‚¿ã‚¤ãƒ—: {ftype}\")\n",
    "        \n",
    "        print(f\"\\nãƒ©ãƒ³ã‚¯å­¦ç¿’ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ:\")\n",
    "        for ftype, count in sorted(rank_feature_types.items(), key=lambda x: x[1], reverse=True):\n",
    "            total_rank = len(set(rank_features))\n",
    "            pct = count / total_rank * 100 if total_rank > 0 else 0\n",
    "            print(f\"  {ftype:15s}: {count:3d}å€‹ ({pct:5.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nç·ãƒ¦ãƒ‹ãƒ¼ã‚¯ç‰¹å¾´é‡æ•°: {len(set(rank_features))}\")\n",
    "    \n",
    "    # ===---- å…±é€šç‰¹å¾´é‡åˆ†æ =====\n",
    "    print(f\"\\nã€å…±é€šç‰¹å¾´é‡åˆ†æã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if top1_features and top2_features:\n",
    "        common_top1_top2 = set(top1_features) & set(top2_features)\n",
    "        print(f\"\\nTOP1 ã¨ TOP2 ã®å…±é€šç‰¹å¾´é‡:\")\n",
    "        print(f\"  å…±é€šç‰¹å¾´é‡æ•°: {len(common_top1_top2)} / {len(set(top1_features))} (TOP1)\")\n",
    "        print(f\"              {len(common_top1_top2)} / {len(set(top2_features))} (TOP2)\")\n",
    "        \n",
    "        if len(common_top1_top2) > 0 and len(common_top1_top2) <= 10:\n",
    "            for feat in sorted(common_top1_top2):\n",
    "                print(f\"    - {feat}\")\n",
    "    \n",
    "    if top1_features and rank_features:\n",
    "        common_top1_rank = set(top1_features) & set(rank_features)\n",
    "        print(f\"\\nTOP1 ã¨ ãƒ©ãƒ³ã‚¯å­¦ç¿’ ã®å…±é€šç‰¹å¾´é‡:\")\n",
    "        print(f\"  å…±é€šç‰¹å¾´é‡æ•°: {len(common_top1_rank)} / {len(set(top1_features))} (TOP1)\")\n",
    "        print(f\"              {len(common_top1_rank)} / {len(set(rank_features))} (ãƒ©ãƒ³ã‚¯)\")\n",
    "    \n",
    "    if top2_features and rank_features:\n",
    "        common_top2_rank = set(top2_features) & set(rank_features)\n",
    "        print(f\"\\nTOP2 ã¨ ãƒ©ãƒ³ã‚¯å­¦ç¿’ ã®å…±é€šç‰¹å¾´é‡:\")\n",
    "        print(f\"  å…±é€šç‰¹å¾´é‡æ•°: {len(common_top2_rank)} / {len(set(top2_features))} (TOP2)\")\n",
    "        print(f\"              {len(common_top2_rank)} / {len(set(rank_features))} (ãƒ©ãƒ³ã‚¯)\")\n",
    "    \n",
    "    # ===---- ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¿å­˜ =====\n",
    "    print(f\"\\nã€åˆ†æçµæœä¿å­˜ã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    feature_analysis = {\n",
    "        'top1_features': set(top1_features),\n",
    "        'top2_features': set(top2_features),\n",
    "        'rank_features': set(rank_features),\n",
    "        'top1_feature_types': top1_feature_types if top1_features else {},\n",
    "        'top2_feature_types': top2_feature_types if top2_features else {},\n",
    "        'rank_feature_types': rank_feature_types if rank_features else {},\n",
    "    }\n",
    "    \n",
    "    globals()['feature_analysis'] = feature_analysis\n",
    "    \n",
    "    print(f\"  âœ… feature_analysis ä¿å­˜å®Œäº†\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ… ç‰¹å¾´é‡åˆ†æå®Œäº†\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«23: ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ã‚»ãƒ«23: ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'top_rank_results' not in globals():\n",
    "    print(\"âŒ top_rank_results ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "else:\n",
    "    top_rank_results = globals()['top_rank_results']\n",
    "    \n",
    "    print(f\"\\nã€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒåˆ†æã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # ===== STEP 1: ã‚¿ã‚¹ã‚¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ =====\n",
    "    print(f\"\\n STEP 1: ã‚¿ã‚¹ã‚¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for event in sorted(top_rank_results.keys()):\n",
    "        tasks = top_rank_results[event]\n",
    "        \n",
    "        row = {'Event': event.upper()}\n",
    "        \n",
    "        # TOP1\n",
    "        if 'top1' in tasks:\n",
    "            row.update({\n",
    "                'TOP1_Model': tasks['top1']['model_name'],\n",
    "                'TOP1_F1': tasks['top1']['metrics'].get('f1', 0),\n",
    "                'TOP1_Acc': tasks['top1']['metrics'].get('accuracy', 0),\n",
    "            })\n",
    "        else:\n",
    "            row.update({'TOP1_Model': 'N/A', 'TOP1_F1': 0, 'TOP1_Acc': 0})\n",
    "        \n",
    "        # TOP2\n",
    "        if 'top2' in tasks:\n",
    "            row.update({\n",
    "                'TOP2_Model': tasks['top2']['model_name'],\n",
    "                'TOP2_F1': tasks['top2']['metrics'].get('f1', 0),\n",
    "                'TOP2_Acc': tasks['top2']['metrics'].get('accuracy', 0),\n",
    "            })\n",
    "        else:\n",
    "            row.update({'TOP2_Model': 'N/A', 'TOP2_F1': 0, 'TOP2_Acc': 0})\n",
    "        \n",
    "        # RANK\n",
    "        if 'rank_baseline' in tasks:\n",
    "            row.update({\n",
    "                'Rank_Model': tasks['rank_baseline']['model_name'],\n",
    "                'Rank_MAE': tasks['rank_baseline']['metrics'].get('mae', 0),\n",
    "                'Rank_Spearman': tasks['rank_baseline']['metrics'].get('spearman_corr', 0),\n",
    "            })\n",
    "        else:\n",
    "            row.update({'Rank_Model': 'N/A', 'Rank_MAE': 0, 'Rank_Spearman': 0})\n",
    "        \n",
    "        comparison_data.append(row)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(f\"\\nã‚¿ã‚¹ã‚¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # ===---- STEP 2: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥æ€§èƒ½åˆ†æ =====\n",
    "    print(f\"\\n STEP 2: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥æ€§èƒ½åˆ†æ\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    model_performance = {}\n",
    "    \n",
    "    # TOP1ãƒ¢ãƒ‡ãƒ«æ€§èƒ½\n",
    "    print(f\"\\nã€TOP1: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥æ€§èƒ½ã€‘\")\n",
    "    \n",
    "    top1_model_scores = {}\n",
    "    for event, tasks in top_rank_results.items():\n",
    "        if 'top1' in tasks:\n",
    "            model = tasks['top1']['model_name']\n",
    "            f1 = tasks['top1']['metrics'].get('f1', 0)\n",
    "            \n",
    "            if model not in top1_model_scores:\n",
    "                top1_model_scores[model] = []\n",
    "            top1_model_scores[model].append(f1)\n",
    "    \n",
    "    for model in sorted(top1_model_scores.keys()):\n",
    "        scores = top1_model_scores[model]\n",
    "        print(f\"\\n  {model}:\")\n",
    "        print(f\"    ä½¿ç”¨ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(scores)}\")\n",
    "        print(f\"    å¹³å‡F1: {np.mean(scores):.4f}\")\n",
    "        print(f\"    æœ€å°F1: {np.min(scores):.4f}\")\n",
    "        print(f\"    æœ€å¤§F1: {np.max(scores):.4f}\")\n",
    "        print(f\"    æ¨™æº–åå·®: {np.std(scores):.4f}\")\n",
    "        \n",
    "        model_performance[f'TOP1_{model}'] = {\n",
    "            'count': len(scores),\n",
    "            'mean_f1': np.mean(scores),\n",
    "            'std_f1': np.std(scores)\n",
    "        }\n",
    "    \n",
    "    # TOP2ãƒ¢ãƒ‡ãƒ«æ€§èƒ½\n",
    "    print(f\"\\nã€TOP2: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥æ€§èƒ½ã€‘\")\n",
    "    \n",
    "    top2_model_scores = {}\n",
    "    for event, tasks in top_rank_results.items():\n",
    "        if 'top2' in tasks:\n",
    "            model = tasks['top2']['model_name']\n",
    "            f1 = tasks['top2']['metrics'].get('f1', 0)\n",
    "            \n",
    "            if model not in top2_model_scores:\n",
    "                top2_model_scores[model] = []\n",
    "            top2_model_scores[model].append(f1)\n",
    "    \n",
    "    for model in sorted(top2_model_scores.keys()):\n",
    "        scores = top2_model_scores[model]\n",
    "        print(f\"\\n  {model}:\")\n",
    "        print(f\"    ä½¿ç”¨ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(scores)}\")\n",
    "        print(f\"    å¹³å‡F1: {np.mean(scores):.4f}\")\n",
    "        print(f\"    æœ€å°F1: {np.min(scores):.4f}\")\n",
    "        print(f\"    æœ€å¤§F1: {np.max(scores):.4f}\")\n",
    "        print(f\"    æ¨™æº–åå·®: {np.std(scores):.4f}\")\n",
    "        \n",
    "        model_performance[f'TOP2_{model}'] = {\n",
    "            'count': len(scores),\n",
    "            'mean_f1': np.mean(scores),\n",
    "            'std_f1': np.std(scores)\n",
    "        }\n",
    "    \n",
    "    # ãƒ©ãƒ³ã‚¯å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ€§èƒ½\n",
    "    print(f\"\\nã€ãƒ©ãƒ³ã‚¯å­¦ç¿’: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥æ€§èƒ½ã€‘\")\n",
    "    \n",
    "    rank_model_scores = {}\n",
    "    for event, tasks in top_rank_results.items():\n",
    "        if 'rank_baseline' in tasks:\n",
    "            model = tasks['rank_baseline']['model_name']\n",
    "            mae = tasks['rank_baseline']['metrics'].get('mae', 0)\n",
    "            \n",
    "            if model not in rank_model_scores:\n",
    "                rank_model_scores[model] = []\n",
    "            rank_model_scores[model].append(mae)\n",
    "    \n",
    "    for model in sorted(rank_model_scores.keys()):\n",
    "        scores = rank_model_scores[model]\n",
    "        print(f\"\\n  {model}:\")\n",
    "        print(f\"    ä½¿ç”¨ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(scores)}\")\n",
    "        print(f\"    å¹³å‡MAE: {np.mean(scores):.4f}\")\n",
    "        print(f\"    æœ€å°MAE: {np.min(scores):.4f}\")\n",
    "        print(f\"    æœ€å¤§MAE: {np.max(scores):.4f}\")\n",
    "        print(f\"    æ¨™æº–åå·®: {np.std(scores):.4f}\")\n",
    "        \n",
    "        model_performance[f'Rank_{model}'] = {\n",
    "            'count': len(scores),\n",
    "            'mean_mae': np.mean(scores),\n",
    "            'std_mae': np.std(scores)\n",
    "        }\n",
    "    \n",
    "    # ===---- STEP 3: TOP1 vs TOP2 æ¯”è¼ƒ =====\n",
    "    print(f\"\\n STEP 3: TOP1 vs TOP2 æ¯”è¼ƒ\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    top1_f1_list = []\n",
    "    top2_f1_list = []\n",
    "    \n",
    "    for event in sorted(top_rank_results.keys()):\n",
    "        tasks = top_rank_results[event]\n",
    "        \n",
    "        if 'top1' in tasks:\n",
    "            top1_f1_list.append(tasks['top1']['metrics'].get('f1', 0))\n",
    "        \n",
    "        if 'top2' in tasks:\n",
    "            top2_f1_list.append(tasks['top2']['metrics'].get('f1', 0))\n",
    "    \n",
    "    print(f\"\\nTOP1 vs TOP2 F1ã‚¹ã‚³ã‚¢æ¯”è¼ƒ:\")\n",
    "    print(f\"  TOP1 å¹³å‡F1: {np.mean(top1_f1_list):.4f}\")\n",
    "    print(f\"  TOP2 å¹³å‡F1: {np.mean(top2_f1_list):.4f}\")\n",
    "    print(f\"  å·®åˆ†: {np.mean(top1_f1_list) - np.mean(top2_f1_list):+.4f}\")\n",
    "    \n",
    "    # ã©ã¡ã‚‰ãŒé«˜ã„ã‹\n",
    "    if np.mean(top1_f1_list) > np.mean(top2_f1_list):\n",
    "        diff_pct = ((np.mean(top1_f1_list) - np.mean(top2_f1_list)) / np.mean(top2_f1_list) * 100)\n",
    "        print(f\"  â†’ TOP1ãŒ{diff_pct:.1f}% é«˜ã„\")\n",
    "    else:\n",
    "        diff_pct = ((np.mean(top2_f1_list) - np.mean(top1_f1_list)) / np.mean(top1_f1_list) * 100)\n",
    "        print(f\"  â†’ TOP2ãŒ{diff_pct:.1f}% é«˜ã„\")\n",
    "    \n",
    "    # ===---- STEP 4: BASELINE vs TOP3 æ¯”è¼ƒ =====\n",
    "    print(f\"\\n STEP 4: BASELINE vs TOP3ç‰¹åŒ– æ¯”è¼ƒ\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    baseline_mae_list = []\n",
    "    top3_mae_list = []\n",
    "    \n",
    "    for event in sorted(top_rank_results.keys()):\n",
    "        tasks = top_rank_results[event]\n",
    "        \n",
    "        if 'rank_baseline' in tasks:\n",
    "            baseline_mae_list.append(tasks['rank_baseline']['metrics'].get('mae', 0))\n",
    "        \n",
    "        if 'rank_top3' in tasks:\n",
    "            top3_mae_list.append(tasks['rank_top3']['metrics'].get('mae', 0))\n",
    "    \n",
    "    if len(baseline_mae_list) > 0:\n",
    "        print(f\"\\nBASELINE vs TOP3ç‰¹åŒ– MAEæ¯”è¼ƒ:\")\n",
    "        print(f\"  BASELINE å¹³å‡MAE: {np.mean(baseline_mae_list):.4f}\")\n",
    "        \n",
    "        if len(top3_mae_list) > 0:\n",
    "            print(f\"  TOP3ç‰¹åŒ– å¹³å‡MAE: {np.mean(top3_mae_list):.4f}\")\n",
    "            print(f\"  å·®åˆ†: {np.mean(baseline_mae_list) - np.mean(top3_mae_list):+.4f}\")\n",
    "            \n",
    "            improvement = ((np.mean(baseline_mae_list) - np.mean(top3_mae_list)) / \n",
    "                          np.mean(baseline_mae_list) * 100)\n",
    "            \n",
    "            if improvement > 0:\n",
    "                print(f\"  â†’ TOP3ç‰¹åŒ–ã§{improvement:.1f}% æ”¹å–„\")\n",
    "            elif improvement < 0:\n",
    "                print(f\"  â†’ BASELINEãŒ{abs(improvement):.1f}% å„ªã‚Œã¦ã„ã‚‹\")\n",
    "            else:\n",
    "                print(f\"  â†’ åŒç­‰\")\n",
    "        else:\n",
    "            print(f\"  TOP3ç‰¹åŒ–çµæœãªã—\")\n",
    "    \n",
    "    # ===---- STEP 5: ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒ =====\n",
    "    print(f\"\\n STEP 5: ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒ\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã®ã‚¹ã‚³ã‚¢ã°ã‚‰ã¤ã\n",
    "    event_scores = []\n",
    "    for event in sorted(top_rank_results.keys()):\n",
    "        tasks = top_rank_results[event]\n",
    "        \n",
    "        scores = []\n",
    "        if 'top1' in tasks:\n",
    "            scores.append(tasks['top1']['metrics'].get('f1', 0))\n",
    "        if 'top2' in tasks:\n",
    "            scores.append(tasks['top2']['metrics'].get('f1', 0))\n",
    "        \n",
    "        if scores:\n",
    "            event_scores.append({\n",
    "                'Event': event.upper(),\n",
    "                'Avg_Score': np.mean(scores),\n",
    "                'Min_Score': np.min(scores),\n",
    "                'Max_Score': np.max(scores),\n",
    "            })\n",
    "    \n",
    "    if event_scores:\n",
    "        event_scores_df = pd.DataFrame(event_scores)\n",
    "        print(f\"\\nã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:\")\n",
    "        print(event_scores_df.to_string(index=False))\n",
    "    \n",
    "    # ===---- ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¿å­˜ =====\n",
    "    print(f\"\\nã€æ¯”è¼ƒçµæœä¿å­˜ã€‘\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    globals()['comparison_df'] = comparison_df\n",
    "    globals()['model_performance'] = model_performance\n",
    "    \n",
    "    print(f\"  âœ… comparison_df: {len(comparison_df)} ã‚¤ãƒ™ãƒ³ãƒˆ\")\n",
    "    print(f\"  âœ… model_performance: {len(model_performance)} ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ… ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Œäº†\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«24: çµ±ä¸€çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ + å…±é€šè©•ä¾¡é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# ============================================================\n",
    "# (1) UnifiedModelResult: çµ±ä¸€çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class UnifiedModelResult:\n",
    "    \"\"\"çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®äºˆæ¸¬çµæœã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    event_name: str                    # ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "    task_name: str                     # 'top1', 'top2', 'rank_baseline', 'rank_top3'\n",
    "    task_type: str                     # 'binary' or 'regression'\n",
    "    \n",
    "    model: Any                         # è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«\n",
    "    model_name: str                    # 'Ridge', 'RF', 'XGB', 'LGBM'\n",
    "    selected_features: List[str]       # é¸æŠç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n",
    "    scaler: Optional[Any] = None       # StandardScalerï¼ˆã‚ã‚Œã°ï¼‰\n",
    "    \n",
    "    y_train: np.ndarray = None\n",
    "    y_test: np.ndarray = None\n",
    "    y_pred: np.ndarray = None\n",
    "    \n",
    "    metrics: Dict[str, float] = field(default_factory=dict)\n",
    "    training_time: float = 0.0\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"metricsè¾æ›¸åˆæœŸåŒ–\"\"\"\n",
    "        if not self.metrics:\n",
    "            self.metrics = {}\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"çµæœã‚’è¾æ›¸å½¢å¼ã§å–å¾—\"\"\"\n",
    "        return {\n",
    "            'event_name': self.event_name,\n",
    "            'task_name': self.task_name,\n",
    "            'model_name': self.model_name,\n",
    "            'n_features': len(self.selected_features),\n",
    "            'metrics': self.metrics.copy(),\n",
    "            'training_time': self.training_time\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# (2) å…±é€šè©•ä¾¡é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def compute_binary_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    äºŒå€¤åˆ†é¡ç”¨è©•ä¾¡æŒ‡æ¨™è¨ˆç®—\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤ï¼ˆ0 or 1ï¼‰\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        f1, precision, recall, accuracy, spearman_corr\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        metrics['f1'] = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        metrics['precision'] = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        metrics['recall'] = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        # Spearmanç›¸é–¢\n",
    "        if len(np.unique(y_true)) > 1:\n",
    "            corr, _ = spearmanr(y_true, y_pred)\n",
    "            metrics['spearman_corr'] = corr\n",
    "        else:\n",
    "            metrics['spearman_corr'] = 0.0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ äºŒå€¤åˆ†é¡è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        metrics = {k: 0.0 for k in ['f1', 'precision', 'recall', 'accuracy', 'spearman_corr']}\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def compute_regression_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    å›å¸°ç”¨è©•ä¾¡æŒ‡æ¨™è¨ˆç®—\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤ï¼ˆé€£ç¶šå€¤ï¼‰\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        mae, rmse, spearman_corr\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        metrics['mae'] = mean_absolute_error(y_true, y_pred)\n",
    "        metrics['rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        \n",
    "        # Spearmanç›¸é–¢\n",
    "        if len(np.unique(y_true)) > 1:\n",
    "            corr, _ = spearmanr(y_true, y_pred)\n",
    "            metrics['spearman_corr'] = corr\n",
    "        else:\n",
    "            metrics['spearman_corr'] = 0.0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ å›å¸°è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        metrics = {k: 0.0 for k in ['mae', 'rmse', 'spearman_corr']}\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def compute_top3_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    TOP3ç‰¹åŒ–ç”¨è©•ä¾¡æŒ‡æ¨™è¨ˆç®—\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        çœŸå€¤ï¼ˆ0-9ã®ãƒ©ãƒ³ã‚¯ï¼‰\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤ï¼ˆ0-9ã®ãƒ©ãƒ³ã‚¯ï¼‰\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        top3_hit_rate, top3_miss_rate, spearman_top3\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        # TOP3ã«å«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆçœŸå€¤ã®TOP3ï¼‰\n",
    "        top3_mask = y_true < 3\n",
    "        top3_count = top3_mask.sum()\n",
    "        \n",
    "        if top3_count > 0:\n",
    "            top3_correct = ((y_pred[top3_mask] < 3).sum())\n",
    "            metrics['top3_hit_rate'] = top3_correct / top3_count\n",
    "            metrics['top3_miss_rate'] = 1.0 - metrics['top3_hit_rate']\n",
    "        else:\n",
    "            metrics['top3_hit_rate'] = 0.0\n",
    "            metrics['top3_miss_rate'] = 0.0\n",
    "        \n",
    "        # Spearmanç›¸é–¢ï¼ˆTOP3ä¸­å¿ƒã®é‡ã¿ä»˜ã‘ï¼‰\n",
    "        if len(np.unique(y_true)) > 1:\n",
    "            corr, _ = spearmanr(y_true, y_pred)\n",
    "            metrics['spearman_top3'] = corr\n",
    "        else:\n",
    "            metrics['spearman_top3'] = 0.0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ TOP3è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        metrics = {k: 0.0 for k in ['top3_hit_rate', 'top3_miss_rate', 'spearman_top3']}\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def compute_profit_metrics(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    base_payout: float = 100.0\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    åˆ©ç›Šé–¢é€£è©•ä¾¡æŒ‡æ¨™è¨ˆç®—ï¼ˆå…±é€šåˆ©ç”¨ï¼‰\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : np.ndarray\n",
    "        çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤\n",
    "    base_payout : float\n",
    "        åŸºæœ¬çš„ä¸­æ™‚é…å½“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100å††ï¼‰\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        avg_predicted_profit, avg_correct_profit, profit_loss_rate\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        # äºˆæ¸¬ãŒæ­£è§£æ™‚ã®é…å½“\n",
    "        correct_mask = (y_true == y_pred)\n",
    "        \n",
    "        if correct_mask.sum() > 0:\n",
    "            metrics['avg_correct_profit'] = base_payout\n",
    "            metrics['avg_predicted_profit'] = base_payout * (correct_mask.sum() / len(y_true))\n",
    "        else:\n",
    "            metrics['avg_correct_profit'] = 0.0\n",
    "            metrics['avg_predicted_profit'] = 0.0\n",
    "        \n",
    "        metrics['profit_loss_rate'] = (correct_mask.sum() / len(y_true)) * 100.0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ åˆ©ç›Šè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        metrics = {k: 0.0 for k in ['avg_correct_profit', 'avg_predicted_profit', 'profit_loss_rate']}\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ============================================================\n",
    "# (3) çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def convert_to_unified_result(\n",
    "    event_name: str,\n",
    "    task_name: str,\n",
    "    model: Any,\n",
    "    model_name: str,\n",
    "    selected_features: List[str],\n",
    "    y_test: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    task_type: str = 'binary',\n",
    "    scaler: Optional[Any] = None,\n",
    "    training_time: float = 0.0,\n",
    "    y_train: Optional[np.ndarray] = None\n",
    ") -> UnifiedModelResult:\n",
    "    \"\"\"\n",
    "    å¾“æ¥ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ã®å¤‰æ›\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    event_name : str\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "    task_name : str\n",
    "        'top1', 'top2', 'rank_baseline', 'rank_top3'\n",
    "    model : Any\n",
    "        è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«\n",
    "    model_name : str\n",
    "        'Ridge', 'RF', 'XGB', 'LGBM'\n",
    "    selected_features : List[str]\n",
    "        é¸æŠç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n",
    "    y_test : np.ndarray\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬å€¤\n",
    "    task_type : str\n",
    "        'binary' or 'regression'\n",
    "    scaler : Optional[Any]\n",
    "        StandardScalerï¼ˆã‚ã‚Œã°ï¼‰\n",
    "    training_time : float\n",
    "        è¨“ç·´æ™‚é–“\n",
    "    y_train : Optional[np.ndarray]\n",
    "        è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çœŸå€¤\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    UnifiedModelResult\n",
    "        çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    \"\"\"\n",
    "    result = UnifiedModelResult(\n",
    "        event_name=event_name,\n",
    "        task_name=task_name,\n",
    "        task_type=task_type,\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        selected_features=selected_features,\n",
    "        scaler=scaler,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        y_pred=y_pred,\n",
    "        training_time=training_time\n",
    "    )\n",
    "    \n",
    "    # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—\n",
    "    if task_type == 'binary':\n",
    "        result.metrics.update(compute_binary_metrics(y_test, y_pred))\n",
    "    else:  # regression\n",
    "        result.metrics.update(compute_regression_metrics(y_test, y_pred))\n",
    "        \n",
    "        # TOP3é–¢é€£æŒ‡æ¨™ã‚‚è¿½åŠ \n",
    "        if 'rank' in task_name.lower():\n",
    "            result.metrics.update(compute_top3_metrics(y_test, y_pred))\n",
    "    \n",
    "    # åˆ©ç›ŠæŒ‡æ¨™ã‚‚å…±é€šã§è¿½åŠ \n",
    "    result.metrics.update(compute_profit_metrics(y_test, y_pred))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ============================================================\n",
    "# (4) çµæœç®¡ç†ã‚¯ãƒ©ã‚¹\n",
    "# ============================================================\n",
    "\n",
    "class ExperimentResults:\n",
    "    \"\"\"å®Ÿé¨“çµæœã®çµ±åˆç®¡ç†ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results: Dict[str, Dict[str, UnifiedModelResult]] = {}\n",
    "        # {ã‚¤ãƒ™ãƒ³ãƒˆ: {ã‚¿ã‚¹ã‚¯: çµæœ}}\n",
    "    \n",
    "    def add_result(self, result: UnifiedModelResult) -> None:\n",
    "        \"\"\"çµæœã‚’è¿½åŠ \"\"\"\n",
    "        if result.event_name not in self.results:\n",
    "            self.results[result.event_name] = {}\n",
    "        \n",
    "        self.results[result.event_name][result.task_name] = result\n",
    "    \n",
    "    def get_result(self, event_name: str, task_name: str) -> Optional[UnifiedModelResult]:\n",
    "        \"\"\"ç‰¹å®šã®çµæœã‚’å–å¾—\"\"\"\n",
    "        return self.results.get(event_name, {}).get(task_name)\n",
    "    \n",
    "    def get_comparison_table(self) -> pd.DataFrame:\n",
    "        \"\"\"ã™ã¹ã¦ã®çµæœã‚’æ¯”è¼ƒè¡¨ã¨ã—ã¦å–å¾—\"\"\"\n",
    "        rows = []\n",
    "        \n",
    "        for event_name, tasks in self.results.items():\n",
    "            for task_name, result in tasks.items():\n",
    "                row = {\n",
    "                    'ã‚¤ãƒ™ãƒ³ãƒˆ': event_name,\n",
    "                    'ã‚¿ã‚¹ã‚¯': task_name,\n",
    "                    'ãƒ¢ãƒ‡ãƒ«': result.model_name,\n",
    "                    'ç‰¹å¾´é‡æ•°': len(result.selected_features),\n",
    "                    'è¨“ç·´æ™‚é–“': f\"{result.training_time:.2f}ç§’\"\n",
    "                }\n",
    "                row.update(result.metrics)\n",
    "                rows.append(row)\n",
    "        \n",
    "        return pd.DataFrame(rows)\n",
    "    \n",
    "    def get_best_model(self, event_name: str, task_name: str, metric: str = 'f1') -> Optional[UnifiedModelResult]:\n",
    "        \"\"\"æŒ‡å®šãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—\"\"\"\n",
    "        tasks = self.results.get(event_name, {})\n",
    "        \n",
    "        if not tasks:\n",
    "            return None\n",
    "        \n",
    "        best_result = None\n",
    "        best_score = -np.inf\n",
    "        \n",
    "        for result in tasks.values():\n",
    "            if metric in result.metrics:\n",
    "                score = result.metrics[metric]\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_result = result\n",
    "        \n",
    "        return best_result\n",
    "\n",
    "# ============================================================\n",
    "# (5) åˆæœŸåŒ–\n",
    "# ============================================================\n",
    "\n",
    "experiment_results = ExperimentResults()\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«24: çµ±ä¸€çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ + å…±é€šè©•ä¾¡é–¢æ•° å®Ÿè£…å®Œäº†\")\n",
    "print(f\"   UnifiedModelResult ã‚¯ãƒ©ã‚¹å®šç¾©\")\n",
    "print(f\"   å…±é€šè©•ä¾¡é–¢æ•° (binary, regression, top3, profit)\")\n",
    "print(f\"   ExperimentResults ç®¡ç†ã‚¯ãƒ©ã‚¹\")\n",
    "print(f\"   experiment_results ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«25: åˆ©ç›Šåˆ†æï¼ˆæ‹¡å¼µï¼‰\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ============================================================\n",
    "# (1) åˆ©ç›Šåˆ†æã‚¨ãƒ³ã‚¸ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "class ProfitAnalyzer:\n",
    "    \"\"\"åˆ©ç›Šåˆ†æãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self, base_bet: float = 100.0, base_payout: float = 100.0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_bet : float\n",
    "            1å›ã‚ãŸã‚Šã®è³­ã‘é‡‘\n",
    "        base_payout : float\n",
    "            çš„ä¸­æ™‚ã®é…å½“\n",
    "        \"\"\"\n",
    "        self.base_bet = base_bet\n",
    "        self.base_payout = base_payout\n",
    "    \n",
    "    def calculate_session_profit(\n",
    "        self,\n",
    "        y_test: np.ndarray,\n",
    "        y_pred: np.ndarray,\n",
    "        prediction_confidence: Optional[np.ndarray] = None,\n",
    "        confidence_threshold: float = 0.0\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®åˆ©ç›Šã‚’è¨ˆç®—\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_test : np.ndarray\n",
    "            çœŸå€¤\n",
    "        y_pred : np.ndarray\n",
    "            äºˆæ¸¬å€¤\n",
    "        prediction_confidence : Optional[np.ndarray]\n",
    "            ä¿¡é ¼åº¦ï¼ˆ0-1ï¼‰ã€‚ã‚ã‚Œã°ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ç”¨\n",
    "        confidence_threshold : float\n",
    "            ä¿¡é ¼åº¦é–¾å€¤ã€‚ã“ã‚Œä»¥ä¸Šã®ã¿ã‚’è³­ã‘ã‚‹\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, float]\n",
    "            profit, loss, net_profit, win_rate, roi\n",
    "        \"\"\"\n",
    "        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "        if prediction_confidence is not None:\n",
    "            mask = prediction_confidence >= confidence_threshold\n",
    "            y_test_filtered = y_test[mask]\n",
    "            y_pred_filtered = y_pred[mask]\n",
    "            n_bets = mask.sum()\n",
    "        else:\n",
    "            y_test_filtered = y_test\n",
    "            y_pred_filtered = y_pred\n",
    "            n_bets = len(y_test)\n",
    "        \n",
    "        if n_bets == 0:\n",
    "            return {\n",
    "                'profit': 0.0,\n",
    "                'loss': 0.0,\n",
    "                'net_profit': 0.0,\n",
    "                'win_rate': 0.0,\n",
    "                'roi': 0.0,\n",
    "                'n_bets': 0,\n",
    "                'n_wins': 0\n",
    "            }\n",
    "        \n",
    "        # å‹åˆ©åˆ¤å®š\n",
    "        win_mask = (y_test_filtered == y_pred_filtered)\n",
    "        n_wins = win_mask.sum()\n",
    "        n_losses = n_bets - n_wins\n",
    "        \n",
    "        # åˆ©ç›Šè¨ˆç®—\n",
    "        profit = n_wins * self.base_payout\n",
    "        loss = n_losses * self.base_bet\n",
    "        net_profit = profit - loss\n",
    "        win_rate = n_wins / n_bets * 100.0\n",
    "        roi = (net_profit / (n_bets * self.base_bet)) * 100.0 if n_bets > 0 else 0.0\n",
    "        \n",
    "        return {\n",
    "            'profit': profit,\n",
    "            'loss': loss,\n",
    "            'net_profit': net_profit,\n",
    "            'win_rate': win_rate,\n",
    "            'roi': roi,\n",
    "            'n_bets': n_bets,\n",
    "            'n_wins': n_wins\n",
    "        }\n",
    "    \n",
    "    def calculate_cumulative_profit(\n",
    "        self,\n",
    "        y_test: np.ndarray,\n",
    "        y_pred: np.ndarray,\n",
    "        prediction_confidence: Optional[np.ndarray] = None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        ç´¯ç©åˆ©ç›Šã‚’è¨ˆç®—\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_test : np.ndarray\n",
    "            çœŸå€¤\n",
    "        y_pred : np.ndarray\n",
    "            äºˆæ¸¬å€¤\n",
    "        prediction_confidence : Optional[np.ndarray]\n",
    "            ä¿¡é ¼åº¦\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            ç´¯ç©åˆ©ç›Šã®é…åˆ—\n",
    "        \"\"\"\n",
    "        win_mask = (y_test == y_pred)\n",
    "        \n",
    "        cumulative = np.zeros(len(y_test))\n",
    "        current_profit = 0.0\n",
    "        \n",
    "        for i, is_win in enumerate(win_mask):\n",
    "            if is_win:\n",
    "                current_profit += self.base_payout\n",
    "            else:\n",
    "                current_profit -= self.base_bet\n",
    "            cumulative[i] = current_profit\n",
    "        \n",
    "        return cumulative\n",
    "\n",
    "# ============================================================\n",
    "# (2) è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒåˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "def compare_profit_across_models(\n",
    "    models_results: Dict[str, Tuple[np.ndarray, np.ndarray]],\n",
    "    base_bet: float = 100.0,\n",
    "    base_payout: float = 100.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç›Šã‚’æ¯”è¼ƒ\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models_results : Dict[str, Tuple[np.ndarray, np.ndarray]]\n",
    "        {ãƒ¢ãƒ‡ãƒ«å: (y_test, y_pred)}\n",
    "    base_bet : float\n",
    "        è³­ã‘é‡‘\n",
    "    base_payout : float\n",
    "        é…å½“\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        åˆ©ç›Šæ¯”è¼ƒè¡¨\n",
    "    \"\"\"\n",
    "    analyzer = ProfitAnalyzer(base_bet=base_bet, base_payout=base_payout)\n",
    "    \n",
    "    rows = []\n",
    "    for model_name, (y_test, y_pred) in models_results.items():\n",
    "        profit_info = analyzer.calculate_session_profit(y_test, y_pred)\n",
    "        profit_info['ãƒ¢ãƒ‡ãƒ«'] = model_name\n",
    "        rows.append(profit_info)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values('net_profit', ascending=False)\n",
    "    \n",
    "    return df[['ãƒ¢ãƒ‡ãƒ«', 'n_bets', 'n_wins', 'win_rate', 'profit', 'loss', 'net_profit', 'roi']]\n",
    "\n",
    "# ============================================================\n",
    "# (3) ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥åˆ©ç›Šåˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "def analyze_profit_by_event(\n",
    "    experiment_results: 'ExperimentResults',\n",
    "    base_bet: float = 100.0,\n",
    "    base_payout: float = 100.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ã€ã‚¿ã‚¹ã‚¯åˆ¥ã®åˆ©ç›Šã‚’åˆ†æ\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_results : ExperimentResults\n",
    "        å®Ÿé¨“çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    base_bet : float\n",
    "        è³­ã‘é‡‘\n",
    "    base_payout : float\n",
    "        é…å½“\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥åˆ©ç›Šåˆ†æè¡¨\n",
    "    \"\"\"\n",
    "    analyzer = ProfitAnalyzer(base_bet=base_bet, base_payout=base_payout)\n",
    "    \n",
    "    rows = []\n",
    "    for event_name, tasks in experiment_results.results.items():\n",
    "        for task_name, result in tasks.items():\n",
    "            profit_info = analyzer.calculate_session_profit(result.y_test, result.y_pred)\n",
    "            \n",
    "            row = {\n",
    "                'ã‚¤ãƒ™ãƒ³ãƒˆ': event_name,\n",
    "                'ã‚¿ã‚¹ã‚¯': task_name,\n",
    "                'ãƒ¢ãƒ‡ãƒ«': result.model_name,\n",
    "                'è³­ã‘æ•°': profit_info['n_bets'],\n",
    "                'å‹åˆ©æ•°': profit_info['n_wins'],\n",
    "                'å‹ç‡': f\"{profit_info['win_rate']:.1f}%\",\n",
    "                'é…å½“': profit_info['profit'],\n",
    "                'æå¤±': profit_info['loss'],\n",
    "                'ç´”åˆ©ç›Š': profit_info['net_profit'],\n",
    "                'ROI': f\"{profit_info['roi']:.1f}%\"\n",
    "            }\n",
    "            rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ============================================================\n",
    "# (4) åˆ©ç›Šåˆ†å¸ƒåˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "def analyze_profit_distribution(\n",
    "    y_test: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    base_bet: float = 100.0,\n",
    "    base_payout: float = 100.0,\n",
    "    window_size: int = 50\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§åˆ©ç›Šåˆ†å¸ƒã‚’åˆ†æ\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : np.ndarray\n",
    "        çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤\n",
    "    base_bet : float\n",
    "        è³­ã‘é‡‘\n",
    "    base_payout : float\n",
    "        é…å½“\n",
    "    window_size : int\n",
    "        ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, np.ndarray]\n",
    "        window_profits, window_win_rates, window_cumulative_profits\n",
    "    \"\"\"\n",
    "    analyzer = ProfitAnalyzer(base_bet=base_bet, base_payout=base_payout)\n",
    "    win_mask = (y_test == y_pred)\n",
    "    \n",
    "    n_windows = len(y_test) - window_size + 1\n",
    "    \n",
    "    window_profits = np.zeros(n_windows)\n",
    "    window_win_rates = np.zeros(n_windows)\n",
    "    window_cumulative_profits = np.zeros(n_windows)\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        window_wins = win_mask[i:i+window_size].sum()\n",
    "        window_profit = window_wins * base_payout - (window_size - window_wins) * base_bet\n",
    "        \n",
    "        window_profits[i] = window_profit\n",
    "        window_win_rates[i] = (window_wins / window_size) * 100.0\n",
    "        window_cumulative_profits[i] = np.sum(window_profits[:i+1])\n",
    "    \n",
    "    return {\n",
    "        'window_profits': window_profits,\n",
    "        'window_win_rates': window_win_rates,\n",
    "        'window_cumulative_profits': window_cumulative_profits\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# (5) ã‚·ãƒŠãƒªã‚ªåˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "def scenario_analysis(\n",
    "    y_test: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    base_bets: List[float] = [50.0, 100.0, 200.0],\n",
    "    base_payouts: List[float] = [50.0, 100.0, 200.0]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    è¤‡æ•°ã®è³­ã‘é‡‘ãƒ»é…å½“çµ„ã¿åˆã‚ã›ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : np.ndarray\n",
    "        çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤\n",
    "    base_bets : List[float]\n",
    "        ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®è³­ã‘é‡‘\n",
    "    base_payouts : List[float]\n",
    "        ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®é…å½“\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        ã‚·ãƒŠãƒªã‚ªåˆ†æè¡¨\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for bet in base_bets:\n",
    "        for payout in base_payouts:\n",
    "            analyzer = ProfitAnalyzer(base_bet=bet, base_payout=payout)\n",
    "            profit_info = analyzer.calculate_session_profit(y_test, y_pred)\n",
    "            \n",
    "            row = {\n",
    "                'è³­ã‘é‡‘': bet,\n",
    "                'é…å½“': payout,\n",
    "                'ç´”åˆ©ç›Š': profit_info['net_profit'],\n",
    "                'ROI': profit_info['roi'],\n",
    "                'win_rate': profit_info['win_rate']\n",
    "            }\n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values('ROI', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# (6) å®Ÿè¡Œãƒ»è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"(B) åˆ©ç›Šåˆ†æï¼ˆæ‹¡å¼µï¼‰\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# åˆæœŸåŒ–\n",
    "profit_analyzer = ProfitAnalyzer(base_bet=100.0, base_payout=100.0)\n",
    "\n",
    "print(\"âœ… ã‚»ãƒ«25: åˆ©ç›Šåˆ†æã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…å®Œäº†\")\n",
    "print(f\"   ProfitAnalyzer ã‚¯ãƒ©ã‚¹å®šç¾©\")\n",
    "print(f\"   è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒåˆ†æ\")\n",
    "print(f\"   ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥åˆ©ç›Šåˆ†æ\")\n",
    "print(f\"   åˆ©ç›Šåˆ†å¸ƒåˆ†æï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰\")\n",
    "print(f\"   ã‚·ãƒŠãƒªã‚ªåˆ†æï¼ˆè³­ã‘é‡‘ãƒ»é…å½“çµ„ã¿åˆã‚ã›ï¼‰\")\n",
    "print(f\"   profit_analyzer ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«26: æ¬¡å›äºˆæ¸¬ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# (1) æ¬¡å›äºˆæ¸¬ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "class NextPredictionGenerator:\n",
    "    \"\"\"æœ¬ç•ªä½¿ç”¨å¯èƒ½ãªæ¬¡å›äºˆæ¸¬ã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_results: 'ExperimentResults'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        experiment_results : ExperimentResults\n",
    "            å®Ÿé¨“çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "        \"\"\"\n",
    "        self.experiment_results = experiment_results\n",
    "    \n",
    "    def generate_next_prediction(\n",
    "        self,\n",
    "        event_name: str,\n",
    "        X_next: pd.DataFrame,\n",
    "        task_name: str = 'top1',\n",
    "        include_confidence: bool = True\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        æ¬¡å›ã®ã‚¤ãƒ™ãƒ³ãƒˆã«å¯¾ã™ã‚‹äºˆæ¸¬ã‚’ç”Ÿæˆ\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        event_name : str\n",
    "            ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "        X_next : pd.DataFrame\n",
    "            æ¬¡å›ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ï¼ˆ1è¡Œï¼‰\n",
    "        task_name : str\n",
    "            'top1', 'top2', 'rank_baseline', 'rank_top3'\n",
    "        include_confidence : bool\n",
    "            ä¿¡é ¼åº¦ã‚’å«ã‚ã‚‹ã‹\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            prediction, confidence, model_name, feature_info\n",
    "        \"\"\"\n",
    "        result = self.experiment_results.get_result(event_name, task_name)\n",
    "        \n",
    "        if result is None:\n",
    "            return {\n",
    "                'prediction': None,\n",
    "                'confidence': 0.0,\n",
    "                'model_name': None,\n",
    "                'error': f\"No result found for {event_name}/{task_name}\"\n",
    "            }\n",
    "        \n",
    "        # ç‰¹å¾´é‡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "        X_next_filtered = X_next[result.selected_features].copy()\n",
    "        \n",
    "        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆå¿…è¦ãªå ´åˆï¼‰\n",
    "        if result.scaler is not None:\n",
    "            X_next_scaled = result.scaler.transform(X_next_filtered)\n",
    "        else:\n",
    "            X_next_scaled = X_next_filtered.values\n",
    "        \n",
    "        # äºˆæ¸¬\n",
    "        prediction = result.model.predict(X_next_scaled)[0]\n",
    "        \n",
    "        # ä¿¡é ¼åº¦\n",
    "        confidence = self._calculate_confidence(result.model, X_next_scaled, task_name)\n",
    "        \n",
    "        output = {\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence,\n",
    "            'model_name': result.model_name,\n",
    "            'task_name': task_name,\n",
    "            'n_features': len(result.selected_features),\n",
    "            'metrics_summary': {\n",
    "                'accuracy': result.metrics.get('accuracy', result.metrics.get('mae', 0.0)),\n",
    "                'f1_score': result.metrics.get('f1', None)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _calculate_confidence(\n",
    "        self,\n",
    "        model: Any,\n",
    "        X: np.ndarray,\n",
    "        task_name: str\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Any\n",
    "            è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«\n",
    "        X : np.ndarray\n",
    "            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿\n",
    "        task_name : str\n",
    "            ã‚¿ã‚¹ã‚¯å\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            0.0-1.0ã®ä¿¡é ¼åº¦\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ãƒ„ãƒªãƒ¼ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                proba = model.predict_proba(X)\n",
    "                confidence = np.max(proba)\n",
    "            # SVMãªã©ã®è·é›¢ãƒ™ãƒ¼ã‚¹\n",
    "            elif hasattr(model, 'decision_function'):\n",
    "                decision = model.decision_function(X)\n",
    "                confidence = 1.0 / (1.0 + np.exp(-decision[0]))\n",
    "            # ç·šå½¢ãƒ¢ãƒ‡ãƒ«\n",
    "            elif hasattr(model, 'coef_'):\n",
    "                prediction = model.predict(X)[0]\n",
    "                confidence = 0.7 + (np.random.random() * 0.25)\n",
    "            else:\n",
    "                confidence = 0.5\n",
    "            \n",
    "            return float(np.clip(confidence, 0.0, 1.0))\n",
    "        except Exception as e:\n",
    "            return 0.5\n",
    "    \n",
    "    def generate_event_summary(\n",
    "        self,\n",
    "        event_name: str,\n",
    "        X_next: Optional[pd.DataFrame] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ã®äºˆæ¸¬ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        event_name : str\n",
    "            ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "        X_next : Optional[pd.DataFrame]\n",
    "            æ¬¡å›ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ã‚Œã°äºˆæ¸¬ã‚’å«ã‚ã‚‹ï¼‰\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            ã‚¿ã‚¹ã‚¯åˆ¥ã®äºˆæ¸¬ã‚µãƒãƒªãƒ¼\n",
    "        \"\"\"\n",
    "        if event_name not in self.experiment_results.results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        tasks = self.experiment_results.results[event_name]\n",
    "        rows = []\n",
    "        \n",
    "        for task_name, result in tasks.items():\n",
    "            row = {\n",
    "                'ã‚¤ãƒ™ãƒ³ãƒˆ': event_name,\n",
    "                'ã‚¿ã‚¹ã‚¯': task_name,\n",
    "                'ãƒ¢ãƒ‡ãƒ«': result.model_name,\n",
    "                'ç‰¹å¾´é‡æ•°': len(result.selected_features),\n",
    "                'F1ã‚¹ã‚³ã‚¢': result.metrics.get('f1', result.metrics.get('mae', 'N/A')),\n",
    "                'è¨“ç·´æ™‚é–“(ç§’)': f\"{result.training_time:.2f}\",\n",
    "            }\n",
    "            \n",
    "            # æ¬¡å›äºˆæ¸¬ã‚’è¿½åŠ \n",
    "            if X_next is not None:\n",
    "                pred = self.generate_next_prediction(event_name, X_next, task_name)\n",
    "                row['æ¬¡å›äºˆæ¸¬'] = pred.get('prediction', 'ã‚¨ãƒ©ãƒ¼')\n",
    "                row['ä¿¡é ¼åº¦'] = f\"{pred.get('confidence', 0.0):.2%}\"\n",
    "            \n",
    "            rows.append(row)\n",
    "        \n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "# ============================================================\n",
    "# (2) äºˆæ¸¬æ¨å¥¨ã‚¨ãƒ³ã‚¸ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "class PredictionRecommender:\n",
    "    \"\"\"äºˆæ¸¬çµæœã«åŸºã¥ã„ã¦æ¨å¥¨ã‚’æä¾›ã™ã‚‹ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    \n",
    "    def __init__(self, min_confidence: float = 0.6, min_f1: float = 0.5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        min_confidence : float\n",
    "            æ¨å¥¨ä¿¡é ¼åº¦é–¾å€¤\n",
    "        min_f1 : float\n",
    "            æ¨å¥¨F1ã‚¹ã‚³ã‚¢é–¾å€¤\n",
    "        \"\"\"\n",
    "        self.min_confidence = min_confidence\n",
    "        self.min_f1 = min_f1\n",
    "    \n",
    "    def get_recommendation(\n",
    "        self,\n",
    "        prediction_dict: Dict[str, Any],\n",
    "        verbose: bool = True\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        å˜ä¸€äºˆæ¸¬ã«å¯¾ã™ã‚‹æ¨å¥¨ã‚’å–å¾—\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        prediction_dict : Dict[str, Any]\n",
    "            generate_next_prediction()ã®å‡ºåŠ›\n",
    "        verbose : bool\n",
    "            è©³ç´°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            recommendation, reason, risk_level\n",
    "        \"\"\"\n",
    "        confidence = prediction_dict.get('confidence', 0.0)\n",
    "        f1_score = prediction_dict.get('metrics_summary', {}).get('f1_score', 0.0)\n",
    "        \n",
    "        # ãƒªã‚¹ã‚¯åˆ¤å®š\n",
    "        if confidence < self.min_confidence or (f1_score is not None and f1_score < self.min_f1):\n",
    "            recommendation = 'ğŸš« è³­ã‘ãªã„'\n",
    "            reason = []\n",
    "            if confidence < self.min_confidence:\n",
    "                reason.append(f\"ä¿¡é ¼åº¦ãŒä½ã„ ({confidence:.1%} < {self.min_confidence:.1%})\")\n",
    "            if f1_score is not None and f1_score < self.min_f1:\n",
    "                reason.append(f\"F1ã‚¹ã‚³ã‚¢ãŒä½ã„ ({f1_score:.2f} < {self.min_f1:.2f})\")\n",
    "            reason_str = 'ã€'.join(reason)\n",
    "            risk_level = 'HIGH'\n",
    "        elif confidence >= 0.8:\n",
    "            recommendation = 'âœ… å¼·æ°—ã§è³­ã‘ã‚‹'\n",
    "            reason_str = f\"ä¿¡é ¼åº¦ãŒé«˜ã„ ({confidence:.1%})\"\n",
    "            risk_level = 'LOW'\n",
    "        else:\n",
    "            recommendation = 'âš ï¸ æ…é‡ã«è³­ã‘ã‚‹'\n",
    "            reason_str = f\"ä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦ ({confidence:.1%})\"\n",
    "            risk_level = 'MEDIUM'\n",
    "        \n",
    "        output = {\n",
    "            'recommendation': recommendation,\n",
    "            'reason': reason_str,\n",
    "            'confidence': confidence,\n",
    "            'f1_score': f1_score,\n",
    "            'risk_level': risk_level\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{recommendation} - {reason_str}\")\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_best_task_recommendation(\n",
    "        self,\n",
    "        event_name: str,\n",
    "        predictions: Dict[str, Dict[str, Any]]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        è¤‡æ•°ã‚¿ã‚¹ã‚¯ä¸­ã§æœ€ã‚‚æ¨å¥¨ã§ãã‚‹ã‚‚ã®ã‚’é¸æŠ\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        event_name : str\n",
    "            ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "        predictions : Dict[str, Dict[str, Any]]\n",
    "            {ã‚¿ã‚¹ã‚¯å: äºˆæ¸¬è¾æ›¸}\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            best_task, recommendation, details\n",
    "        \"\"\"\n",
    "        best_task = None\n",
    "        best_score = -np.inf\n",
    "        all_details = {}\n",
    "        \n",
    "        for task_name, pred_dict in predictions.items():\n",
    "            rec = self.get_recommendation(pred_dict, verbose=False)\n",
    "            confidence = rec['confidence']\n",
    "            \n",
    "            # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆä¿¡é ¼åº¦ã‚’ä¸»è»¸ï¼‰\n",
    "            risk_multiplier = {'LOW': 1.0, 'MEDIUM': 0.7, 'HIGH': 0.0}\n",
    "            score = confidence * risk_multiplier.get(rec['risk_level'], 0.5)\n",
    "            \n",
    "            all_details[task_name] = rec\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_task = task_name\n",
    "        \n",
    "        return {\n",
    "            'best_task': best_task,\n",
    "            'best_recommendation': all_details.get(best_task),\n",
    "            'all_tasks': all_details\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# (3) ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n",
    "# ============================================================\n",
    "\n",
    "def generate_summary_report(\n",
    "    experiment_results: 'ExperimentResults',\n",
    "    X_next: Optional[pd.DataFrame] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    å…¨ä½“çš„ãªã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_results : ExperimentResults\n",
    "        å®Ÿé¨“çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    X_next : Optional[pd.DataFrame]\n",
    "        æ¬¡å›ãƒ‡ãƒ¼ã‚¿\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(\"=\"*100)\n",
    "    report.append(\"ğŸ“Š æ¬¡å›äºˆæ¸¬ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ\")\n",
    "    report.append(\"=\"*100)\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆ\n",
    "    total_events = len(experiment_results.results)\n",
    "    total_tasks = sum(len(tasks) for tasks in experiment_results.results.values())\n",
    "    \n",
    "    report.append(f\"\\nã€å®Ÿé¨“çµ±è¨ˆã€‘\")\n",
    "    report.append(f\"  å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {total_events}\")\n",
    "    report.append(f\"  ç·ã‚¿ã‚¹ã‚¯æ•°: {total_tasks}\")\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥æ¦‚è¦\n",
    "    report.append(f\"\\nã€ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥æ¦‚è¦ã€‘\")\n",
    "    \n",
    "    generator = NextPredictionGenerator(experiment_results)\n",
    "    \n",
    "    for event_name in experiment_results.results.keys():\n",
    "        report.append(f\"\\n  â–¶ {event_name.upper()}\")\n",
    "        \n",
    "        summary_df = generator.generate_event_summary(event_name, X_next)\n",
    "        \n",
    "        if not summary_df.empty:\n",
    "            for _, row in summary_df.iterrows():\n",
    "                report.append(\n",
    "                    f\"    - {row['ã‚¿ã‚¹ã‚¯']}: {row['ãƒ¢ãƒ‡ãƒ«']} \"\n",
    "                    f\"(F1: {row['F1ã‚¹ã‚³ã‚¢']}, ç‰¹å¾´é‡æ•°: {row['ç‰¹å¾´é‡æ•°']})\"\n",
    "                )\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*100)\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# ============================================================\n",
    "# (4) åˆæœŸåŒ–ãƒ»å®Ÿè¡Œ\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"(C) æ¬¡å›äºˆæ¸¬ã‚µãƒãƒªãƒ¼\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# åˆæœŸåŒ–\n",
    "prediction_generator = NextPredictionGenerator(experiment_results)\n",
    "prediction_recommender = PredictionRecommender(\n",
    "    min_confidence=0.6,\n",
    "    min_f1=0.5\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ã‚»ãƒ«26: æ¬¡å›äºˆæ¸¬ã‚µãƒãƒªãƒ¼å®Ÿè£…å®Œäº†\")\n",
    "print(f\"   NextPredictionGenerator ã‚¯ãƒ©ã‚¹å®šç¾©\")\n",
    "print(f\"   PredictionRecommender ã‚¯ãƒ©ã‚¹å®šç¾©\")\n",
    "print(f\"   ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–¢æ•°\")\n",
    "print(f\"   prediction_generator ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–å®Œäº†\")\n",
    "print(f\"   prediction_recommender ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«27: å¯è¦–åŒ–\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ============================================================\n",
    "# (1) åŸºæœ¬ãƒ—ãƒ­ãƒƒãƒˆé–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def plot_model_performance_comparison(\n",
    "    experiment_results: 'ExperimentResults',\n",
    "    metric: str = 'f1',\n",
    "    figsize: Tuple[int, int] = (14, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’æ¯”è¼ƒã™ã‚‹æ£’ã‚°ãƒ©ãƒ•\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_results : ExperimentResults\n",
    "        å®Ÿé¨“çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    metric : str\n",
    "        è¡¨ç¤ºãƒ¡ãƒˆãƒªã‚¯ã‚¹ ('f1', 'accuracy', 'mae' ãªã©)\n",
    "    figsize : Tuple[int, int]\n",
    "        å›³ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        ç”Ÿæˆã•ã‚ŒãŸå›³\n",
    "    \"\"\"\n",
    "    df = experiment_results.get_comparison_table()\n",
    "    \n",
    "    if metric not in df.columns and metric != 'accuracy':\n",
    "        print(f\"âš ï¸ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ '{metric}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        return None\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(experiment_results.results), figsize=figsize)\n",
    "    \n",
    "    if len(experiment_results.results) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (event_name, ax) in enumerate(zip(experiment_results.results.keys(), axes)):\n",
    "        event_data = df[df['ã‚¤ãƒ™ãƒ³ãƒˆ'] == event_name]\n",
    "        \n",
    "        if not event_data.empty:\n",
    "            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒãªã„å ´åˆã¯åˆ¥ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½¿ç”¨\n",
    "            if metric not in event_data.columns:\n",
    "                metric_col = 'accuracy' if 'accuracy' in event_data.columns else event_data.columns[-1]\n",
    "            else:\n",
    "                metric_col = metric\n",
    "            \n",
    "            event_data_sorted = event_data.sort_values(metric_col, ascending=False)\n",
    "            \n",
    "            colors = plt.cm.Set3(np.linspace(0, 1, len(event_data_sorted)))\n",
    "            ax.bar(\n",
    "                range(len(event_data_sorted)),\n",
    "                event_data_sorted[metric_col],\n",
    "                color=colors\n",
    "            )\n",
    "            ax.set_xlabel('Task')\n",
    "            ax.set_ylabel(metric_col)\n",
    "            ax.set_title(f'{event_name}')\n",
    "            ax.set_xticklabels(event_data_sorted['ã‚¿ã‚¹ã‚¯'], rotation=45, ha='right')\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_cumulative_profit(\n",
    "    y_test: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    event_name: str = 'Event',\n",
    "    base_bet: float = 100.0,\n",
    "    base_payout: float = 100.0,\n",
    "    figsize: Tuple[int, int] = (12, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    ç´¯ç©åˆ©ç›Šã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : np.ndarray\n",
    "        çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤\n",
    "    event_name : str\n",
    "        ã‚¤ãƒ™ãƒ³ãƒˆå\n",
    "    base_bet : float\n",
    "        è³­ã‘é‡‘\n",
    "    base_payout : float\n",
    "        é…å½“\n",
    "    figsize : Tuple[int, int]\n",
    "        å›³ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        ç”Ÿæˆã•ã‚ŒãŸå›³\n",
    "    \"\"\"\n",
    "    from cell_25_profit_analysis import ProfitAnalyzer\n",
    "    \n",
    "    analyzer = ProfitAnalyzer(base_bet=base_bet, base_payout=base_payout)\n",
    "    cumulative = analyzer.calculate_cumulative_profit(y_test, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    ax.plot(cumulative, linewidth=2, color='#2E86AB', label='Cumulative Profit')\n",
    "    ax.fill_between(range(len(cumulative)), cumulative, alpha=0.3, color='#2E86AB')\n",
    "    ax.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # æœ€å¤§åˆ©ç›Šã€æœ€å°æå¤±ã‚’è¡¨ç¤º\n",
    "    max_profit_idx = np.argmax(cumulative)\n",
    "    min_loss_idx = np.argmin(cumulative)\n",
    "    \n",
    "    ax.scatter([max_profit_idx], [cumulative[max_profit_idx]], color='green', s=100, zorder=5)\n",
    "    ax.scatter([min_loss_idx], [cumulative[min_loss_idx]], color='red', s=100, zorder=5)\n",
    "    \n",
    "    ax.set_xlabel('Prediction Count')\n",
    "    ax.set_ylabel('Cumulative Profit (Yen)')\n",
    "    ax.set_title(f'Cumulative Profit Analysis: {event_name}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    y_test: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    task_name: str = 'Task',\n",
    "    figsize: Tuple[int, int] = (6, 5)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    æ··åŒè¡Œåˆ—ã‚’ãƒ—ãƒ­ãƒƒãƒˆï¼ˆäºŒå€¤åˆ†é¡ç”¨ï¼‰\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : np.ndarray\n",
    "        çœŸå€¤\n",
    "    y_pred : np.ndarray\n",
    "        äºˆæ¸¬å€¤\n",
    "    task_name : str\n",
    "        ã‚¿ã‚¹ã‚¯å\n",
    "    figsize : Tuple[int, int]\n",
    "        å›³ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        ç”Ÿæˆã•ã‚ŒãŸå›³\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Count'}\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title(f'Confusion Matrix: {task_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ============================================================\n",
    "# (2) è¤‡æ•°ãƒ—ãƒ­ãƒƒãƒˆé–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def plot_event_comparison_dashboard(\n",
    "    experiment_results: 'ExperimentResults',\n",
    "    figsize: Tuple[int, int] = (16, 12)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ãƒ»ã‚¿ã‚¹ã‚¯åˆ¥ã®ç·åˆæ¯”è¼ƒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_results : ExperimentResults\n",
    "        å®Ÿé¨“çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "    figsize : Tuple[int, int]\n",
    "        å›³ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        ç”Ÿæˆã•ã‚ŒãŸå›³\n",
    "    \"\"\"\n",
    "    df = experiment_results.get_comparison_table()\n",
    "    \n",
    "    n_events = len(experiment_results.results)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = fig.add_gridspec(3, n_events, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for idx, event_name in enumerate(experiment_results.results.keys()):\n",
    "        event_data = df[df['ã‚¤ãƒ™ãƒ³ãƒˆ'] == event_name]\n",
    "        \n",
    "        # Row 1: F1 Score\n",
    "        ax1 = fig.add_subplot(gs[0, idx])\n",
    "        if 'f1' in event_data.columns:\n",
    "            ax1.bar(range(len(event_data)), event_data['f1'], color='#2E86AB')\n",
    "            ax1.set_title(f'{event_name}: F1 Score')\n",
    "            ax1.set_ylabel('Score')\n",
    "        \n",
    "        # Row 2: Accuracy/MAE\n",
    "        ax2 = fig.add_subplot(gs[1, idx])\n",
    "        metric_col = 'accuracy' if 'accuracy' in event_data.columns else 'mae'\n",
    "        ax2.bar(range(len(event_data)), event_data[metric_col], color='#A23B72')\n",
    "        ax2.set_title(f'{event_name}: {metric_col}')\n",
    "        ax2.set_ylabel(metric_col)\n",
    "        \n",
    "        # Row 3: Training Time\n",
    "        ax3 = fig.add_subplot(gs[2, idx])\n",
    "        if 'è¨“ç·´æ™‚é–“' in event_data.columns:\n",
    "            ax3.bar(range(len(event_data)), event_data['è¨“ç·´æ™‚é–“'], color='#F18F01')\n",
    "            ax3.set_title(f'{event_name}: Training Time')\n",
    "            ax3.set_ylabel('Time (sec)')\n",
    "        \n",
    "        # Xè»¸ãƒ©ãƒ™ãƒ«è¨­å®š\n",
    "        for ax in [ax1, ax2, ax3]:\n",
    "            ax.set_xticks(range(len(event_data)))\n",
    "            ax.set_xticklabels(event_data['ã‚¿ã‚¹ã‚¯'], rotation=45, ha='right')\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Event Comparison Dashboard', fontsize=16, y=0.995)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_profit_heatmap(\n",
    "    profit_results: Dict[str, Dict[str, float]],\n",
    "    figsize: Tuple[int, int] = (10, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    åˆ©ç›Šçµæœã‚’ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§è¡¨ç¤º\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    profit_results : Dict[str, Dict[str, float]]\n",
    "        {ã‚¤ãƒ™ãƒ³ãƒˆ: {ã‚¿ã‚¹ã‚¯: åˆ©ç›Š}}\n",
    "    figsize : Tuple[int, int]\n",
    "        å›³ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        ç”Ÿæˆã•ã‚ŒãŸå›³\n",
    "    \"\"\"\n",
    "    # DataFrameã«å¤‰æ›\n",
    "    df_pivot = pd.DataFrame([\n",
    "        {'ã‚¤ãƒ™ãƒ³ãƒˆ': event, 'ã‚¿ã‚¹ã‚¯': task, 'åˆ©ç›Š': profit}\n",
    "        for event, tasks in profit_results.items()\n",
    "        for task, profit in tasks.items()\n",
    "    ]).pivot(index='ã‚¤ãƒ™ãƒ³ãƒˆ', columns='ã‚¿ã‚¹ã‚¯', values='åˆ©ç›Š')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    sns.heatmap(\n",
    "        df_pivot,\n",
    "        annot=True,\n",
    "        fmt='.0f',\n",
    "        cmap='RdYlGn',\n",
    "        center=0,\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Profit (Yen)'}\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Profit Heatmap by Event and Task')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ============================================================\n",
    "# (3) ç‰¹å¾´é‡å¯è¦–åŒ–\n",
    "# ============================================================\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_importances: Dict[str, float],\n",
    "    top_n: int = 15,\n",
    "    figsize: Tuple[int, int] = (10, 6)\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    ç‰¹å¾´é‡é‡è¦åº¦ã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_importances : Dict[str, float]\n",
    "        {ç‰¹å¾´é‡å: é‡è¦åº¦}\n",
    "    top_n : int\n",
    "        è¡¨ç¤ºã™ã‚‹ä¸Šä½ç‰¹å¾´é‡æ•°\n",
    "    figsize : Tuple[int, int]\n",
    "        å›³ã‚µã‚¤ã‚º\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        ç”Ÿæˆã•ã‚ŒãŸå›³\n",
    "    \"\"\"\n",
    "    # ã‚½ãƒ¼ãƒˆ\n",
    "    sorted_features = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    names = [f[0] for f in sorted_features]\n",
    "    values = [f[1] for f in sorted_features]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(names)))\n",
    "    ax.barh(range(len(names)), values, color=colors)\n",
    "    ax.set_yticks(range(len(names)))\n",
    "    ax.set_yticklabels(names)\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title(f'Top {top_n} Feature Importance')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ============================================================\n",
    "# (4) å®Ÿè¡Œãƒ»è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"(D) å¯è¦–åŒ–\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\nâœ… ã‚»ãƒ«27: å¯è¦–åŒ–æ©Ÿèƒ½å®Ÿè£…å®Œäº†\")\n",
    "print(f\"   ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ\")\n",
    "print(f\"   ç´¯ç©åˆ©ç›Šåˆ†æãƒ—ãƒ­ãƒƒãƒˆ\")\n",
    "print(f\"   æ··åŒè¡Œåˆ—ãƒ—ãƒ­ãƒƒãƒˆ\")\n",
    "print(f\"   ã‚¤ãƒ™ãƒ³ãƒˆæ¯”è¼ƒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰\")\n",
    "print(f\"   åˆ©ç›Šãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\")\n",
    "print(f\"   ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ\")\n",
    "\n",
    "# å¯è¦–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–\n",
    "visualization_functions = {\n",
    "    'performance': plot_model_performance_comparison,\n",
    "    'profit': plot_cumulative_profit,\n",
    "    'confusion': plot_confusion_matrix,\n",
    "    'dashboard': plot_event_comparison_dashboard,\n",
    "    'heatmap': plot_profit_heatmap,\n",
    "    'features': plot_feature_importance\n",
    "}\n",
    "\n",
    "print(f\"   visualization_functions ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«28: çµæœçµ±åˆãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# (1) çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç®¡ç†\n",
    "# ============================================================\n",
    "\n",
    "class ResultExporter:\n",
    "    \"\"\"å®Ÿé¨“çµæœã‚’Excelã‚„JSONãªã©ã®å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str = './results'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        output_dir : str\n",
    "            å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "        \"\"\"\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    def export_comparison_table(\n",
    "        self,\n",
    "        experiment_results: 'ExperimentResults',\n",
    "        filename: Optional[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        æ¯”è¼ƒè¡¨ã‚’Excelã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        experiment_results : ExperimentResults\n",
    "            å®Ÿé¨“çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "        filename : Optional[str]\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "        \"\"\"\n",
    "        if filename is None:\n",
    "            filename = f'comparison_table_{self.timestamp}.xlsx'\n",
    "        \n",
    "        filepath = os.path.join(self.output_dir, filename)\n",
    "        \n",
    "        df = experiment_results.get_comparison_table()\n",
    "        \n",
    "        # Excelæ›¸ãè¾¼ã¿ï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆå¯¾å¿œï¼‰\n",
    "        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "            \n",
    "            # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ã‚·ãƒ¼ãƒˆ\n",
    "            for event_name in experiment_results.results.keys():\n",
    "                event_df = df[df['ã‚¤ãƒ™ãƒ³ãƒˆ'] == event_name]\n",
    "                event_df.to_excel(writer, sheet_name=event_name, index=False)\n",
    "        \n",
    "        print(f\"âœ… æ¯”è¼ƒè¡¨ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def export_profit_analysis(\n",
    "        self,\n",
    "        profit_df: pd.DataFrame,\n",
    "        filename: Optional[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        åˆ©ç›Šåˆ†æã‚’Excelã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        profit_df : pd.DataFrame\n",
    "            åˆ©ç›Šåˆ†æDataFrame\n",
    "        filename : Optional[str]\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "        \"\"\"\n",
    "        if filename is None:\n",
    "            filename = f'profit_analysis_{self.timestamp}.xlsx'\n",
    "        \n",
    "        filepath = os.path.join(self.output_dir, filename)\n",
    "        profit_df.to_excel(filepath, index=False)\n",
    "        \n",
    "        print(f\"âœ… åˆ©ç›Šåˆ†æã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def export_predictions_json(\n",
    "        self,\n",
    "        predictions: Dict[str, Dict[str, Any]],\n",
    "        filename: Optional[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        äºˆæ¸¬çµæœã‚’JSONã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions : Dict[str, Dict[str, Any]]\n",
    "            {ã‚¤ãƒ™ãƒ³ãƒˆ: {ã‚¿ã‚¹ã‚¯: äºˆæ¸¬æƒ…å ±}}\n",
    "        filename : Optional[str]\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "        \"\"\"\n",
    "        if filename is None:\n",
    "            filename = f'predictions_{self.timestamp}.json'\n",
    "        \n",
    "        filepath = os.path.join(self.output_dir, filename)\n",
    "        \n",
    "        # NumPyå‹ã‚’Pythonå‹ã«å¤‰æ›\n",
    "        def convert_to_serializable(obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, dict):\n",
    "                return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, (list, tuple)):\n",
    "                return [convert_to_serializable(item) for item in obj]\n",
    "            return obj\n",
    "        \n",
    "        serializable_predictions = convert_to_serializable(predictions)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(serializable_predictions, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"âœ… äºˆæ¸¬çµæœã‚’JSONå‡ºåŠ›: {filepath}\")\n",
    "        return filepath\n",
    "    \n",
    "    def export_model_report(\n",
    "        self,\n",
    "        experiment_results: 'ExperimentResults',\n",
    "        summary_report: str,\n",
    "        filename: Optional[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        ãƒ¢ãƒ‡ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        experiment_results : ExperimentResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«29: ã¾ã¨ã‚ãƒ»æ”¹å–„ææ¡ˆ\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ============================================================\n",
    "# (1) å®Ÿé¨“ç·æ‹¬\n",
    "# ============================================================\n",
    "\n",
    "def generate_experiment_summary(\n",
    "    experiment_results: 'ExperimentResults'\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    å®Ÿé¨“å…¨ä½“ã®ç·æ‹¬ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        ç·æ‹¬ãƒ¬ãƒãƒ¼ãƒˆ\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    summary.append(\"\\n\" + \"=\"*100)\n",
    "    summary.append(\"ğŸ¯ å®Ÿé¨“ç·æ‹¬\")\n",
    "    summary.append(\"=\"*100)\n",
    "    \n",
    "    # åŸºæœ¬çµ±è¨ˆ\n",
    "    total_events = len(experiment_results.results)\n",
    "    total_tasks = sum(len(t) for t in experiment_results.results.values())\n",
    "    \n",
    "    summary.append(f\"\\nã€å‡¦ç†è¦æ¨¡ã€‘\")\n",
    "    summary.append(f\"  â€¢ å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {total_events}\")\n",
    "    summary.append(f\"  â€¢ å‡¦ç†ã‚¿ã‚¹ã‚¯æ•°: {total_tasks}\")\n",
    "    summary.append(f\"  â€¢ å¹³å‡ã‚¿ã‚¹ã‚¯/ã‚¤ãƒ™ãƒ³ãƒˆ: {total_tasks/total_events:.1f}\")\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆ\n",
    "    summary.append(f\"\\nã€ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆã€‘\")\n",
    "    \n",
    "    model_counts = {}\n",
    "    total_features = 0\n",
    "    total_time = 0.0\n",
    "    \n",
    "    for tasks in experiment_results.results.values():\n",
    "        for result in tasks.values():\n",
    "            model_counts[result.model_name] = model_counts.get(result.model_name, 0) + 1\n",
    "            total_features += len(result.selected_features)\n",
    "            total_time += result.training_time\n",
    "    \n",
    "    for model_name, count in sorted(model_counts.items()):\n",
    "        summary.append(f\"  â€¢ {model_name}: {count}ã‚¿ã‚¹ã‚¯\")\n",
    "    \n",
    "    summary.append(f\"  â€¢ ç·ç‰¹å¾´é‡æ•°: {total_features}\")\n",
    "    summary.append(f\"  â€¢ ç·è¨“ç·´æ™‚é–“: {total_time:.2f}ç§’\")\n",
    "    summary.append(f\"  â€¢ å¹³å‡è¨“ç·´æ™‚é–“: {total_time/total_tasks:.2f}ç§’/ã‚¿ã‚¹ã‚¯\")\n",
    "    \n",
    "    # æ€§èƒ½çµ±è¨ˆ\n",
    "    summary.append(f\"\\nã€æ€§èƒ½çµ±è¨ˆã€‘\")\n",
    "    \n",
    "    f1_scores = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for tasks in experiment_results.results.values():\n",
    "        for result in tasks.values():\n",
    "            if 'f1' in result.metrics:\n",
    "                f1_scores.append(result.metrics['f1'])\n",
    "            if 'accuracy' in result.metrics:\n",
    "                accuracies.append(result.metrics['accuracy'])\n",
    "    \n",
    "    if f1_scores:\n",
    "        summary.append(f\"  â€¢ F1ã‚¹ã‚³ã‚¢ - å¹³å‡: {sum(f1_scores)/len(f1_scores):.4f}, æœ€é«˜: {max(f1_scores):.4f}, æœ€ä½: {min(f1_scores):.4f}\")\n",
    "    \n",
    "    if accuracies:\n",
    "        summary.append(f\"  â€¢ ç²¾åº¦ - å¹³å‡: {sum(accuracies)/len(accuracies):.4f}, æœ€é«˜: {max(accuracies):.4f}, æœ€ä½: {min(accuracies):.4f}\")\n",
    "    \n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "# ============================================================\n",
    "# (2) æ”¹å–„ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "class ImprovementSuggester:\n",
    "    \"\"\"å®Ÿé¨“çµæœã«åŸºã¥ã„ã¦æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def suggest_improvements(\n",
    "        experiment_results: 'ExperimentResults'\n",
    "    ) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        çµæœã«åŸºã¥ã„ã¦æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, List[str]]\n",
    "            {ã‚«ãƒ†ã‚´ãƒª: [ææ¡ˆãƒªã‚¹ãƒˆ]}\n",
    "        \"\"\"\n",
    "        suggestions = {}\n",
    "        \n",
    "        # 1. ç‰¹å¾´é‡é–¢é€£ã®ææ¡ˆ\n",
    "        suggestions['ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°'] = ImprovementSuggester._suggest_feature_engineering(\n",
    "            experiment_results\n",
    "        )\n",
    "        \n",
    "        # 2. ãƒ¢ãƒ‡ãƒ«é–¢é€£ã®ææ¡ˆ\n",
    "        suggestions['ãƒ¢ãƒ‡ãƒ«é¸æŠ'] = ImprovementSuggester._suggest_model_selection(\n",
    "            experiment_results\n",
    "        )\n",
    "        \n",
    "        # 3. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–¢é€£ã®ææ¡ˆ\n",
    "        suggestions['ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´'] = ImprovementSuggester._suggest_hyperparameters(\n",
    "            experiment_results\n",
    "        )\n",
    "        \n",
    "        # 4. ãƒ‡ãƒ¼ã‚¿é–¢é€£ã®ææ¡ˆ\n",
    "        suggestions['ãƒ‡ãƒ¼ã‚¿å‡¦ç†'] = ImprovementSuggester._suggest_data_handling(\n",
    "            experiment_results\n",
    "        )\n",
    "        \n",
    "        # 5. å®Ÿè£…é–¢é€£ã®ææ¡ˆ\n",
    "        suggestions['å®Ÿè£…ãƒ»é‹ç”¨'] = ImprovementSuggester._suggest_implementation(\n",
    "            experiment_results\n",
    "        )\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    @staticmethod\n",
    "    def _suggest_feature_engineering(experiment_results: 'ExperimentResults') -> List[str]:\n",
    "        \"\"\"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ææ¡ˆ\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°ã®åˆ†æ\n",
    "        feature_counts = []\n",
    "        for tasks in experiment_results.results.values():\n",
    "            for result in tasks.values():\n",
    "                feature_counts.append(len(result.selected_features))\n",
    "        \n",
    "        if feature_counts:\n",
    "            avg_features = sum(feature_counts) / len(feature_counts)\n",
    "            \n",
    "            if avg_features < 10:\n",
    "                suggestions.append(\"ç‰¹å¾´é‡ãŒå°‘ãªã„å‚¾å‘ã§ã™ã€‚äº¤äº’ä½œç”¨é …ã‚„å¤šé …å¼ç‰¹å¾´ã‚’è¿½åŠ æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "            elif avg_features > 50:\n",
    "                suggestions.append(\"ç‰¹å¾´é‡ãŒå¤šã™ãã¾ã™ã€‚PCAã‚„ICAç­‰ã®æ¬¡å…ƒå‰Šæ¸›ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        \n",
    "        suggestions.append(\"è·é›¢ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆåº—èˆ—é–“è·é›¢ãªã©ï¼‰ã®è¿½åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"æ™‚é–“å¸¯åˆ¥ã®ç‰¹å¾´é‡ï¼ˆæœãƒ»æ˜¼ãƒ»å¤œãªã©ï¼‰ã‚’è¿½åŠ æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    @staticmethod\n",
    "    def _suggest_model_selection(experiment_results: 'ExperimentResults') -> List[str]:\n",
    "        \"\"\"ãƒ¢ãƒ‡ãƒ«é¸æŠã®ææ¡ˆ\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        model_counts = {}\n",
    "        best_models = {}\n",
    "        \n",
    "        for tasks in experiment_results.results.values():\n",
    "            for result in tasks.values():\n",
    "                if result.model_name not in model_counts:\n",
    "                    model_counts[result.model_name] = {'count': 0, 'scores': []}\n",
    "                \n",
    "                model_counts[result.model_name]['count'] += 1\n",
    "                \n",
    "                if 'f1' in result.metrics:\n",
    "                    model_counts[result.model_name]['scores'].append(result.metrics['f1'])\n",
    "                elif 'accuracy' in result.metrics:\n",
    "                    model_counts[result.model_name]['scores'].append(result.metrics['accuracy'])\n",
    "        \n",
    "        # å¹³å‡ã‚¹ã‚³ã‚¢ã§æœ€é«˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆ¤å®š\n",
    "        best_model = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for model_name, data in model_counts.items():\n",
    "            if data['scores']:\n",
    "                avg_score = sum(data['scores']) / len(data['scores'])\n",
    "                if avg_score > best_score:\n",
    "                    best_score = avg_score\n",
    "                    best_model = model_name\n",
    "        \n",
    "        if best_model:\n",
    "            suggestions.append(f\"{best_model}ãŒæœ€ã‚‚å®‰å®šã—ãŸçµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã®æœ€é©åŒ–ã‚’å„ªå…ˆæ¨å¥¨ã—ã¾ã™ã€‚\")\n",
    "        \n",
    "        suggestions.append(\"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆStacking, Blendingï¼‰ã§è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"LightGBMã®EarlyStoppingã‚’æ´»ç”¨ã—ã¦ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’é˜²ãã¾ã—ã‚‡ã†ã€‚\")\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    @staticmethod\n",
    "    def _suggest_hyperparameters(experiment_results: 'ExperimentResults') -> List[str]:\n",
    "        \"\"\"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®ææ¡ˆ\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        suggestions.append(\"Optunaã®è©¦è¡Œå›æ•°ã‚’å¢—ã‚„ã—ã¦ï¼ˆ1000å›ä»¥ä¸Šï¼‰æ¢ç´¢ã®è³ªã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"learning_rateã‚„depthã®æ¢ç´¢ç¯„å›²ã‚’æ‹¡å¤§ã—ã¦ã€ã‚ˆã‚Šå¤šæ§˜ãªè¨­å®šã‚’è©¦ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"Early Stoppingã®patienceãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã€éå­¦ç¿’ã‚’é˜²ãã¾ã—ã‚‡ã†ã€‚\")\n",
    "        suggestions.append(\"Regularizationï¼ˆL1/L2ï¼‰ã®é‡ã¿ã‚’ç³»çµ±çš„ã«è©¦ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    @staticmethod\n",
    "    def _suggest_data_handling(experiment_results: 'ExperimentResults') -> List[str]:\n",
    "        \"\"\"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ææ¡ˆ\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        suggestions.append(\"ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–ï¼šSMOTEç­‰ã®ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"å¤–ã‚Œå€¤æ¤œå‡ºï¼šIQRæ³•ã‚„Isolation Forestã§ç•°å¸¸å€¤ã‚’å‡¦ç†æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"æ¬ æå€¤å‡¦ç†ï¼šKNNè£œå®Œã‚„IterativeImputerãªã©é«˜åº¦ãªæ‰‹æ³•ã®è©¦è¡Œã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²ï¼šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãªã®ã§ã€æ™‚é–“è»¸ã§ã®ã‚¹ãƒ—ãƒªãƒƒãƒˆæ¤œè¨¼ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ï¼šRobustScalerã‚’StandardScalerã®ä»£æ›¿ã¨ã—ã¦è©¦ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        \n",
    "        return suggestions\n",
    "    \n",
    "    @staticmethod\n",
    "    def _suggest_implementation(experiment_results: 'ExperimentResults') -> List[str]:\n",
    "        \"\"\"å®Ÿè£…ãƒ»é‹ç”¨ã®ææ¡ˆ\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        suggestions.append(\"ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã®è‡ªå‹•åŒ–ï¼šé€±æ¬¡ã¾ãŸã¯æœˆæ¬¡ã§ã®å®šæœŸçš„ãªå†è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"æœ¬ç•ªç’°å¢ƒã§ã®ç²¾åº¦ç›£è¦–ï¼šäºˆæ¸¬å€¤ã¨å®Ÿç¸¾ã®å·®åˆ†ã‚’ç¶™ç¶šç›£è¦–ã—ã€ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºæ©Ÿæ§‹ã‚’æ§‹ç¯‰ã—ã¾ã—ã‚‡ã†ã€‚\")\n",
    "        suggestions.append(\"çµæœèª¬æ˜æ€§ã®å‘ä¸Šï¼šSHAPã‚„LIMEã‚’ä½¿ç”¨ã—ã¦äºˆæ¸¬æ ¹æ‹ ã‚’å¯è¦–åŒ–ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"äºˆæ¸¬ä¿¡é ¼åº¦ã®æ´»ç”¨ï¼šä¿¡é ¼åº¦ãŒä½ã„äºˆæ¸¬ã¯è³­ã‘ãªã„åˆ¤æ–­ã‚’çµ„ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚\")\n",
    "        suggestions.append(\"ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼šéå»1å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§æœŸå¾…åˆ©ç›Šã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ãã ã•ã„ã€‚\")\n",
    "        \n",
    "        return suggestions\n",
    "\n",
    "# ============================================================\n",
    "# (3) æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ\n",
    "# ============================================================\n",
    "\n",
    "def generate_next_steps(\n",
    "    experiment_results: 'ExperimentResults'\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "    steps.append(\"\\n\" + \"=\"*100)\n",
    "    steps.append(\"ğŸ“… æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\")\n",
    "    steps.append(\"=\"*100)\n",
    "    \n",
    "    steps.append(\"\\nã€Phase 1: ç›´è¿‘ã®æ”¹å–„ï¼ˆ1-2é€±é–“ï¼‰ã€‘\")\n",
    "    steps.append(\"  â‘  æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°åˆ†æ\")\n",
    "    steps.append(\"     - SHAPå€¤ã§ç‰¹å¾´é‡ã®å¯„ä¸åº¦ã‚’å¯è¦–åŒ–\")\n",
    "    steps.append(\"     - èª¤åˆ†é¡ã‚±ãƒ¼ã‚¹ã®å‚¾å‘åˆ†æ\")\n",
    "    steps.append(\"  â‘¡ ç‰¹å¾´é‡ã®è¿½åŠ ç”Ÿæˆ\")\n",
    "    steps.append(\"     - äº¤äº’ä½œç”¨é …ã®è¿½åŠ \")\n",
    "    steps.append(\"     - æ™‚é–“å¸¯åˆ¥ã®ç‰¹å¾´é‡\")\n",
    "    steps.append(\"  â‘¢ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¾®èª¿æ•´\")\n",
    "    steps.append(\"     - è©¦è¡Œå›æ•°ã‚’2000å›ä»¥ä¸Šã«å¢—åŠ \")\n",
    "    \n",
    "    steps.append(\"\\nã€Phase 2: ä¸­æœŸæ”¹å–„ï¼ˆ2-4é€±é–“ï¼‰ã€‘\")\n",
    "    steps.append(\"  â‘  ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã®å®Ÿè£…\")\n",
    "    steps.append(\"     - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ä»˜ã‘å¹³å‡\")\n",
    "    steps.append(\"     - Stackingã«ã‚ˆã‚‹2æ®µéšå­¦ç¿’\")\n",
    "    steps.append(\"  â‘¡ ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å°å…¥\")\n",
    "    steps.append(\"     - æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“è»¸åˆ†å‰²CV\")\n",
    "    steps.append(\"     - K-fold CVçµæœã®çµ±è¨ˆæ¤œå®š\")\n",
    "    steps.append(\"  â‘¢ æœ¬ç•ªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰\")\n",
    "    steps.append(\"     - è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»å‰å‡¦ç†\")\n",
    "    steps.append(\"     - å®šæœŸçš„ãªå†è¨“ç·´ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°\")\n",
    "    \n",
    "    steps.append(\"\\nã€Phase 3: é•·æœŸå±•æœ›ï¼ˆ1ãƒ¶æœˆä»¥ä¸Šï¼‰ã€‘\")\n",
    "    steps.append(\"  â‘  Deep Learningã®æ¤œè¨\")\n",
    "    steps.append(\"     - LSTM/GRUã«ã‚ˆã‚‹æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\")\n",
    "    steps.append(\"     - AutoML(AutoKerasç­‰)ã«ã‚ˆã‚‹è‡ªå‹•æ¢ç´¢\")\n",
    "    steps.append(\"  â‘¡ ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’\")\n",
    "    steps.append(\"     - TOP1, TOP2, ãƒ©ãƒ³ã‚¯å­¦ç¿’ã‚’çµ±åˆ\")\n",
    "    steps.append(\"  â‘¢ èª¬æ˜å¯èƒ½AIã®å¼·åŒ–\")\n",
    "    steps.append(\"     - ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ§‹ç¯‰\")\n",
    "    steps.append(\"     - äºˆæ¸¬æ ¹æ‹ ã®è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\")\n",
    "    \n",
    "    steps.append(\"\\n\" + \"=\"*100)\n",
    "    \n",
    "    return \"\\n\".join(steps)\n",
    "\n",
    "# ============================================================\n",
    "# (4) å®Ÿè¡Œãƒ»è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"(F) ã¾ã¨ã‚ãƒ»æ”¹å–„ææ¡ˆ\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# å®Ÿé¨“ç·æ‹¬\n",
    "summary = generate_experiment_summary(experiment_results)\n",
    "print(summary)\n",
    "\n",
    "# æ”¹å–„ææ¡ˆ\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ğŸ’¡ æ”¹å–„ææ¡ˆ\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "suggester = ImprovementSuggester()\n",
    "suggestions = suggester.suggest_improvements(experiment_results)\n",
    "\n",
    "for category, suggestion_list in suggestions.items():\n",
    "    print(f\"\\nã€{category}ã€‘\")\n",
    "    for i, suggestion in enumerate(suggestion_list, 1):\n",
    "        print(f\"  {i}. {suggestion}\")\n",
    "\n",
    "# æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ\n",
    "next_steps = generate_next_steps(experiment_results)\n",
    "print(next_steps)\n",
    "\n",
    "# æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… åˆ†æå®Œäº†\")\n",
    "print(\"=\"*100)\n",
    "print(\"\"\"\n",
    "ã€å®Œæˆã—ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ã¤ã„ã¦ã€‘\n",
    "  ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ãƒ‘ãƒã‚¹ãƒ­ã®æœ«å°¾æ•°å­—ã¨ãƒ©ãƒ³ã‚¯äºˆæ¸¬ã«ã¤ã„ã¦ã€\n",
    "  è¤‡æ•°ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’çµ±ä¸€çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§è©•ä¾¡ã—ã¾ã—ãŸã€‚\n",
    "  \n",
    "ã€ä¸»ãªæˆæœã€‘\n",
    "  âœ“ çµ±ä¸€çµæœãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆUnifiedModelResultï¼‰ã®ç¢ºç«‹\n",
    "  âœ“ å…±é€šè©•ä¾¡é–¢æ•°ã¨åˆ©ç›Šåˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè£…\n",
    "  âœ“ æ¬¡å›äºˆæ¸¬ã¨æ¨å¥¨ã‚¨ãƒ³ã‚¸ãƒ³ã®æ§‹ç¯‰\n",
    "  âœ“ åŒ…æ‹¬çš„ãªå¯è¦–åŒ–ã¨çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½\n",
    "  \n",
    "ã€ä»Šå¾Œã®æ´»ç”¨ã€‘\n",
    "  æ–°ãŸãªãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ã‚„ç‰¹å¾´é‡ã®æ”¹å–„ãŒã‚ã‚Œã°ã€\n",
    "  ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å†å®Ÿè¡Œã™ã‚‹ã“ã¨ã§å®¹æ˜“ã«æ”¹å–„ã‚’æ¤œè¨¼ã§ãã¾ã™ã€‚\n",
    "  \n",
    "  å®šæœŸçš„ãªãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ã¨ãƒ‰ãƒªãƒ•ãƒˆç›£è¦–ã«ã‚ˆã‚Šã€\n",
    "  ç¶™ç¶šçš„ãªæ€§èƒ½ç¶­æŒãŒæœŸå¾…ã§ãã¾ã™ã€‚\n",
    "\n",
    "ã€ã‚µãƒãƒ¼ãƒˆã€‘\n",
    "  è³ªå•ã‚„æ”¹å–„ææ¡ˆã¯ã€Notebookã®ã‚³ãƒ¡ãƒ³ãƒˆæ¬„ã¾ãŸã¯\n",
    "  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… ã‚»ãƒ«29: ã¾ã¨ã‚ãƒ»æ”¹å–„ææ¡ˆ å®Ÿè£…å®Œäº†\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«20: ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œæŸ»ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«20ã€‘ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œæŸ»ï¼‰\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================\n",
    "# 1. BASELINEå›å¸°ç‰ˆã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nâœ… BASELINEå›å¸°ç‰ˆã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ç¢ºèª\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "completed_events = [e for e in rank_baseline_results if rank_baseline_results[e] is not None]\n",
    "print(f\"å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(completed_events)}/{len(test_events)}\")\n",
    "\n",
    "if len(completed_events) == 0:\n",
    "    print(\"âŒ BASELINEå›å¸°ç‰ˆã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    raise ValueError(\"ã‚»ãƒ«18ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "\n",
    "# ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’é›†è¨ˆ\n",
    "feature_importance_all = {}\n",
    "\n",
    "# ============================================================\n",
    "# 2. ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã«ç‰¹å¾´é‡é‡è¦åº¦ã‚’æŠ½å‡º\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã«ç‰¹å¾´é‡é‡è¦åº¦ã‚’æŠ½å‡º\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for event in completed_events:\n",
    "    result = rank_baseline_results[event]\n",
    "    model = result['model']\n",
    "    selected_features = result['selected_features']\n",
    "    model_name = result['model_name']\n",
    "    \n",
    "    print(f\"\\nã€{event.upper()}ã€‘\")\n",
    "    print(f\"  ãƒ¢ãƒ‡ãƒ«: {model_name}\")\n",
    "    print(f\"  ç‰¹å¾´é‡æ•°: {len(selected_features)}\")\n",
    "    \n",
    "    # ç‰¹å¾´é‡é‡è¦åº¦ã®æŠ½å‡º\n",
    "    if model_name == 'RandomForest':\n",
    "        # RandomForestã®å ´åˆ\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance_dict = dict(zip(selected_features, importances))\n",
    "        \n",
    "        print(f\"  é‡è¦åº¦ã‚¿ã‚¤ãƒ—: RandomForest feature_importances\")\n",
    "    \n",
    "    else:  # Ridge\n",
    "        # Ridgeã®å ´åˆã¯ä¿‚æ•°ã®çµ¶å¯¾å€¤ã‚’ä½¿ç”¨\n",
    "        importances = np.abs(model.coef_)\n",
    "        feature_importance_dict = dict(zip(selected_features, importances))\n",
    "        \n",
    "        print(f\"  é‡è¦åº¦ã‚¿ã‚¤ãƒ—: Ridge coefficient (absolute value)\")\n",
    "    \n",
    "    # æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«ï¼‰\n",
    "    max_importance = max(importances) if len(importances) > 0 else 1.0\n",
    "    if max_importance > 0:\n",
    "        feature_importance_dict = {k: v / max_importance for k, v in feature_importance_dict.items()}\n",
    "    \n",
    "    feature_importance_all[event] = feature_importance_dict\n",
    "    \n",
    "    # TOP10ã®é‡è¦åº¦ã‚’è¡¨ç¤º\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"  TOP10ç‰¹å¾´é‡:\")\n",
    "    for i, (feat, importance) in enumerate(sorted_features[:10], 1):\n",
    "        print(f\"    {i:2d}. {feat:40s}: {importance:.6f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. å…¨ã‚¤ãƒ™ãƒ³ãƒˆé›†è¨ˆã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€å…¨ã‚¤ãƒ™ãƒ³ãƒˆé›†è¨ˆ: ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "# ã™ã¹ã¦ã®ã‚¤ãƒ™ãƒ³ãƒˆã§ç™»å ´ã—ãŸç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’é›†è¨ˆ\n",
    "feature_importance_aggregated = {}\n",
    "\n",
    "for event, feature_dict in feature_importance_all.items():\n",
    "    for feature, importance in feature_dict.items():\n",
    "        if feature not in feature_importance_aggregated:\n",
    "            feature_importance_aggregated[feature] = []\n",
    "        feature_importance_aggregated[feature].append(importance)\n",
    "\n",
    "# å¹³å‡é‡è¦åº¦ã‚’è¨ˆç®—\n",
    "feature_importance_mean = {}\n",
    "for feature, importances in feature_importance_aggregated.items():\n",
    "    feature_importance_mean[feature] = {\n",
    "        'mean': np.mean(importances),\n",
    "        'std': np.std(importances),\n",
    "        'count': len(importances),\n",
    "        'max': np.max(importances),\n",
    "        'min': np.min(importances)\n",
    "    }\n",
    "\n",
    "# ã‚½ãƒ¼ãƒˆ\n",
    "sorted_features_global = sorted(\n",
    "    feature_importance_mean.items(),\n",
    "    key=lambda x: x[1]['mean'],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# TOP50ã‚’è¡¨ç¤º\n",
    "print(f\"\\nã€TOP50ç‰¹å¾´é‡ï¼ˆå¹³å‡é‡è¦åº¦ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰ã€‘\\n\")\n",
    "print(f\"{'Rank':5s} {'ç‰¹å¾´é‡å':45s} {'å¹³å‡':10s} {'æ¨™æº–åå·®':10s} {'ç™»å ´æ•°':8s} {'æœ€å¤§':10s}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "top50_features = sorted_features_global[:50]\n",
    "for rank, (feature, stats) in enumerate(top50_features, 1):\n",
    "    print(f\"{rank:5d}  {feature:45s}  {stats['mean']:10.6f}  {stats['std']:10.6f}  {stats['count']:8d}  {stats['max']:10.6f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ç–‘ã„ã®ã‚ã‚‹ç‰¹å¾´é‡ã®æ¤œæŸ»\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ç–‘ã„ã®ã‚ã‚‹ç‰¹å¾´é‡ã®æ¤œæŸ»ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "# ãƒªãƒ¼ã‚¯ç–‘ã„ç‰¹å¾´é‡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n",
    "leak_keywords = [\n",
    "    'rank',           # ãƒ©ãƒ³ã‚¯é–¢é€£\n",
    "    'digit',          # æœ«å°¾æ•°å­—é–¢é€£\n",
    "    'last_',          # æœ€æ–°å€¤\n",
    "    'prev_',          # å‰æ—¥å€¤\n",
    "    'current_',       # ç¾åœ¨å€¤\n",
    "    'target',         # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ\n",
    "    'label',          # ãƒ©ãƒ™ãƒ«\n",
    "    'y_',             # ç›®çš„å¤‰æ•°\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ” ãƒªãƒ¼ã‚¯ç–‘ã„ã®ã‚ã‚‹ç‰¹å¾´é‡:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "leak_suspected = []\n",
    "for rank, (feature, stats) in enumerate(top50_features, 1):\n",
    "    is_suspicious = False\n",
    "    suspicious_keywords = []\n",
    "    \n",
    "    for keyword in leak_keywords:\n",
    "        if keyword.lower() in feature.lower():\n",
    "            is_suspicious = True\n",
    "            suspicious_keywords.append(keyword)\n",
    "    \n",
    "    if is_suspicious:\n",
    "        leak_suspected.append({\n",
    "            'rank': rank,\n",
    "            'feature': feature,\n",
    "            'mean': stats['mean'],\n",
    "            'keywords': suspicious_keywords\n",
    "        })\n",
    "        print(f\"  âš ï¸  #{rank} {feature:45s} | ç–‘ã„: {', '.join(suspicious_keywords)}\")\n",
    "\n",
    "if len(leak_suspected) == 0:\n",
    "    print(\"  âœ… TOP50ã«ãƒªãƒ¼ã‚¯ç–‘ã„ã®ã‚ã‚‹ç‰¹å¾´é‡ã¯è¦‹å½“ãŸã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€TOP50ç‰¹å¾´é‡ã®ã‚«ãƒ†ã‚´ãƒªåˆ†æã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "# ç‰¹å¾´é‡åã‹ã‚‰æ¥é ­è¾ãƒ»ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡º\n",
    "feature_categories = {}\n",
    "\n",
    "for feature, stats in top50_features:\n",
    "    # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã§åˆ†å‰²\n",
    "    parts = feature.split('_')\n",
    "    \n",
    "    if len(parts) > 0:\n",
    "        # æœ€åˆã®éƒ¨åˆ†ã‚’ã‚«ãƒ†ã‚´ãƒªã¨ã™ã‚‹\n",
    "        category = parts[0]\n",
    "    else:\n",
    "        category = 'unknown'\n",
    "    \n",
    "    if category not in feature_categories:\n",
    "        feature_categories[category] = []\n",
    "    \n",
    "    feature_categories[category].append({\n",
    "        'feature': feature,\n",
    "        'mean': stats['mean']\n",
    "    })\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®é›†è¨ˆ\n",
    "print(\"\\nç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†å¸ƒ:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "category_stats = []\n",
    "for category in sorted(feature_categories.keys()):\n",
    "    features = feature_categories[category]\n",
    "    mean_importance = np.mean([f['mean'] for f in features])\n",
    "    count = len(features)\n",
    "    \n",
    "    category_stats.append({\n",
    "        'category': category,\n",
    "        'count': count,\n",
    "        'mean_importance': mean_importance\n",
    "    })\n",
    "\n",
    "# ã‚½ãƒ¼ãƒˆï¼ˆã‚«ã‚¦ãƒ³ãƒˆé †ï¼‰\n",
    "category_stats.sort(key=lambda x: x['count'], reverse=True)\n",
    "\n",
    "for cat_stat in category_stats:\n",
    "    print(f\"  {cat_stat['category']:20s}: {cat_stat['count']:3d}å€‹ (å¹³å‡é‡è¦åº¦: {cat_stat['mean_importance']:.6f})\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. æœ€é‡è¦ç‰¹å¾´é‡ã®è©³ç´°æƒ…å ±\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€æœ€é‡è¦TOP10ç‰¹å¾´é‡ã®è©³ç´°æƒ…å ±ã€‘\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "for rank, (feature, stats) in enumerate(top50_features[:10], 1):\n",
    "    print(f\"#{rank}: {feature}\")\n",
    "    print(f\"     å¹³å‡é‡è¦åº¦:  {stats['mean']:.6f}\")\n",
    "    print(f\"     æ¨™æº–åå·®:    {stats['std']:.6f}\")\n",
    "    print(f\"     ç™»å ´ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {stats['count']}/{len(completed_events)}\")\n",
    "    print(f\"     æœ€å¤§å€¤:      {stats['max']:.6f}\")\n",
    "    print(f\"     æœ€å°å€¤:      {stats['min']:.6f}\")\n",
    "    \n",
    "    # ç™»å ´ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¡¨ç¤º\n",
    "    appearing_events = [e for e in completed_events if feature in feature_importance_all[e]]\n",
    "    print(f\"     ç™»å ´ã‚¤ãƒ™ãƒ³ãƒˆ: {', '.join(appearing_events)}\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# 7. çµæœã‚’DataFrameã§ä¿å­˜\n",
    "# ============================================================\n",
    "\n",
    "top50_df = pd.DataFrame([\n",
    "    {\n",
    "        'Rank': rank,\n",
    "        'Feature': feature,\n",
    "        'å¹³å‡é‡è¦åº¦': stats['mean'],\n",
    "        'æ¨™æº–åå·®': stats['std'],\n",
    "        'ç™»å ´æ•°': stats['count'],\n",
    "        'æœ€å¤§å€¤': stats['max'],\n",
    "        'æœ€å°å€¤': stats['min'],\n",
    "        'ãƒªãƒ¼ã‚¯ç–‘ã„': 'ã¯ã„' if any(kw.lower() in feature.lower() for kw in leak_keywords) else 'ã„ã„ãˆ'\n",
    "    }\n",
    "    for rank, (feature, stats) in enumerate(top50_features[:50], 1)\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# 8. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['feature_importance_all'] = feature_importance_all\n",
    "globals()['feature_importance_aggregated'] = feature_importance_aggregated\n",
    "globals()['feature_importance_mean'] = feature_importance_mean\n",
    "globals()['top50_df'] = top50_df\n",
    "globals()['feature_categories'] = feature_categories\n",
    "\n",
    "# ============================================================\n",
    "# 9. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"âœ… ã‚»ãƒ«20: ç‰¹å¾´é‡é‡è¦åº¦åˆ†æå®Œäº†\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ä¿å­˜ã•ã‚ŒãŸå¤‰æ•°:\")\n",
    "print(f\"  â€¢ feature_importance_all: ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã®ç‰¹å¾´é‡é‡è¦åº¦\")\n",
    "print(f\"  â€¢ feature_importance_mean: å…¨ã‚¤ãƒ™ãƒ³ãƒˆé›†è¨ˆã®çµ±è¨ˆæƒ…å ±\")\n",
    "print(f\"  â€¢ top50_df: TOP50ç‰¹å¾´é‡ã®DataFrame\")\n",
    "print(f\"  â€¢ feature_categories: ã‚«ãƒ†ã‚´ãƒªåˆ¥ç‰¹å¾´é‡åˆ†é¡\")\n",
    "\n",
    "print(f\"\\nâš ï¸  ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œæŸ»:\")\n",
    "print(f\"  â€¢ ãƒªãƒ¼ã‚¯ç–‘ã„ã®ã‚ã‚‹ç‰¹å¾´é‡: {len(leak_suspected)}å€‹\")\n",
    "if len(leak_suspected) > 0:\n",
    "    print(f\"  â€¢ æœ€ã‚‚ç–‘ã‚ã—ã„ç‰¹å¾´é‡: {leak_suspected[0]['feature']} (#{leak_suspected[0]['rank']})\")\n",
    "\n",
    "print(f\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "print(f\"  1. top50_df ã‚’ç¢ºèªã—ã¦ã€ç–‘ã‚ã—ã„ç‰¹å¾´é‡ã‚’ç‰¹å®š\")\n",
    "print(f\"  2. ã‚»ãƒ«21ã§è©³ç´°ãªãƒªãƒ¼ã‚¯æ¤œæŸ»ã‚’å®Ÿæ–½\")\n",
    "print(f\"  3. å¿…è¦ã«å¿œã˜ã¦ç‰¹å¾´é‡ã‚’é™¤å¤–ã—ã¦å†å­¦ç¿’\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«23: max_games/min_gamesã¨prev_ç³»ç‰¹å¾´é‡ã®æ¤œæŸ»\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«23ã€‘max_games/min_gamesã¨prev_ç³»ç‰¹å¾´é‡ã®æ¤œæŸ»\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================\n",
    "# 1. max_games, min_games ã®å•é¡Œæ¤œæŸ»\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€å•é¡Œ1ã€‘max_games, min_games ã¯å½“æ—¥ã®æƒ…å ±ã‹ï¼Ÿ\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "âš ï¸  CRITICAL ISSUE FOUND!\n",
    "\n",
    "ã€max_games, min_gamesã®å®šç¾©ã€‘\n",
    "  max_games: å½“æ—¥ã®11å°ï¼ˆæœ«å°¾0-10ï¼‰ã®ä¸­ã§ã€Œã‚²ãƒ¼ãƒ æ•°ãŒæœ€å¤§ã ã£ãŸå°ã€ã®Gæ•°\n",
    "  min_games: å½“æ—¥ã®11å°ï¼ˆæœ«å°¾0-10ï¼‰ã®ä¸­ã§ã€Œã‚²ãƒ¼ãƒ æ•°ãŒæœ€å°ã ã£ãŸå°ã€ã®Gæ•°\n",
    "\n",
    "ã€å•é¡Œç‚¹ã€‘\n",
    "  âœ… max_games, min_games ã¯ã€Œå½“æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã€ã§ã™\n",
    "  âœ… ã“ã‚Œã‚‰ã¯å½“æ—¥11è¡Œã™ã¹ã¦ã§ã€ŒåŒã˜å€¤ã€ã«ãªã‚Šã¾ã™\n",
    "  \n",
    "  ä¾‹:\n",
    "    æ—¥ä»˜ = 2025-01-15, æœ«å°¾0ã®ã¨ãã®max_games = 2856\n",
    "    æ—¥ä»˜ = 2025-01-15, æœ«å°¾1ã®ã¨ãã®max_games = 2856  ï¼ˆåŒã˜å€¤ï¼‰\n",
    "    æ—¥ä»˜ = 2025-01-15, æœ«å°¾2ã®ã¨ãã®max_games = 2856  ï¼ˆåŒã˜å€¤ï¼‰\n",
    "  \n",
    "  â†’ ã™ã¹ã¦ã®æœ«å°¾ã§åŒã˜å€¤ãŒé…ç½®ã•ã‚Œã‚‹\n",
    "  â†’ æœ«å°¾ã”ã¨ã®ãƒ©ãƒ³ã‚¯å·®ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ã¯æœ‰ç”¨ãªæƒ…å ±ã§ã¯ãªã„\n",
    "  \n",
    "ã€ãƒªãƒ¼ã‚¯ã®æœ‰ç„¡ã€‘\n",
    "  âœ… å‰æ—¥ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªã„ï¼ˆlagå‡¦ç†ã•ã‚Œã¦ã„ãªã„ï¼‰\n",
    "  âœ… å½“æ—¥ã®ç¢ºå®šå€¤ï¼ˆå–¶æ¥­çµ‚äº†å¾Œã«ç¢ºå®šï¼‰\n",
    "  âœ… ã“ã‚Œã¯ã€Œå½“æ—¥ãƒ‡ãƒ¼ã‚¿ã€ï¼ã€Œãƒªãƒ¼ã‚¯ã€ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„\n",
    "  \n",
    "ã€ä¿®æ­£æ–¹æ³•ã€‘\n",
    "  âŒ max_games, min_games ã‚’ç‰¹å¾´é‡ã‹ã‚‰é™¤å¤–ã™ã¹ã\n",
    "  âŒ ã¾ãŸã¯ã€lagå‡¦ç†ã—ã¦ã€Œå‰æ—¥ã®max_gamesã€ã¨ã—ã¦ä½¿ç”¨\n",
    "\"\"\")\n",
    "\n",
    "# ã‚»ãƒ«04ã®å®Ÿè£…ã‚’ç¢ºèª\n",
    "print(\"\\nã€ã‚»ãƒ«04ã§ã® max_games, min_games ã®å‡¦ç†ç¢ºèªã€‘\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# df_merged ã« max_games, min_games ãŒã‚ã‚‹ã‹ç¢ºèª\n",
    "if 'df_merged' in globals():\n",
    "    merged_cols = df_merged.columns.tolist()\n",
    "    \n",
    "    if 'max_games' in merged_cols:\n",
    "        print(\"âŒ max_games: å­˜åœ¨ï¼ˆç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ä¸­ï¼‰\")\n",
    "        \n",
    "        # ã‚µãƒ³ãƒ—ãƒ«æ¤œæŸ»\n",
    "        sample_date = sorted(df_merged['date_num'].unique())[2]\n",
    "        sample_data = df_merged[df_merged['date_num'] == sample_date]\n",
    "        \n",
    "        print(f\"\\n   ã‚µãƒ³ãƒ—ãƒ«æ¤œæŸ»ï¼ˆæ—¥ä»˜: {sample_date}ï¼‰:\")\n",
    "        print(f\"     è¡Œæ•°: {len(sample_data)}\")\n",
    "        print(f\"     max_gamesã®å€¤: {sample_data['max_games'].unique()}\")\n",
    "        print(f\"     â†’ ã™ã¹ã¦ã®æœ«å°¾ã§åŒã˜å€¤: {len(sample_data['max_games'].unique()) == 1}\")\n",
    "        \n",
    "        if len(sample_data['max_games'].unique()) == 1:\n",
    "            print(f\"\\n   âœ… ç¢ºèª: å½“æ—¥11è¡Œã™ã¹ã¦ã§ max_games = {sample_data['max_games'].iloc[0]}\")\n",
    "    \n",
    "    if 'min_games' in merged_cols:\n",
    "        print(\"\\nâŒ min_games: å­˜åœ¨ï¼ˆç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ä¸­ï¼‰\")\n",
    "        \n",
    "        # ã‚µãƒ³ãƒ—ãƒ«æ¤œæŸ»\n",
    "        sample_date = sorted(df_merged['date_num'].unique())[2]\n",
    "        sample_data = df_merged[df_merged['date_num'] == sample_date]\n",
    "        \n",
    "        print(f\"\\n   ã‚µãƒ³ãƒ—ãƒ«æ¤œæŸ»ï¼ˆæ—¥ä»˜: {sample_date}ï¼‰:\")\n",
    "        print(f\"     min_gamesã®å€¤: {sample_data['min_games'].unique()}\")\n",
    "        print(f\"     â†’ ã™ã¹ã¦ã®æœ«å°¾ã§åŒã˜å€¤: {len(sample_data['min_games'].unique()) == 1}\")\n",
    "        \n",
    "        if len(sample_data['min_games'].unique()) == 1:\n",
    "            print(f\"\\n   âœ… ç¢ºèª: å½“æ—¥11è¡Œã™ã¹ã¦ã§ min_games = {sample_data['min_games'].iloc[0]}\")\n",
    "else:\n",
    "    print(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚»ãƒ«04ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼‰\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. prev_ç³»ç‰¹å¾´é‡ã®å­˜åœ¨ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€å•é¡Œ2ã€‘prev_ç³»ç‰¹å¾´é‡ã¯ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if 'df_merged' in globals():\n",
    "    prev_cols = [col for col in df_merged.columns if col.startswith('prev_')]\n",
    "    \n",
    "    if len(prev_cols) > 0:\n",
    "        print(f\"âœ… prev_ç³»ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™\")\n",
    "        print(f\"\\n   ç·æ•°: {len(prev_cols)}å€‹\")\n",
    "        print(f\"\\n   ã‚µãƒ³ãƒ—ãƒ«ç‰¹å¾´é‡ï¼ˆæœ€åˆã®20å€‹ï¼‰:\")\n",
    "        for i, col in enumerate(prev_cols[:20], 1):\n",
    "            print(f\"     {i:2d}. {col}\")\n",
    "        \n",
    "        if len(prev_cols) > 20:\n",
    "            print(f\"     ... ä»–{len(prev_cols)-20}å€‹\")\n",
    "        \n",
    "        # prev_ç³»ç‰¹å¾´é‡ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡\n",
    "        prev_categories = {}\n",
    "        for col in prev_cols:\n",
    "            # prev_x_* ã‹ã‚‰ ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡º\n",
    "            parts = col.split('_')\n",
    "            if len(parts) >= 2:\n",
    "                category = '_'.join(parts[1:])  # prev_ã®å¾Œã‚\n",
    "                if category not in prev_categories:\n",
    "                    prev_categories[category] = []\n",
    "                prev_categories[category].append(col)\n",
    "        \n",
    "        print(f\"\\n   ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:\")\n",
    "        for category in sorted(prev_categories.keys())[:10]:\n",
    "            count = len(prev_categories[category])\n",
    "            print(f\"     â€¢ {category}: {count}å€‹\")\n",
    "        \n",
    "        if len(prev_categories) > 10:\n",
    "            print(f\"     ... ä»–{len(prev_categories)-10}å€‹ã‚«ãƒ†ã‚´ãƒª\")\n",
    "    \n",
    "    else:\n",
    "        print(\"âŒ PROBLEM: prev_ç³»ç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼\")\n",
    "        print(\"\\n   åŸå› ã®å¯èƒ½æ€§:\")\n",
    "        print(\"   1. ã‚»ãƒ«03ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„\")\n",
    "        print(\"   2. ã‚»ãƒ«03ã§ç‰¹å¾´é‡ç”Ÿæˆã«å¤±æ•—ã—ã¦ã„ã‚‹\")\n",
    "        print(\"   3. ã‚»ãƒ«05ã®ãƒãƒ¼ã‚¸å‡¦ç†ã§å‰Šé™¤ã•ã‚Œã¦ã—ã¾ã£ãŸ\")\n",
    "else:\n",
    "    print(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. ç‰¹å¾´é‡ã®å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒã‚§ãƒƒã‚¯ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if 'df_merged' in globals():\n",
    "    # å„ã‚«ãƒ†ã‚´ãƒªã®ç‰¹å¾´é‡æ•°\n",
    "    categories = {\n",
    "        'prev_': 'ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ç‰¹å¾´é‡ï¼ˆã‚»ãƒ«03ï¼‰',\n",
    "        'allday_': 'å…¨æ—¥ä»˜ãƒ©ã‚°ãƒ»ç§»å‹•å¹³å‡ç‰¹å¾´é‡ï¼ˆã‚»ãƒ«04-1, 04-2ï¼‰',\n",
    "        'distance_': 'è·é›¢ç‰¹å¾´é‡ï¼ˆã‚»ãƒ«04-3ï¼‰',\n",
    "        'match_': 'ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°ç‰¹å¾´é‡ï¼ˆã‚»ãƒ«04-3ï¼‰',\n",
    "    }\n",
    "    \n",
    "    print(\"\\nç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for prefix, description in categories.items():\n",
    "        cols = [col for col in df_merged.columns if col.startswith(prefix)]\n",
    "        status = \"âœ…\" if len(cols) > 0 else \"âŒ\"\n",
    "        print(f\"{status} {prefix:15s}: {len(cols):4d}å€‹  ({description})\")\n",
    "    \n",
    "    # ãã®ä»–ã®åˆ¤å®šç‰¹å¾´é‡\n",
    "    other_features = [\n",
    "        'is_weekday0', 'is_weekday1', 'is_weekday2', 'is_weekday3', 'is_weekday4',\n",
    "        'is_weekday5', 'is_weekday6', 'is_saturday', 'is_sunday', 'weekday_num',\n",
    "        'days_since_start', 'days_to_end', 'day_of_month',\n",
    "        'digit_num', 'last_digit'\n",
    "    ]\n",
    "    other_found = [col for col in other_features if col in df_merged.columns]\n",
    "    \n",
    "    print(f\"âœ… {'ãã®ä»–':15s}: {len(other_found):4d}å€‹  (æ›œæ—¥ãƒ»æ™‚ç³»åˆ—ãƒ»åŸºæœ¬å±æ€§)\")\n",
    "    \n",
    "    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°\n",
    "    is_cols = [col for col in df_merged.columns if col.startswith('is_')]\n",
    "    print(f\"âœ… {'is_*':15s}: {len(is_cols):4d}å€‹  (ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°)\")\n",
    "    \n",
    "    total_features = (\n",
    "        len([col for col in df_merged.columns if col.startswith('prev_')]) +\n",
    "        len([col for col in df_merged.columns if col.startswith('allday_')]) +\n",
    "        len([col for col in df_merged.columns if col.startswith('distance_')]) +\n",
    "        len([col for col in df_merged.columns if col.startswith('match_')]) +\n",
    "        len(other_found) +\n",
    "        len(is_cols)\n",
    "    )\n",
    "    \n",
    "    print(f\"-\" * 100)\n",
    "    print(f\"åˆè¨ˆç‰¹å¾´é‡: {total_features}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. æ¨å¥¨äº‹é …\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€æ¨å¥¨äº‹é …ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ”´ CRITICAL: max_games, min_games ã¯é™¤å¤–ã™ã¹ã\n",
    "\n",
    "ç†ç”±:\n",
    "  1. å½“æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚‹\n",
    "  2. ã™ã¹ã¦ã®æœ«å°¾è¡Œã§åŒã˜å€¤ï¼ˆæœ¬æ¥ã¯å€‹åˆ¥ã®å°ã®çµ±è¨ˆãªã®ã«å½“æ—¥ã«é›†ç´„ï¼‰\n",
    "  3. å‰æ—¥ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦lagå‡¦ç†ã•ã‚Œã¦ã„ãªã„\n",
    "  4. ãƒ©ãƒ³ã‚¯äºˆæ¸¬ã«ã¯ä¸è¦ãªæƒ…å ±\n",
    "\n",
    "å¯¾ç­–:\n",
    "  ã‚¹ãƒ†ãƒƒãƒ—1: ã‚»ãƒ«05ã§ max_games, min_games ã‚’é™¤å¤–\n",
    "    â†’ ç‰¹å¾´é‡ã® exclude_patterns ã«è¿½åŠ \n",
    "    \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—2: å¿…è¦ã«å¿œã˜ã¦ã€Œ1æ—¥å‰ã®max_gamesã€ã‚’ä½¿ç”¨\n",
    "    â†’ allday_lag1_max_games ã¨ã—ã¦æ–°è¦ä½œæˆ\n",
    "    â†’ ãŸã ã—ã€ã“ã‚ŒãŒæœ¬å½“ã«æœ‰ç”¨ã‹ã¯ç–‘å•\n",
    "  \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—3: ã‚»ãƒ«18ã§å†å­¦ç¿’\n",
    "    â†’ BASELINEç‰ˆã®ç²¾åº¦ãŒæ›´ã«å‘ä¸Šã™ã‚‹å¯èƒ½æ€§\n",
    "\n",
    "âœ… GOOD: prev_ç³»ç‰¹å¾´é‡ã¯å­˜åœ¨\n",
    "\n",
    "ç¢ºèª:\n",
    "  â€¢ prev_* ç‰¹å¾´é‡ã¯æ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹\n",
    "  â€¢ ã‚»ãƒ«03ã®å®Ÿè£…ã«å•é¡Œã¯ãªã„\n",
    "  â€¢ ã‚¤ãƒ™ãƒ³ãƒˆå±¥æ­´ãƒ‡ãƒ¼ã‚¿ã¯æ­£ç¢ºã«ä¿æŒã•ã‚Œã¦ã„ã‚‹\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… ã‚»ãƒ«23: max_games/min_gamesã¨prev_ç³»ç‰¹å¾´é‡ã®æ¤œæŸ»å®Œäº†\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®ã€‘\n",
    "\n",
    "å„ªå…ˆåº¦1 (ã™ãã«å®Ÿæ–½):\n",
    "  â˜ ã‚»ãƒ«05ã‚’ä¿®æ­£: max_games, min_gamesã‚’é™¤å¤–\n",
    "  â˜ ã‚»ãƒ«18ã§å†å­¦ç¿’ï¼ˆBASELINEç‰ˆï¼‰\n",
    "  â˜ ã‚»ãƒ«19ã§æ€§èƒ½æ¯”è¼ƒ\n",
    "\n",
    "å„ªå…ˆåº¦2 (æ¤œè¨¼å¿…è¦):\n",
    "  â˜ max_games, min_gamesé™¤å¤–å¾Œã®ç²¾åº¦å‘ä¸Šåº¦åˆã„ã‚’æ¸¬å®š\n",
    "  â˜ RMSE, RÂ²ã®æ”¹å–„ã‚’ç¢ºèª\n",
    "  \n",
    "å„ªå…ˆåº¦3 (å°†æ¥å¯¾å¿œ):\n",
    "  â˜ allday_lag1_max_games ã®æœ‰ç”¨æ€§ã‚’æ¤œè¨¼\n",
    "  â˜ TOP3ç‰ˆã®æ”¹è‰¯\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«21: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯è©³ç´°æ¤œæŸ»\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«21ã€‘ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯è©³ç´°æ¤œæŸ»\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================\n",
    "# 1. æ¤œæŸ»å¯¾è±¡ã®ç‰¹å¾´é‡ã‚’å®šç¾©\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nâœ… æ¤œæŸ»å¯¾è±¡ã®ç‰¹å¾´é‡ã‚’å®šç¾©\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# TOP50ã‹ã‚‰ç‰¹ã«ç–‘ã‚ã—ã„ç‰¹å¾´é‡ã‚’æŠ½å‡º\n",
    "suspicious_features = [\n",
    "    'allday_lag1_avg_diff_coins_pct',      # #1 æœ€é‡è¦\n",
    "    'allday_lag4_avg_diff_coins',          # #2\n",
    "    'allday_lag1_total_diff_coins_diff',   # #4 å…¨ã‚¤ãƒ™ãƒ³ãƒˆ\n",
    "    'allday_lag1_avg_diff_coins_diff',     # #5 å…¨ã‚¤ãƒ™ãƒ³ãƒˆ\n",
    "    'digit_num',                            # #38 å½“æ—¥ãƒ‡ãƒ¼ã‚¿ï¼Ÿ\n",
    "    'allday_best_rank_7d_last_digit_rank_efficiency',  # #46 last_digitä½¿ç”¨\n",
    "    'weekday_digit_interaction',           # #29 digitä½¿ç”¨\n",
    "]\n",
    "\n",
    "print(f\"æ¤œæŸ»å¯¾è±¡: {len(suspicious_features)}å€‹ã®ç‰¹å¾´é‡\")\n",
    "for feat in suspicious_features[:3]:\n",
    "    print(f\"  â€¢ {feat}\")\n",
    "print(f\"  ...\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. å„ã‚¤ãƒ™ãƒ³ãƒˆã§ã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡ºã—ã¦è©³ç´°æ¤œæŸ»\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æ¤œæŸ»ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "# æ¤œæŸ»å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã‚’é¸æŠ\n",
    "test_event = '1day'\n",
    "event_col = f'is_{test_event}'\n",
    "\n",
    "# ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º\n",
    "event_data_full = df_merged[df_merged[event_col] == 1].copy().sort_values('date_num')\n",
    "\n",
    "print(f\"\\nğŸ“Š æ¤œæŸ»å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆ: {test_event.upper()}\")\n",
    "print(f\"   ç·è¡Œæ•°: {len(event_data_full)}\")\n",
    "print(f\"   æ—¥ä»˜ç¯„å›²: {event_data_full['date_num'].min()} ï½ {event_data_full['date_num'].max()}\")\n",
    "print(f\"   ç†æƒ³çš„ãªè¡Œæ•°: {len(event_data_full['date_num'].unique())} æ—¥ Ã— 11 = {len(event_data_full['date_num'].unique()) * 11}\")\n",
    "\n",
    "# å„æ—¥ä»˜ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç¢ºèª\n",
    "date_counts = event_data_full['date_num'].value_counts().sort_index()\n",
    "print(f\"\\n   å„æ—¥ä»˜ã®ã‚µãƒ³ãƒ—ãƒ«æ•°:\")\n",
    "print(f\"      æœ€å°å€¤: {date_counts.min()}, æœ€å¤§å€¤: {date_counts.max()}, æ¨™æº–: {date_counts.mode().values[0] if len(date_counts.mode()) > 0 else 'N/A'}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. å„ç‰¹å¾´é‡ã®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’æ¤œæŸ»\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€ç‰¹å¾´é‡ã®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯æ¤œæŸ»ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "# ============================================================\n",
    "# ç‰¹å¾´é‡1: allday_lag1_avg_diff_coins_pct\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ç‰¹å¾´é‡1ã€‘allday_lag1_avg_diff_coins_pct\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "if 'allday_lag1_avg_diff_coins_pct' in event_data_full.columns:\n",
    "    feat = 'allday_lag1_avg_diff_coins_pct'\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«æ—¥ã‚’é¸æŠ\n",
    "    sample_dates = sorted(event_data_full['date_num'].unique())[2:5]\n",
    "    \n",
    "    for sample_date in sample_dates:\n",
    "        sample_data = event_data_full[event_data_full['date_num'] == sample_date].copy()\n",
    "        \n",
    "        if len(sample_data) > 0:\n",
    "            print(f\"\\n  æ—¥ä»˜: {sample_date} ({len(sample_data)}è¡Œ)\")\n",
    "            print(f\"    å€¤ã®ç¯„å›²: min={sample_data[feat].min():.6f}, max={sample_data[feat].max():.6f}\")\n",
    "            print(f\"    å€¤ãŒåŒã˜è¡Œæ•°: {(sample_data[feat] == sample_data[feat].iloc[0]).sum()}/{len(sample_data)}\")\n",
    "            \n",
    "            # å‰æ—¥ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª\n",
    "            prev_date = sample_date - 1\n",
    "            prev_data = event_data_full[event_data_full['date_num'] == prev_date]\n",
    "            \n",
    "            if len(prev_data) > 0:\n",
    "                print(f\"    âœ“ å‰æ—¥ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ ({prev_date}): {len(prev_data)}è¡Œ\")\n",
    "            else:\n",
    "                print(f\"    âœ— å‰æ—¥ãƒ‡ãƒ¼ã‚¿ãªã— ({prev_date})\")\n",
    "else:\n",
    "    print(\"  âœ— ã“ã®ç‰¹å¾´é‡ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# ç‰¹å¾´é‡2: digit_num (æœ«å°¾æ•°å­—ã‚’æ•°å€¤åŒ–ã—ãŸã‚‚ã®)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nã€ç‰¹å¾´é‡2ã€‘digit_num\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "if 'digit_num' in event_data_full.columns and 'last_digit' in event_data_full.columns:\n",
    "    feat = 'digit_num'\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«æ—¥ã‚’é¸æŠ\n",
    "    sample_date = sorted(event_data_full['date_num'].unique())[2]\n",
    "    sample_data = event_data_full[event_data_full['date_num'] == sample_date].copy()\n",
    "    \n",
    "    print(f\"\\n  ã‚µãƒ³ãƒ—ãƒ«æ—¥ä»˜: {sample_date}\")\n",
    "    print(f\"  è¡Œæ•°: {len(sample_data)}\")\n",
    "    \n",
    "    if len(sample_data) > 0:\n",
    "        print(f\"  digit_num ã®å€¤: {sorted(sample_data[feat].unique())}\")\n",
    "        print(f\"  last_digit ã®å€¤: {sorted(sample_data['last_digit'].unique())}\")\n",
    "        \n",
    "        # å½“æ—¥ã®æœ«å°¾æ•°å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "        print(f\"\\n  âš ï¸  digit_num ã¯ last_digit (å½“æ—¥ã®æœ«å°¾æ•°å­—) ã‹ã‚‰ç›´æ¥ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™\")\n",
    "        print(f\"      â†’ ã“ã‚Œã¯ã€Œå½“æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã€ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼\")\n",
    "else:\n",
    "    print(\"  âœ— ã“ã®ç‰¹å¾´é‡ã¾ãŸã¯last_digitãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ç‰¹å¾´é‡ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œæŸ»\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œæŸ»ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "print(\"\\nğŸ” æ¤œæŸ»å¯¾è±¡: allday_lag1_avg_diff_coins_pct\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "if 'allday_lag1_avg_diff_coins_pct' in event_data_full.columns:\n",
    "    feat = 'allday_lag1_avg_diff_coins_pct'\n",
    "    \n",
    "    # æ™‚ç³»åˆ—ã‚’ä¸¦ã¹ã¦è¡¨ç¤º\n",
    "    unique_dates = sorted(event_data_full['date_num'].unique())[:8]\n",
    "    \n",
    "    print(f\"\\næ—¥ä»˜ã”ã¨ã®ç‰¹å¾´é‡ã®å€¤ï¼ˆå…¨è¡ŒãŒåŒã˜å€¤ã‹ç¢ºèªï¼‰:\")\n",
    "    print(f\"{'æ—¥ä»˜':8s} {'å€¤ã®çµ±è¨ˆ':50s} {'å…¨è¡ŒåŒä¸€':10s}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for date in unique_dates:\n",
    "        date_data = event_data_full[event_data_full['date_num'] == date]\n",
    "        values = date_data[feat].values\n",
    "        \n",
    "        all_same = len(set(values)) == 1\n",
    "        value_str = f\"min={values.min():.4f}, max={values.max():.4f}, std={values.std():.4f}\"\n",
    "        \n",
    "        print(f\"{date:8.0f}  {value_str:50s}  {'âœ“Yes' if all_same else 'âœ—No':10s}\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸  è§£é‡ˆ:\")\n",
    "    print(f\"  â€¢ å…¨è¡ŒãŒåŒã˜å€¤ = å½“æ—¥ã®ã™ã¹ã¦ã®11è¡Œã§åŒã˜å€¤ = å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„å€¤\")\n",
    "    print(f\"  â€¢ ã¤ã¾ã‚Šã€Œlag1 = 1æ—¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã€ã§ã‚ã£ã¦ã‚‚ã€å½“æ—¥11è¡Œã™ã¹ã¦ãŒåŒã˜å€¤\")\n",
    "    print(f\"    â†’ å½“æ—¥ã®æœ€çµ‚çµæœã‚’äºˆæ¸¬ã«ä½¿ã£ã¦ã„ã‚‹ = ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ç›®çš„å¤‰æ•°ã¨ã®é–¢ä¿‚ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€ç›®çš„å¤‰æ•°ã¨ã®é–¢ä¿‚ç¢ºèªã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "if 'last_digit_rank_diff' in event_data_full.columns and 'allday_lag1_avg_diff_coins_pct' in event_data_full.columns:\n",
    "    feat = 'allday_lag1_avg_diff_coins_pct'\n",
    "    target = 'last_digit_rank_diff'\n",
    "    \n",
    "    sample_date = sorted(event_data_full['date_num'].unique())[3]\n",
    "    date_data = event_data_full[event_data_full['date_num'] == sample_date].copy()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ«æ—¥ä»˜: {sample_date}\")\n",
    "    print(f\"   ç‰¹å¾´é‡å€¤ã¨ç›®çš„å¤‰æ•°ã®é–¢ä¿‚:\")\n",
    "    print(f\"{'é †ä½':6s} {feat[:40]:40s} {target:20s}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    date_data_sorted = date_data.sort_values(target)\n",
    "    \n",
    "    for i, (_, row) in enumerate(date_data_sorted.head(11).iterrows(), 1):\n",
    "        feat_val = row.get(feat, np.nan)\n",
    "        target_val = row.get(target, np.nan)\n",
    "        \n",
    "        print(f\"{i:6d}  {feat_val:40.6f}  {target_val:20.1f}\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸  è§£é‡ˆ:\")\n",
    "    print(f\"  â€¢ ç‰¹å¾´é‡å€¤ãŒã™ã¹ã¦åŒã˜ = lag1ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚å½“æ—¥ã®å¤‰å‹•ãŒãªã„\")\n",
    "    print(f\"  â€¢ ç›®çš„å¤‰æ•°ã¯1ï½11ã§å¤‰å‹• = ãƒ©ãƒ³ã‚¯äºˆæ¸¬\")\n",
    "    print(f\"  â€¢ ã€Œå‰æ—¥ã®å¹³å‡ã‚³ã‚¤ãƒ³å·®ã€ã§ã¯ã€Œå½“æ—¥ã®ãƒ©ãƒ³ã‚¯ã€ãŒäºˆæ¸¬ã§ãã‚‹ã¯ãš\")\n",
    "    print(f\"    â†’ è«–ç†çš„ã«ã¯é–¢ä¿‚ãŒãªã„ã¯ãšã ãŒã€é«˜ç²¾åº¦ã¨ã„ã†çŸ›ç›¾\")\n",
    "    print(f\"    â†’ ç‰¹å¾´é‡ç”Ÿæˆæ™‚ã«å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãŒæ··å…¥ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ï¼\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. ç‰¹å¾´é‡ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®ä»•æ§˜ã‚’æ¨å®š\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€ç‰¹å¾´é‡ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®ä»•æ§˜æ¨å®šã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "print(\"\\nğŸ” allday_lag*_* ç‰¹å¾´é‡ã®å•é¡Œç‚¹:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "print(\"\\nç¾åœ¨ã®å®Ÿè£…ï¼ˆæ¨å®šï¼‰:\")\n",
    "print(\"\"\"\n",
    "  for lag_day in [1, 4, 7, ...]:\n",
    "      lag_col = f'allday_lag{lag_day}_{target_col}'\n",
    "      df_out[lag_col] = df_out['date'].shift(lag_day)  # lag_dayã®å‰å¾Œã§è¡Œã‚’ç§»å‹•\n",
    "      \n",
    "  å•é¡Œ: shift() ã¯è¡Œã‚’ã‚·ãƒ•ãƒˆã™ã‚‹ã ã‘ã§ã€æ—¥ä»˜å˜ä½ã§ã¯ã‚·ãƒ•ãƒˆã—ã¦ã„ãªã„\n",
    "        â†’ 1æ—¥ = è¤‡æ•°è¡Œï¼ˆ11è¡Œï¼‰ã‚ã‚‹ãŸã‚ã€å˜ç´”ãªè¡Œã‚·ãƒ•ãƒˆã§ã¯ãƒ‡ãƒ¼ã‚¿ãŒæ··åœ¨\n",
    "        â†’ å½“æ—¥ã¨å‰æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒæ··ã–ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nç†æƒ³çš„ãªå®Ÿè£…:\")\n",
    "print(\"\"\"\n",
    "  1. æ—¥ä»˜ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–\n",
    "  2. å„æ—¥ä»˜ã”ã¨ã«é›†ç´„å€¤ã‚’è¨ˆç®—\n",
    "  3. æ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã§labã‚’é©ç”¨\n",
    "  4. å…ƒã®è¡Œæ•°ï¼ˆ11è¡Œï¼‰ã«å¾©å…ƒï¼ˆffillç­‰ã§åŸ‹ã‚ã‚‹ï¼‰\n",
    "  \n",
    "  ãŸã ã—ã€ç¾åœ¨ã®BASELINEç‰¹å¾´é‡ã¯ç•°ãªã‚‹ä»•æ§˜ã®å¯èƒ½æ€§ãŒã‚ã‚‹\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ”´ CRITICAL: é«˜ç¢ºç‡ã§ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™\n",
    "\n",
    "ç†ç”±:\n",
    "  1. TOP50ç‰¹å¾´é‡ã®43å€‹ãŒç–‘ã‚ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€\n",
    "  2. allday_lag1_* ç‰¹å¾´é‡ãŒå½“æ—¥11è¡Œã™ã¹ã¦ã§åŒã˜å€¤\n",
    "  3. digit_num ãŒ last_digit ã‹ã‚‰ç›´æ¥ç”Ÿæˆï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿ï¼‰\n",
    "  4. éå¸¸ã«é«˜ã„äºˆæ¸¬ç²¾åº¦ï¼ˆRMSE=2.14, RÂ²=0.54ï¼‰ãŒèª¬æ˜ã§ããªã„\n",
    "\n",
    "æ¨å¥¨ã•ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:\n",
    "  \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—1: ç‰¹å¾´é‡ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’å¾¹åº•æ¤œæŸ»\n",
    "    â†’ ã‚»ãƒ«04-2, ã‚»ãƒ«04-3 ã‚ãŸã‚Šã§ç‰¹å¾´é‡ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¢ºèª\n",
    "    â†’ æ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã®lagå‡¦ç†ãŒæ­£ã—ãå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "    \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—2: å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã®é™¤å¤–ç¢ºèª\n",
    "    â†’ æœ«å°¾æ•°å­—ï¼ˆdigit_numï¼‰ã¯å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚é™¤å¤–\n",
    "    â†’ å½“æ—¥ã®åŠ¹ç‡å€¤ã€ã‚²ãƒ¼ãƒ æ•°ç­‰ã‚‚é™¤å¤–æ¤œè¨\n",
    "    \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—3: ç‰¹å¾´é‡ã®å†ç”Ÿæˆ\n",
    "    â†’ æ—¥ä»˜å˜ä½ã§ã®lagå‡¦ç†ã‚’å³å¯†ã«å®Ÿè£…\n",
    "    â†’ å½“æ—¥ = äºˆæ¸¬å¯¾è±¡ã§ã‚ã‚Šã€ç‰¹å¾´é‡ã«å«ã¾ã‚Œã‚‹ã¹ãã§ã¯ãªã„\n",
    "    \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡é™¤å¤–ãƒªã‚¹ãƒˆã®ä½œæˆ\n",
    "    â†’ ã‚»ãƒ«11Rã§æ¤œå‡ºã•ã‚ŒãŸã€Œç–‘ã‚ã—ã„ç‰¹å¾´é‡ã€ã‚’é™¤å¤–\n",
    "    â†’ ã‚¯ãƒªãƒ¼ãƒ³ãªç‰¹å¾´é‡ã®ã¿ã§å†å­¦ç¿’\n",
    "\n",
    "ã‚¹ãƒ†ãƒƒãƒ—5: å†å­¦ç¿’å¾Œã®æ€§èƒ½ç¢ºèª\n",
    "    â†’ RMSE, RÂ², Spearman ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã‚’äºˆæœŸ\n",
    "    â†’ ãƒªã‚¢ãƒ«ãªäºˆæ¸¬ç²¾åº¦ãŒå¾—ã‚‰ã‚Œã‚‹\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['suspicious_features'] = suspicious_features\n",
    "\n",
    "# ============================================================\n",
    "# 9. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"âœ… ã‚»ãƒ«21: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯è©³ç´°æ¤œæŸ»å®Œäº†\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "print(f\"\\nâš ï¸  çµè«–:\")\n",
    "print(f\"   ã€ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§: éå¸¸ã«é«˜ã„ã€‘\")\n",
    "print(f\"\\n   æ¬¡ã®ã‚»ãƒ«22ã§ç‰¹å¾´é‡ã‹ã‚‰ç–‘ã‚ã—ã„ç‰¹å¾´é‡ã‚’é™¤å¤–ã—ã¦å†å­¦ç¿’ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«22: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯åŸå› åˆ†æã®ç·æ‹¬\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ã‚»ãƒ«22ã€‘ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯åŸå› åˆ†æã®ç·æ‹¬\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================\n",
    "# 1. ç‰¹å¾´é‡ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®å†æ¤œè¨¼\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ç‰¹å¾´é‡ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®å†æ¤œè¨¼ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "âœ… ã‚»ãƒ«04-1ã®å®Ÿè£…ç¢ºèª\n",
    "\n",
    "ã€ãƒ©ã‚°å‡¦ç†ã€‘\n",
    "  ã‚³ãƒ¼ãƒ‰:\n",
    "    shift_amount = lag_day * 11\n",
    "    df_out.groupby('digit_num')[target_col].shift(shift_amount)\n",
    "  \n",
    "  æ„å‘³:\n",
    "    â€¢ 1æ—¥ = 11è¡Œï¼ˆæœ«å°¾0-10ã®11å°ï¼‰\n",
    "    â€¢ lag_dayæ—¥å‰ã‚’å–å¾—ã™ã‚‹ãŸã‚ shift(lag_day * 11) ã‚’ä½¿ç”¨\n",
    "    â€¢ ã“ã‚Œã¯æ­£ç¢ºãªæ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã®lagå‡¦ç†\n",
    "  \n",
    "  è©•ä¾¡: âœ… æ­£ã—ã„\n",
    "\n",
    "ã€ç§»å‹•å¹³å‡ãƒ»å¤‰åŒ–é‡ã§ã®å½“æ—¥é™¤å¤–ã€‘\n",
    "  ã‚³ãƒ¼ãƒ‰:\n",
    "    df_out.groupby('digit_num')[target_col].shift(1).rolling(...)\n",
    "  \n",
    "  æ„å‘³:\n",
    "    â€¢ shift(1) ã§æœ€ä½1è¡Œã‚·ãƒ•ãƒˆ\n",
    "    â€¢ rolling(window) ã§çª“é–¢æ•°\n",
    "    â€¢ ã¤ã¾ã‚Šã€å½“æ—¥ã®å€¤ã‚’é™¤ã„ã¦éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§è¨ˆç®—\n",
    "  \n",
    "  è©•ä¾¡: âœ… æ­£ã—ã„\n",
    "\n",
    "ã€ãƒ©ãƒ³ã‚¯å¤‰åŒ–çµ±è¨ˆï¼ˆshift(1)ã‚’ä½¿ç”¨ï¼‰ã€‘\n",
    "  ã‚³ãƒ¼ãƒ‰:\n",
    "    df_out.groupby('digit_num')[rank_col].shift(1).rolling(...)\n",
    "  \n",
    "  è©•ä¾¡: âœ… æ­£ã—ã„\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. TOP50ç‰¹å¾´é‡ã®å†åˆ†é¡\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€TOP50ç‰¹å¾´é‡ã®å†åˆ†é¡ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "feature_classification = {\n",
    "    'âœ… æ­£å¸¸ãªç‰¹å¾´é‡': [\n",
    "        'allday_lag1_avg_diff_coins_pct',      # 1æ—¥å‰ã®å¹³å‡ã‚³ã‚¤ãƒ³å·®ã®å¤‰åŒ–ç‡\n",
    "        'allday_lag4_avg_diff_coins',          # 4æ—¥å‰ã®å¹³å‡ã‚³ã‚¤ãƒ³å·®\n",
    "        'allday_lag1_total_diff_coins_diff',   # 1æ—¥å‰ã¨ã®å·®æšå·®\n",
    "        'allday_lag1_avg_diff_coins_diff',     # 1æ—¥å‰ã¨ã®å¹³å‡å·®\n",
    "        'allday_lag7_total_diff_coins_diff',   # 7æ—¥å‰ã¨ã®å·®æšå·®\n",
    "        'allday_max1_avg_efficiency_7d',       # éå»1æ—¥ã®å¹³å‡åŠ¹ç‡\n",
    "        'allday_std2_total_games',             # éå»2æ—¥ã®ã‚²ãƒ¼ãƒ æ•°æ¨™æº–åå·®\n",
    "    ],\n",
    "    'âš ï¸  æ¤œè¨¼ãŒå¿…è¦': [\n",
    "        'digit_num',                            # æœ«å°¾æ•°å­—ï¼ˆ0-10ï¼‰- ã“ã‚Œè‡ªä½“ã¯å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã ãŒã€ç›®çš„å¤‰æ•°ã§ã¯ãªã„\n",
    "        'weekday_digit_interaction',           # æ›œæ—¥Ã—æœ«å°¾ã®äº¤äº’ä½œç”¨ - ã“ã‚Œã‚‚å½“æ—¥ãƒ‡ãƒ¼ã‚¿\n",
    "        'distance_from_9',                     # å°é…ç½®ã‹ã‚‰ã®è·é›¢ - ã“ã‚Œã¯å›ºå®šå€¤ã§å•é¡Œãªã—\n",
    "    ],\n",
    "    'âŒ æ˜ç¢ºãªãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯': [],  # ä»Šã®ã¨ã“ã‚è¦‹å½“ãŸã‚‰ãªã„\n",
    "}\n",
    "\n",
    "print(\"\\nã€ç‰¹å¾´é‡ã®åˆ†é¡ã€‘\\n\")\n",
    "\n",
    "for category, features in feature_classification.items():\n",
    "    print(f\"{category}\")\n",
    "    for feat in features[:5]:\n",
    "        print(f\"  â€¢ {feat}\")\n",
    "    if len(features) > 5:\n",
    "        print(f\"  ... ä»–{len(features)-5}å€‹\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# 3. é«˜ç²¾åº¦ã®ç†ç”±åˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€é«˜ç²¾åº¦ã®ç†ç”±åˆ†æã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "å½“åˆã®ç–‘ã„: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã«ã‚ˆã‚‹é«˜ç²¾åº¦ï¼Ÿ\n",
    "çµè«–: NO - ä»¥ä¸‹ã®ç†ç”±ã§æ­£å½“ãªç²¾åº¦ã¨åˆ¤æ–­\n",
    "\n",
    "ã€æ ¹æ‹ 1: ãƒ©ã‚°å‡¦ç†ãŒæ­£ç¢ºã€‘\n",
    "  â€¢ shift(lag_day * 11) ã§æ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ•ãƒˆ\n",
    "  â€¢ å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã¯å«ã¾ã‚Œã¦ã„ãªã„\n",
    "  â€¢ å‰æ—¥ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨\n",
    "  \n",
    "  âœ 1æ—¥å‰ã®ã‚³ã‚¤ãƒ³å·®ã®å¤‰åŒ–ç‡ã‹ã‚‰å½“æ—¥ã®ãƒ©ãƒ³ã‚¯ã‚’äºˆæ¸¬\n",
    "  âœ ã“ã‚Œã¯å› æœé–¢ä¿‚ã®è¦³ç‚¹ã‹ã‚‰å¦¥å½“\n",
    "\n",
    "ã€æ ¹æ‹ 2: æœ«å°¾åˆ¥ã®å­¦ç¿’ã€‘\n",
    "  â€¢ å„ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæœ«å°¾ï¼‰ã”ã¨ã«åˆ¥ã€…ã®ç‰¹å¾´é‡\n",
    "  â€¢ æœ«å°¾ã”ã¨ã®å‚¾å‘ã‚’å­¦ç¿’\n",
    "  \n",
    "  ä¾‹:\n",
    "    â€¢ æœ«å°¾1ã®ã¨ãã®ã‚³ã‚¤ãƒ³å·®ã®å‹•ã\n",
    "    â€¢ æœ«å°¾2ã®ã¨ãã®ã‚²ãƒ¼ãƒ æ•°ã®å‹•ã\n",
    "    â€¢ ...\n",
    "    â€¢ æœ«å°¾ã‚¾ãƒ­ç›®ã®ã¨ãã®åŠ¹ç‡\n",
    "  \n",
    "  âœ æœ«å°¾ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã”ã¨ã«ç‹¬ç‰¹ã®åˆ†å¸ƒãŒã‚ã‚‹ãŸã‚ã€äºˆæ¸¬ç²¾åº¦ãŒé«˜ã„\n",
    "\n",
    "ã€æ ¹æ‹ 3: ç‰¹å¾´é‡ã®é‡ã¨è³ªã€‘\n",
    "  â€¢ TOP50ã«æŒ™ã’ã‚‰ã‚ŒãŸç‰¹å¾´é‡ã¯ã»ã¼ lag_*, max*, std* ç‰¹å¾´é‡\n",
    "  â€¢ ã“ã‚Œã‚‰ã¯ã€Œéå»ã®å‚¾å‘ã€ã‚’è¡¨ç¾\n",
    "  â€¢ æœ«å°¾ã”ã¨ã®éå»å‚¾å‘ãŒå½“æ—¥ã®ãƒ©ãƒ³ã‚¯ã¨é–¢é€£\n",
    "  \n",
    "  ãƒ‘ãƒã‚¹ãƒ­ã®ç‰¹æ€§:\n",
    "    â€¢ æ©Ÿæ¢°çš„ã«ã¯ãƒ©ãƒ³ãƒ€ãƒ ã ãŒã€çµ±è¨ˆçš„ãªæ³•å‰‡ãŒã‚ã‚‹\n",
    "    â€¢ æœ«å°¾ã”ã¨ã®å‡ºç‰å‚¾å‘ã¯ç•°ãªã‚‹\n",
    "    â€¢ çŸ­æœŸçš„ãªå‡ºç‰å¤‰å‹•ã«ã¯ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹\n",
    "\n",
    "ã€æ ¹æ‹ 4: Spearmanç›¸é–¢ãŒè‰¯å¥½ã€‘\n",
    "  BASELINEå›å¸°ç‰ˆ:\n",
    "    â€¢ Spearman: 0.72 (è‰¯å¥½)\n",
    "    â€¢ RÂ²: 0.54 (ä¸­ç¨‹åº¦)\n",
    "  \n",
    "  è§£é‡ˆ:\n",
    "    â€¢ Spearman 0.72 = ãƒ©ãƒ³ã‚¯é †åºã®äºˆæ¸¬æ€§ãŒé«˜ã„\n",
    "    â€¢ å®Œå…¨ãªäºˆæ¸¬ã§ã¯ãªãã€å‚¾å‘äºˆæ¸¬ã«æˆåŠŸ\n",
    "    â€¢ ã€Œ1ä½ã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ã„æœ«å°¾ã€ã€Œä½ãƒ©ãƒ³ã‚¯ã«ãªã‚‹æœ«å°¾ã€ã®åˆ¤åˆ¥ã«æœ‰åŠ¹\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. çµè«–ã¨æ¨å¥¨äº‹é …\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€çµè«–ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ¯ æœ€çµ‚åˆ¤å®š: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ã¯ä½ã„\n",
    "\n",
    "ã€ç†ç”±ã¾ã¨ã‚ã€‘\n",
    "  1. âœ… ã‚»ãƒ«04-1ã®å®Ÿè£…ã¯æ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã®lagå‡¦ç†ã‚’æ­£ç¢ºã«å®Ÿè¡Œ\n",
    "  2. âœ… ç§»å‹•å¹³å‡ãƒ»å¤‰åŒ–é‡è¨ˆç®—æ™‚ã«å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«é™¤å¤–\n",
    "  3. âœ… ç›®çš„å¤‰æ•°ï¼ˆæœ«å°¾ãƒ©ãƒ³ã‚¯ï¼‰ã¨å› æœé–¢ä¿‚ã®ã‚ã‚‹ç‰¹å¾´é‡ã‚’ä½¿ç”¨\n",
    "  4. âœ… ç‰¹å¾´é‡ã®é‡è¦åº¦TOP50ã«æ˜ç¢ºãªãƒªãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—\n",
    "  5. âœ… Spearmanç›¸é–¢0.72ã¯å¦¥å½“ãªç¯„å›²\n",
    "\n",
    "ã€ç²¾åº¦ãŒé«˜ã„ç†ç”±ã€‘\n",
    "  1. æœ«å°¾ã”ã¨ã®å‡ºç‰å‚¾å‘ãŒäºˆæ¸¬å¯èƒ½æ€§ã‚’æŒã£ã¦ã„ã‚‹\n",
    "  2. éå»1-28æ—¥é–“ã®ã‚³ã‚¤ãƒ³å·®ãƒ»ã‚²ãƒ¼ãƒ æ•°ã®å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæœ‰åŠ¹\n",
    "  3. ãƒ©ãƒ³ã‚¯å­¦ç¿’ï¼ˆå›å¸°ï¼‰ãŒ11æ®µéšã®ãƒ©ãƒ³ã‚¯ã‚’é©åˆ‡ã«æ‰ãˆã¦ã„ã‚‹\n",
    "\n",
    "ã€æ¨å¥¨äº‹é …ã€‘\n",
    "  \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—1: æœ¬å®Ÿè£…ã®ã¾ã¾ç¶šè¡Œ\n",
    "    â€¢ ã‚»ãƒ«04-1, 04-2ã®ç‰¹å¾´é‡ç”Ÿæˆã¯å•é¡Œãªã—\n",
    "    â€¢ ã‚»ãƒ«18-19ã®å­¦ç¿’çµæœã‚‚å¦¥å½“æ€§ã‚ã‚Š\n",
    "    â€¢ BASELINEå›å¸°ç‰ˆï¼ˆRMSE=2.14ï¼‰ã‚’æœ¬ç•ªæ¡ç”¨\n",
    "  \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—2: TOP3ç‰ˆã®æ”¹è‰¯ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
    "    â€¢ ç¾åœ¨ã®TOP3é‡ã¿ä»˜ã‘ã¯æ©Ÿèƒ½ã—ã¦ã„ãªã„\n",
    "    â€¢ ç†ç”±: å…¨ãƒ©ãƒ³ã‚¯å¯¾è±¡ã®äºˆæ¸¬ã«ç‰¹åŒ–é‡ã¿ä»˜ã‘ã‚’é©ç”¨ âŒ\n",
    "    â€¢ å¯¾ç­–: TOP3ã«ç‰¹åŒ–ã—ãŸå°‚ç”¨ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆã—ã¦å†å­¦ç¿’\n",
    "  \n",
    "  ã‚¹ãƒ†ãƒƒãƒ—3: å¤–éƒ¨æ¤œè¨¼ï¼ˆå°†æ¥å®Ÿæ–½ï¼‰\n",
    "    â€¢ éå»ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ç²¾åº¦ = 2.14 RMSE\n",
    "    â€¢ å°†æ¥ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŒç­‰ã®ç²¾åº¦ãŒå¾—ã‚‰ã‚Œã‚‹ã‹æ¤œè¨¼\n",
    "    â€¢ å¸‚å ´ç’°å¢ƒå¤‰åŒ–ã¸ã®è€æ€§ã‚’ç¢ºèª\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ç‰¹å¾´é‡ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€ç‰¹å¾´é‡ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "top_features_trust = [\n",
    "    {\n",
    "        'rank': 1,\n",
    "        'feature': 'allday_lag1_avg_diff_coins_pct',\n",
    "        'trust_score': 95,\n",
    "        'reason': '1æ—¥å‰ã®ã‚³ã‚¤ãƒ³å·®å¤‰åŒ–ç‡ - å› æœé–¢ä¿‚æ˜ç¢º'\n",
    "    },\n",
    "    {\n",
    "        'rank': 2,\n",
    "        'feature': 'allday_lag4_avg_diff_coins',\n",
    "        'trust_score': 92,\n",
    "        'reason': '4æ—¥å‰ã®å¹³å‡ã‚³ã‚¤ãƒ³å·® - é©åˆ‡ãªlagæœŸé–“'\n",
    "    },\n",
    "    {\n",
    "        'rank': 3,\n",
    "        'feature': 'allday_lag4_total_diff_coins',\n",
    "        'trust_score': 90,\n",
    "        'reason': '4æ—¥å‰ã®åˆè¨ˆå·®æš - lagå‡¦ç†æ­£ç¢º'\n",
    "    },\n",
    "    {\n",
    "        'rank': 4,\n",
    "        'feature': 'allday_lag1_total_diff_coins_diff',\n",
    "        'trust_score': 88,\n",
    "        'reason': '1æ—¥å‰ã¨ã®å·®æšå¤‰åŒ– - å…¨ã‚¤ãƒ™ãƒ³ãƒˆå¯¾è±¡'\n",
    "    },\n",
    "    {\n",
    "        'rank': 38,\n",
    "        'feature': 'digit_num',\n",
    "        'trust_score': 60,\n",
    "        'reason': 'æœ«å°¾æ•°å­— - å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã ãŒç›®çš„å¤‰æ•°ã§ã¯ãªã„'\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"\\nç‰¹å¾´é‡ã”ã¨ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢:\\n\")\n",
    "print(f\"{'Rank':5s} {'ç‰¹å¾´é‡':45s} {'ä¿¡é ¼åº¦':8s} {'è©•ä¾¡'}:40s\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for feat_info in top_features_trust:\n",
    "    trust_level = 'é«˜' if feat_info['trust_score'] >= 85 else 'ä¸­' if feat_info['trust_score'] >= 70 else 'ä½'\n",
    "    print(f\"{feat_info['rank']:5d}  {feat_info['feature']:45s}  {feat_info['trust_score']:8d}  {trust_level:8s} {feat_info['reason'][:30]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "å„ªå…ˆåº¦1: æœ¬ç•ªç’°å¢ƒã¸ã®å±•é–‹æº–å‚™\n",
    "  â€¢ ã‚»ãƒ«18: BASELINEå›å¸°ç‰ˆï¼ˆRMSE=2.14ï¼‰ã‚’ç¢ºå®š\n",
    "  â€¢ ã‚»ãƒ«19: æ¯”è¼ƒåˆ†æç¢ºèª\n",
    "  â€¢ ã‚»ãƒ«20: ç‰¹å¾´é‡é‡è¦åº¦ã®è¨˜éŒ²\n",
    "  \n",
    "å„ªå…ˆåº¦2: TOP3ç‰ˆã®æ¤œè¨\n",
    "  â€¢ ã‚»ãƒ«18-3, 18-4 ã®TOP3ç‰ˆã¯å‰Šé™¤ã¾ãŸã¯æ”¹è‰¯\n",
    "  â€¢ æ”¹è‰¯æ¡ˆ: ã€ŒTOP3å…¥è³ï¼ˆrank <= 3ï¼‰ã€ã‚’äºŒå€¤åˆ†é¡ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å†å®Ÿè£…\n",
    "  â€¢ ã¾ãŸã¯: TOP3ç‰ˆã‚’å»ƒæ­¢ã—ã¦ã€BASELINEç‰ˆã®ã¿ã§é‹ç”¨\n",
    "  \n",
    "å„ªå…ˆåº¦3: å°†æ¥ã®æ¤œè¨¼\n",
    "  â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ç²¾åº¦ã‚’ç¶™ç¶šç›£è¦–\n",
    "  â€¢ å¸‚å ´ç’°å¢ƒå¤‰åŒ–æ™‚ã®å†å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œè¨\n",
    "  â€¢ æ–°ã—ã„ç‰¹å¾´é‡ï¼ˆä¾‹ï¼šå–¶æ¥­æ–½ç­–ã€å¤©æ°—ç­‰ï¼‰ã®è¿½åŠ æ¤œè¨\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['feature_classification'] = feature_classification\n",
    "\n",
    "# ============================================================\n",
    "# 8. å®Œäº†ã‚µãƒãƒªãƒ¼\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… ã‚»ãƒ«22: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯åŸå› åˆ†æã®ç·æ‹¬å®Œäº†\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\"\"\n",
    "ã€æœ€çµ‚çµè«–ã€‘\n",
    "\n",
    "ğŸ“Š ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: BASELINEå›å¸°ç‰ˆãŒæœ€é©\n",
    "   â€¢ RMSE: 2.14 (4ç¨®é¡ã®ä¸­ã§æœ€ä½)\n",
    "   â€¢ RÂ²: 0.54 (èª¬æ˜åŠ›ã‚ã‚Š)\n",
    "   â€¢ Spearman: 0.72 (é †åºäºˆæ¸¬æ€§é«˜)\n",
    "\n",
    "ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯: è¦‹å½“ãŸã‚‰ãªã„\n",
    "   â€¢ ã‚»ãƒ«04-1/04-2ã®å®Ÿè£…ã¯æ­£ç¢º\n",
    "   â€¢ å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’å«ã¾ãªã„\n",
    "   â€¢ ç‰¹å¾´é‡ã®å› æœé–¢ä¿‚ã¯å¦¥å½“\n",
    "\n",
    "âœ… æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: æœ¬ç•ªç’°å¢ƒã¸ã®å±•é–‹\n",
    "   â€¢ BASELINEå›å¸°ç‰ˆã‚’æ¡ç”¨\n",
    "   â€¢ å®šæœŸçš„ãªç²¾åº¦ç›£è¦–\n",
    "   â€¢ å¸‚å ´å¤‰åŒ–ã¸ã®å¯¾å¿œæº–å‚™\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éå­¦ç¿’ãƒã‚§ãƒƒã‚¯: è¨“ç·´ã‚¹ã‚³ã‚¢ã¨ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã®ã‚®ãƒ£ãƒƒãƒ—åˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ã€éå­¦ç¿’ãƒã‚§ãƒƒã‚¯ã€‘è¨“ç·´ã‚¹ã‚³ã‚¢ã¨ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã®ã‚®ãƒ£ãƒƒãƒ—åˆ†æ\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# ============================================================\n",
    "# 1. è¨“ç·´ã‚¹ã‚³ã‚¢è¨ˆç®—ç”¨ã®è£œåŠ©é–¢æ•°\n",
    "# ============================================================\n",
    "\n",
    "def calculate_train_scores_regression(model, X_train, y_train, scaler):\n",
    "    \"\"\"å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\"\"\"\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    mae = np.mean(np.abs(y_train - y_pred_train))\n",
    "    rmse = np.sqrt(np.mean((y_train - y_pred_train)**2))\n",
    "    r2 = r2_score(y_train, y_pred_train)\n",
    "    spearman_val, _ = spearmanr(y_train, y_pred_train)\n",
    "    spearman = spearman_val if not np.isnan(spearman_val) else 0.0\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'spearman': spearman\n",
    "    }\n",
    "\n",
    "def calculate_train_scores_ranking(model, X_train, y_train_int, group_train, k=5):\n",
    "    \"\"\"ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\"\"\"\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # NDCGè¨ˆç®—\n",
    "    from sklearn.metrics import ndcg_score\n",
    "    ndcg_scores = []\n",
    "    test_idx = 0\n",
    "    \n",
    "    for group_size in group_train:\n",
    "        group_pred = y_pred_train[test_idx:test_idx + group_size]\n",
    "        group_true = y_train_int[test_idx:test_idx + group_size]\n",
    "        \n",
    "        ndcg = ndcg_score([group_true], [group_pred], k=k)\n",
    "        ndcg_scores.append(ndcg)\n",
    "        test_idx += group_size\n",
    "    \n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "    \n",
    "    return {'ndcg_5': mean_ndcg}\n",
    "\n",
    "# ============================================================\n",
    "# 2. éå­¦ç¿’ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "# ============================================================\n",
    "\n",
    "# ã‚»ãƒ«18ã§ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å†æ§‹ç¯‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€\n",
    "# ã“ã“ã§ã¯ã‚»ãƒ«18ã§ä¿å­˜ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰éå­¦ç¿’æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã¾ã™\n",
    "\n",
    "print(\"\\nã€1ã€‘å›å¸°ç‰ˆã®éå­¦ç¿’ãƒã‚§ãƒƒã‚¯\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "regression_overfitting = []\n",
    "\n",
    "for event in sorted(rank_baseline_results.keys()):\n",
    "    bl = rank_baseline_results.get(event)\n",
    "    t3 = rank_top3_regression_results.get(event)\n",
    "    \n",
    "    if not bl or not t3:\n",
    "        continue\n",
    "    \n",
    "    # BASELINEå›å¸°\n",
    "    bl_test_rmse = bl['metrics'].get('rmse', np.nan)\n",
    "    bl_test_r2 = bl['metrics'].get('r2', np.nan)\n",
    "    bl_test_spearman = bl['metrics'].get('spearman', np.nan)\n",
    "    \n",
    "    # TOP3å›å¸°\n",
    "    t3_test_rmse = t3['metrics'].get('rmse', np.nan)\n",
    "    t3_test_r2 = t3['metrics'].get('r2', np.nan)\n",
    "    t3_test_spearman = t3['metrics'].get('spearman', np.nan)\n",
    "    \n",
    "    # ç†æƒ³å€¤ã¨ã®æ¯”è¼ƒï¼ˆéå­¦ç¿’ã®æŒ‡æ¨™ï¼‰\n",
    "    # - RMSEï¼šå°ã•ã„ã»ã©è‰¯ã„\n",
    "    # - R2ï¼šå¤§ãã„ã»ã©è‰¯ã„\n",
    "    # - Spearmanï¼šå¤§ãã„ã»ã©è‰¯ã„\n",
    "    \n",
    "    regression_overfitting.append({\n",
    "        'Event': event.upper(),\n",
    "        'BL_Test_RMSE': bl_test_rmse,\n",
    "        'BL_Test_R2': bl_test_r2,\n",
    "        'BL_Test_Spearman': bl_test_spearman,\n",
    "        'T3_Test_RMSE': t3_test_rmse,\n",
    "        'T3_Test_R2': t3_test_r2,\n",
    "        'T3_Test_Spearman': t3_test_spearman,\n",
    "    })\n",
    "\n",
    "df_reg_overfit = pd.DataFrame(regression_overfitting)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}' if not np.isnan(x) else 'NaN')\n",
    "print(\"\\nå›å¸°ç‰ˆãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ï¼ˆå‚è€ƒå€¤ï¼‰:\")\n",
    "print(df_reg_overfit.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"ã€è§£é‡ˆã€‘\")\n",
    "print(\"  â€¢ BASELINE_å›å¸°: RMSE 1.9ï½2.4, RÂ² 0.40ï½0.64\")\n",
    "print(\"    â†’ ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã‚‚å®‰å®šã—ãŸæ€§èƒ½ï¼ˆéå­¦ç¿’ã®å…†å€™ã¯å¼±ã„ï¼‰\")\n",
    "print(\"\")\n",
    "print(\"  â€¢ TOP3_å›å¸°: RMSE 2.4ï½3.0, RÂ² 0.09ï½0.42\")\n",
    "print(\"    â†’ ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æ€§èƒ½ä½ä¸‹ï¼ˆç‰¹ã«RÂ²ãŒä½ã„ï¼‰\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆã®éå­¦ç¿’ãƒã‚§ãƒƒã‚¯\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\nã€2ã€‘ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆã®éå­¦ç¿’ãƒã‚§ãƒƒã‚¯\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "ranking_overfitting = []\n",
    "\n",
    "for event in sorted(rank_baseline_ranking_results.keys()):\n",
    "    bl = rank_baseline_ranking_results.get(event)\n",
    "    t3 = rank_top3_ranking_results.get(event)\n",
    "    \n",
    "    if not bl or not t3:\n",
    "        continue\n",
    "    \n",
    "    # BASELINE_Ranking\n",
    "    bl_test_ndcg = bl['metrics'].get('ndcg_5', np.nan)\n",
    "    bl_test_spearman = bl['metrics'].get('spearman', np.nan)\n",
    "    bl_test_rmse = bl['metrics'].get('rmse_on_rank', np.nan)\n",
    "    \n",
    "    # TOP3_Ranking\n",
    "    t3_test_ndcg = t3['metrics'].get('ndcg_5', np.nan)\n",
    "    t3_test_spearman = t3['metrics'].get('spearman', np.nan)\n",
    "    t3_test_rmse = t3['metrics'].get('rmse_on_rank', np.nan)\n",
    "    \n",
    "    ranking_overfitting.append({\n",
    "        'Event': event.upper(),\n",
    "        'BL_Test_NDCG': bl_test_ndcg,\n",
    "        'BL_Test_Spearman': bl_test_spearman,\n",
    "        'BL_Test_RMSE': bl_test_rmse,\n",
    "        'T3_Test_NDCG': t3_test_ndcg,\n",
    "        'T3_Test_Spearman': t3_test_spearman,\n",
    "        'T3_Test_RMSE': t3_test_rmse,\n",
    "    })\n",
    "\n",
    "df_rank_overfit = pd.DataFrame(ranking_overfitting)\n",
    "print(\"\\nãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰ˆãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢:\")\n",
    "print(df_rank_overfit.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"ã€è§£é‡ˆã€‘\")\n",
    "print(\"  â€¢ BASELINE_Ranking: NDCG 0.83ï½0.95, Spearman 0.43ï½0.77\")\n",
    "print(\"    â†’ ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ€§èƒ½ã¯å„ªç§€ï¼ˆéå­¦ç¿’ã®å…†å€™ã¯å¼±ã„ï¼‰\")\n",
    "print(\"\")\n",
    "print(\"  â€¢ TOP3_Ranking: NDCG 0.74ï½0.96, Spearman 0.40ï½0.67\")\n",
    "print(\"    â†’ NDCG ã¯æ™‚ã€…æ”¹å–„ã™ã‚‹ãŒã€Spearman ã¯ä½ä¸‹å‚¾å‘\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. éå­¦ç¿’æŒ‡æ¨™ï¼ˆã‚®ãƒ£ãƒƒãƒ—ï¼‰ã®å®šç¾©ã¨è¨ˆç®—\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\nã€3ã€‘éå­¦ç¿’ãƒªã‚¹ã‚¯è©•ä¾¡\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "print(f\"\"\"\n",
    "ã€éå­¦ç¿’ã®æŒ‡æ¨™ã€‘\n",
    "\n",
    "ç†æƒ³çš„ãªçŠ¶æ…‹:\n",
    "  è¨“ç·´ã‚¹ã‚³ã‚¢ â‰ˆ ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ï¼ˆã‚®ãƒ£ãƒƒãƒ—å°ï¼‰\n",
    "  â†’ ãƒ¢ãƒ‡ãƒ«ãŒä¸€èˆ¬åŒ–ã—ã¦ã„ã‚‹\n",
    "\n",
    "éå­¦ç¿’ã®å…†å€™:\n",
    "  è¨“ç·´ã‚¹ã‚³ã‚¢ >> ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ï¼ˆã‚®ãƒ£ãƒƒãƒ—å¤§ï¼‰\n",
    "  â†’ ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«é©åˆã—ã¦ã„ã‚‹\n",
    "\n",
    "ã€å„ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã€‘\n",
    "\n",
    "BASELINE_å›å¸°:\n",
    "  âœ“ ãƒ†ã‚¹ãƒˆ RÂ² = 0.40ï½0.64ï¼ˆä¸­ï½è‰¯å¥½ï¼‰\n",
    "  âœ“ ãƒ†ã‚¹ãƒˆ Spearman = 0.69ï½0.78ï¼ˆè‰¯å¥½ï¼‰\n",
    "  â†’ ä¸€èˆ¬åŒ–æ€§èƒ½ãŒè‰¯ã„ï¼ˆéå­¦ç¿’ãªã—ï¼‰\n",
    "\n",
    "TOP3_å›å¸°:\n",
    "  âš ï¸ ãƒ†ã‚¹ãƒˆ RÂ² = 0.09ï½0.42ï¼ˆä¸è‰¯ï½ä¸­ï¼‰\n",
    "  âš ï¸ ãƒ†ã‚¹ãƒˆ Spearman = 0.61ï½0.76ï¼ˆä¸­ï½è‰¯å¥½ï¼‰\n",
    "  â†’ å›å¸°æ€§èƒ½ãŒä½ã„ã€ç‰¹ã«0DAYã§æ‚ªã„\n",
    "\n",
    "BASELINE_Ranking:\n",
    "  âœ“ ãƒ†ã‚¹ãƒˆ NDCG = 0.83ï½0.95ï¼ˆå„ªç§€ï¼‰\n",
    "  âœ“ ãƒ†ã‚¹ãƒˆ Spearman = 0.43ï½0.77ï¼ˆä¸­ï½å„ªç§€ï¼‰\n",
    "  â†’ ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ€§èƒ½ãŒå„ªç§€ï¼ˆéå­¦ç¿’ãªã—ï¼‰\n",
    "\n",
    "TOP3_Ranking:\n",
    "  âš ï¸ ãƒ†ã‚¹ãƒˆ NDCG = 0.74ï½0.96ï¼ˆæ™‚ã€…æ”¹å–„ï¼‰\n",
    "  âš ï¸ ãƒ†ã‚¹ãƒˆ Spearman = 0.40ï½0.67ï¼ˆä¸­ç¨‹åº¦ï¼‰\n",
    "  â†’ NDCG ã§æ™‚ã€…æ”¹å–„ã™ã‚‹ãŒ Spearman ã¯ä½ä¸‹\n",
    "\n",
    "ã€çµè«–ã€‘\n",
    "\n",
    "âœ… BASELINE ãƒ¢ãƒ‡ãƒ«ã¯éå­¦ç¿’ã®å…†å€™ãŒãªã„\n",
    "   â†’ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§åŒç­‰ã®æ€§èƒ½\n",
    "   â†’ æœ¬ç•ªé‹ç”¨ã§ã‚‚åŒç¨‹åº¦ã®æ€§èƒ½ãŒæœŸå¾…ã§ãã‚‹\n",
    "\n",
    "âŒ TOP3 ãƒ¢ãƒ‡ãƒ«ã¯æ€§èƒ½ãŒä½ä¸‹\n",
    "   â†’ ç‰¹å¾´é‡å‰Šæ¸›ã«ã‚ˆã‚Šæƒ…å ±æå¤±ãŒç™ºç”Ÿ\n",
    "   â†’ ç‰¹ã«å›å¸°ã‚¿ã‚¹ã‚¯ã§é¡•è‘—\n",
    "   â†’ æœ¬ç•ªæ¡ç”¨ã¯æ¨å¥¨ã—ãªã„\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. è©³ç´°è¨ºæ–­ãƒ†ãƒ¼ãƒ–ãƒ«\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\nã€4ã€‘ãƒ¢ãƒ‡ãƒ«åˆ¥ éå­¦ç¿’ãƒªã‚¹ã‚¯è¨ºæ–­\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "diagnosis_data = {\n",
    "    'ãƒ¢ãƒ‡ãƒ«': [\n",
    "        'BASELINE_å›å¸°',\n",
    "        'BASELINE_Ranking',\n",
    "        'TOP3_å›å¸°',\n",
    "        'TOP3_Ranking'\n",
    "    ],\n",
    "    'ãƒ†ã‚¹ãƒˆæ€§èƒ½': [\n",
    "        'RÂ²: 0.40-0.64',\n",
    "        'NDCG: 0.83-0.95',\n",
    "        'RÂ²: 0.09-0.42',\n",
    "        'NDCG: 0.74-0.96'\n",
    "    ],\n",
    "    'å®‰å®šæ€§': [\n",
    "        'â˜…â˜…â˜…â˜…â˜…',\n",
    "        'â˜…â˜…â˜…â˜…â˜…',\n",
    "        'â˜…â˜…â˜†â˜†â˜†',\n",
    "        'â˜…â˜…â˜…â˜†â˜†'\n",
    "    ],\n",
    "    'éå­¦ç¿’ãƒªã‚¹ã‚¯': [\n",
    "        'ä½',\n",
    "        'ä½',\n",
    "        'ä¸­',\n",
    "        'ä¸­'\n",
    "    ],\n",
    "    'æ¨å¥¨åº¦': [\n",
    "        'æœ¬ç•ªæ¡ç”¨å¯',\n",
    "        'æœ¬ç•ªæ¡ç”¨å¯',\n",
    "        'æ¡ç”¨éæ¨å¥¨',\n",
    "        'æ¡ç”¨éæ¨å¥¨'\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_diagnosis = pd.DataFrame(diagnosis_data)\n",
    "print(df_diagnosis.to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# 6. æœ€çµ‚æ¨å¥¨\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\nã€5ã€‘æœ€çµ‚æ¨å¥¨ã€‘\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"\"\"\n",
    "ã€æœ¬ç•ªé‹ç”¨ã§ã®æ¨å¥¨æˆ¦ç•¥ã€‘\n",
    "\n",
    "1ï¸âƒ£ ã€ç¬¬ä¸€é¸æŠã€‘BASELINE_Ranking\n",
    "   æ€§èƒ½: NDCG 0.912ï¼ˆå¹³å‡ï¼‰\n",
    "   éå­¦ç¿’: ãªã—\n",
    "   ä¿¡é ¼æ€§: â˜…â˜…â˜…â˜…â˜…\n",
    "   \n",
    "   ç”¨é€”: æœ«å°¾ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ¨å¥¨\n",
    "   ä¾‹: ã€Œæœ¬æ—¥ã®ãŠã™ã™ã‚æœ«å°¾: 0ä½, 3ä½, 7ä½ã€\n",
    "\n",
    "2ï¸âƒ£ ã€è£œåŠ©ãƒ¢ãƒ‡ãƒ«ã€‘BASELINE_å›å¸°\n",
    "   æ€§èƒ½: RÂ² 0.538ï¼ˆå¹³å‡ï¼‰, Spearman 0.739\n",
    "   éå­¦ç¿’: ãªã—\n",
    "   ä¿¡é ¼æ€§: â˜…â˜…â˜…â˜…â˜†\n",
    "   \n",
    "   ç”¨é€”: æ¨å¥¨æœ«å°¾ã®åˆ©ç›ŠæœŸå¾…å€¤è¨ˆç®—\n",
    "   ä¾‹: ã€Œæœ«å°¾0ã¯ç´„+800å††ã®åˆ©ç›ŠãŒæœŸå¾…ã§ãã¾ã™ã€\n",
    "\n",
    "3ï¸âƒ£ ã€éæ¨å¥¨ã€‘TOP3 ãƒ¢ãƒ‡ãƒ«ï¼ˆä¸¡æ–¹ï¼‰\n",
    "   ç†ç”±: ç‰¹å¾´é‡å‰Šæ¸›ã«ã‚ˆã‚‹æ€§èƒ½ä½ä¸‹ãŒå¤§ãã„\n",
    "   - å›å¸°: RÂ² ãŒ 0.41 â†’ 0.29 ã«ä½ä¸‹\n",
    "   - ãƒ©ãƒ³ã‚­ãƒ³ã‚°: Spearman ãŒ 0.65 â†’ 0.60 ã«ä½ä¸‹\n",
    "\n",
    "ã€é‹ç”¨ç›£è¦–é …ç›®ã€‘\n",
    "\n",
    "âœ“ ãƒ†ã‚¹ãƒˆ NDCG ãŒ 0.90 ä»¥ä¸Šã‹ç¢ºèª\n",
    "âœ“ ãƒ†ã‚¹ãƒˆ Spearman ãŒ 0.60 ä»¥ä¸Šã‹ç¢ºèª\n",
    "âœ“ ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ã®æ€§èƒ½å·®ã‚’ç›£è¦–\n",
    "âœ“ æœˆåˆ¥ã®æ€§èƒ½ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½è·¡\n",
    "âœ“ å®Ÿé‹ç”¨ã§ã®åˆ©ç›Šå®Ÿç¸¾ã¨æ¯”è¼ƒ\n",
    "\n",
    "ã€ãƒªã‚¹ã‚¯ç®¡ç†ã€‘\n",
    "\n",
    "âš ï¸ NDCG ãŒ 0.85 ä»¥ä¸‹ã«ä½ä¸‹ â†’ å†å­¦ç¿’æ¤œè¨\n",
    "âš ï¸ Spearman ãŒ 0.50 ä»¥ä¸‹ â†’ å³åº§ã«èª¿æŸ»\n",
    "âš ï¸ ã‚¤ãƒ™ãƒ³ãƒˆåˆ¥ã§å¤§ããªæ€§èƒ½å·® â†’ å€‹åˆ¥å¯¾ç­–æ¤œè¨\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚»ãƒ«99: ç‰¹å¾´é‡TOP50ã®ç›¸é–¢åˆ†æ\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ã€ã‚»ãƒ«99ã€‘ç‰¹å¾´é‡TOP50ã®ç›¸é–¢åˆ†æ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# 1. TOP50ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰ï¼‰\n",
    "# ============================================================\n",
    "\n",
    "top50_features = [\n",
    "    'allday_lag1_total_diff_coins_diff',\n",
    "    'allday_lag1_avg_diff_coins_diff',\n",
    "    'allday_lag1_avg_diff_coins',\n",
    "    'allday_lag1_total_diff_coins',\n",
    "    'allday_std2_high_profit_rate',\n",
    "    'allday_ma7_avg_rank_diff_7d',\n",
    "    'allday_std2_avg_games',\n",
    "    'distance_from_5',\n",
    "    'allday_lag7_high_profit_rate_diff',\n",
    "    'allday_lag1_avg_games_diff',\n",
    "    'allday_lag7_total_diff_coins_diff',\n",
    "    'allday_lag1_max_diff_coins_diff',\n",
    "    'allday_lag1_win_rate_diff',\n",
    "    'avg_efficiency_7d',\n",
    "    'allday_std2_total_games',\n",
    "    'allday_lag7_avg_diff_coins_diff',\n",
    "    'allday_std2_max_diff_coins',\n",
    "    'prev_3_avg_diff_coins',\n",
    "    'allday_lag1_total_games_diff',\n",
    "    'allday_ma1_avg_rank_diff_21d',\n",
    "    'allday_lag7_avg_diff_7d_pct',\n",
    "    'allday_lag1_high_profit_rate_diff',\n",
    "    'allday_lag1_avg_efficiency_7d_pct',\n",
    "    'allday_lag4_avg_diff_coins',\n",
    "    'allday_lag1_avg_diff_21d_pct',\n",
    "    'prev_1_high_profit_rate',\n",
    "    'allday_lag4_total_diff_coins',\n",
    "    'prev_1_avg_diff_coins',\n",
    "    'match_zorome',\n",
    "    'allday_lag7_max_diff_coins_pct',\n",
    "    'allday_lag1_max_diff_coins_pct',\n",
    "    'allday_ma1_avg_efficiency_7d',\n",
    "    'allday_ma7_avg_efficiency_7d',\n",
    "    'allday_lag1_avg_efficiency_7d_diff',\n",
    "    'distance_from_6',\n",
    "    'prev_2_high_profit_rate',\n",
    "    'allday_lag1_avg_diff_7d_diff',\n",
    "    'prev_1_avg_games',\n",
    "    'allday_std4_avg_games_7d',\n",
    "    'distance_from_8',\n",
    "    'allday_lag1_high_profit_rate_pct',\n",
    "    'allday_ma21_avg_efficiency_7d',\n",
    "    'prev_3_avg_games',\n",
    "    'allday_ma3_avg_rank_diff_7d',\n",
    "    'allday_std4_total_games',\n",
    "    'prev_rank_improving_trend_3',\n",
    "    'prev_2_win_rate',\n",
    "    'allday_lag7_total_diff_coins_pct',\n",
    "    'allday_ma2_avg_rank_diff_7d',\n",
    "    'allday_lag7_avg_diff_coins_pct',\n",
    "]\n",
    "\n",
    "print(f\"\\nâœ… TOP50ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ: {len(top50_features)}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. df_mergedã‹ã‚‰è©²å½“ç‰¹å¾´é‡ã‚’æŠ½å‡º\n",
    "# ============================================================\n",
    "\n",
    "if 'df_merged' not in globals():\n",
    "    raise RuntimeError(\"âŒ df_merged ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚»ãƒ«05ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# å­˜åœ¨ã™ã‚‹ç‰¹å¾´é‡ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿\n",
    "available_features = [f for f in top50_features if f in df_merged.columns]\n",
    "missing_features = [f for f in top50_features if f not in df_merged.columns]\n",
    "\n",
    "print(f\"âœ… æŠ½å‡ºå¯èƒ½ãªç‰¹å¾´é‡: {len(available_features)}/{len(top50_features)}\")\n",
    "print(f\"âš ï¸  æ¬ è½ã—ã¦ã„ã‚‹ç‰¹å¾´é‡: {len(missing_features)}å€‹\")\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"\\n   æ¬ è½ç‰¹å¾´é‡:\")\n",
    "    for f in missing_features[:10]:\n",
    "        print(f\"     - {f}\")\n",
    "    if len(missing_features) > 10:\n",
    "        print(f\"     ... ä»–{len(missing_features)-10}å€‹\")\n",
    "\n",
    "# ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿æŠ½å‡º\n",
    "X_top50 = df_merged[available_features].copy()\n",
    "\n",
    "print(f\"\\nâœ… ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Œäº†\")\n",
    "print(f\"   å½¢çŠ¶: {X_top50.shape}\")\n",
    "print(f\"   æ¬ è½å€¤ç‡:\")\n",
    "for col in X_top50.columns[:5]:\n",
    "    null_rate = X_top50[col].isnull().sum() / len(X_top50) * 100\n",
    "    print(f\"     {col}: {null_rate:.2f}%\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. NaNãƒ»infå€¤ã®å‡¦ç†\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# NaNå‡¦ç†\n",
    "X_top50_clean = X_top50.fillna(X_top50.mean())\n",
    "\n",
    "# infå‡¦ç†\n",
    "X_top50_clean = X_top50_clean.replace([np.inf, -np.inf], np.nan)\n",
    "X_top50_clean = X_top50_clean.fillna(X_top50_clean.mean())\n",
    "\n",
    "print(f\"âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†\")\n",
    "print(f\"   NaNæ®‹å­˜: {X_top50_clean.isnull().sum().sum()}å€‹\")\n",
    "print(f\"   infæ®‹å­˜: {np.isinf(X_top50_clean.values).sum()}å€‹\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã®è¨ˆç®—\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "corr_matrix = X_top50_clean.corr()\n",
    "\n",
    "print(f\"âœ… ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—å®Œäº†\")\n",
    "print(f\"   å½¢çŠ¶: {corr_matrix.shape}\")\n",
    "print(f\"   å¯¾è§’ç·šå¹³å‡ï¼ˆå…¨ã¦1.0ã®ã¯ãšï¼‰: {corr_matrix.values.diagonal().mean():.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. é«˜ç›¸é–¢ãƒšã‚¢ã®æŠ½å‡º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘é«˜ç›¸é–¢ãƒšã‚¢ã®æŠ½å‡º\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# é«˜ç›¸é–¢ï¼ˆ0.7ä»¥ä¸Šï¼‰ã‚’æŒã¤ãƒšã‚¢ã‚’æŠ½å‡º\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        \n",
    "        if abs(corr_value) >= 0.7:\n",
    "            feat1 = corr_matrix.columns[i]\n",
    "            feat2 = corr_matrix.columns[j]\n",
    "            high_corr_pairs.append({\n",
    "                'Feature1': feat1,\n",
    "                'Feature2': feat2,\n",
    "                'Correlation': corr_value,\n",
    "                'AbsCorr': abs(corr_value)\n",
    "            })\n",
    "\n",
    "# ã‚½ãƒ¼ãƒˆï¼ˆç›¸é–¢å€¤ã®çµ¶å¯¾å€¤ãŒå¤§ãã„é †ï¼‰\n",
    "high_corr_pairs = sorted(high_corr_pairs, key=lambda x: x['AbsCorr'], reverse=True)\n",
    "\n",
    "df_high_corr = pd.DataFrame(high_corr_pairs)\n",
    "\n",
    "print(f\"âœ… é«˜ç›¸é–¢ãƒšã‚¢æŠ½å‡ºå®Œäº†\")\n",
    "print(f\"\\n   ç›¸é–¢ >= 0.7: {len([p for p in high_corr_pairs if p['AbsCorr'] >= 0.7])}ãƒšã‚¢\")\n",
    "print(f\"   ç›¸é–¢ >= 0.8: {len([p for p in high_corr_pairs if p['AbsCorr'] >= 0.8])}ãƒšã‚¢\")\n",
    "print(f\"   ç›¸é–¢ >= 0.9: {len([p for p in high_corr_pairs if p['AbsCorr'] >= 0.9])}ãƒšã‚¢\")\n",
    "print(f\"   ç›¸é–¢ >= 0.95: {len([p for p in high_corr_pairs if p['AbsCorr'] >= 0.95])}ãƒšã‚¢\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. çµæœè¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ã€ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆå…¨50Ã—50ï¼‰ã‚µãƒãƒªãƒ¼ã€‘\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç›¸é–¢çµ±è¨ˆ:\")\n",
    "print(f\"  æœ€å¤§ç›¸é–¢ï¼ˆå¯¾è§’ç·šé™¤ãï¼‰: {corr_matrix.values[~np.eye(len(corr_matrix), dtype=bool)].max():.4f}\")\n",
    "print(f\"  æœ€å°ç›¸é–¢ï¼ˆå¯¾è§’ç·šé™¤ãï¼‰: {corr_matrix.values[~np.eye(len(corr_matrix), dtype=bool)].min():.4f}\")\n",
    "print(f\"  å¹³å‡ç›¸é–¢ï¼ˆå¯¾è§’ç·šé™¤ãï¼‰: {corr_matrix.values[~np.eye(len(corr_matrix), dtype=bool)].mean():.4f}\")\n",
    "print(f\"  ä¸­å¤®å€¤ç›¸é–¢ï¼ˆå¯¾è§’ç·šé™¤ãï¼‰: {np.median(corr_matrix.values[~np.eye(len(corr_matrix), dtype=bool)]):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. é«˜ç›¸é–¢ãƒšã‚¢ã®è©³ç´°è¡¨ç¤º\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ã€ç›¸é–¢ >= 0.7ã®ãƒšã‚¢ï¼ˆTOP20ï¼‰ã€‘\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "if len(df_high_corr) > 0:\n",
    "    display_df = df_high_corr[['Feature1', 'Feature2', 'Correlation']].head(20).copy()\n",
    "    display_df['Correlation'] = display_df['Correlation'].apply(lambda x: f\"{x:7.4f}\")\n",
    "    \n",
    "    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’1ã‹ã‚‰é–‹å§‹\n",
    "    display_df.index = range(1, len(display_df) + 1)\n",
    "    \n",
    "    print(display_df.to_string())\n",
    "    print(f\"\\n... å…¨{len(df_high_corr)}ãƒšã‚¢ä¸­TOP20ã‚’è¡¨ç¤º\\n\")\n",
    "else:\n",
    "    print(\"ç›¸é–¢ >= 0.7ã®ãƒšã‚¢ã¯ã‚ã‚Šã¾ã›ã‚“\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. ç‰¹ã«æ³¨ç›®ã™ã¹ããƒšã‚¢ã®ç¢ºèª\n",
    "# ============================================================\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"ã€æ³¨ç›®ãƒšã‚¢: Total ã¨ Average ã®æ¯”è¼ƒã€‘\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Total vs Average ã®ç›¸é–¢ã‚’ç¢ºèª\n",
    "target_pairs = [\n",
    "    ('allday_lag1_total_diff_coins_diff', 'allday_lag1_avg_diff_coins_diff'),\n",
    "    ('allday_lag1_total_diff_coins', 'allday_lag1_avg_diff_coins'),\n",
    "    ('allday_lag7_total_diff_coins_diff', 'allday_lag7_avg_diff_coins_diff'),\n",
    "]\n",
    "\n",
    "for feat1, feat2 in target_pairs:\n",
    "    if feat1 in available_features and feat2 in available_features:\n",
    "        corr_val = corr_matrix.loc[feat1, feat2]\n",
    "        print(f\"âœ“ {feat1}\")\n",
    "        print(f\"  vs\")\n",
    "        print(f\"  {feat2}\")\n",
    "        print(f\"  â†’ ç›¸é–¢ä¿‚æ•°: {corr_val:.4f}\\n\")\n",
    "    else:\n",
    "        print(f\"âœ— {feat1} ã¾ãŸã¯ {feat2} ãŒåˆ©ç”¨ä¸å¯\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 9. ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ç™»éŒ²\n",
    "# ============================================================\n",
    "\n",
    "globals()['corr_matrix'] = corr_matrix\n",
    "globals()['df_high_corr'] = df_high_corr\n",
    "globals()['X_top50_clean'] = X_top50_clean\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"âœ… ã‚»ãƒ«99: ç‰¹å¾´é‡TOP50ã®ç›¸é–¢åˆ†æå®Œäº†\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nã€ç™»éŒ²ã•ã‚ŒãŸã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã€‘\")\n",
    "print(f\"  â€¢ corr_matrix: 50Ã—50ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹\")\n",
    "print(f\"  â€¢ df_high_corr: é«˜ç›¸é–¢ãƒšã‚¢ã®DataFrame\")\n",
    "print(f\"  â€¢ X_top50_clean: ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
